{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"./data/dataset.csv\"\n",
    "df = pd.read_csv(dataPath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['popularity',\n",
       " 'duration_ms',\n",
       " 'explicit',\n",
       " 'danceability',\n",
       " 'energy',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'acousticness',\n",
       " 'instrumentalness',\n",
       " 'liveness',\n",
       " 'valence',\n",
       " 'tempo',\n",
       " 'time_signature']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(df.columns)\n",
    "columnsToKeep = columns[4: -1]\n",
    "columnsToKeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>21</td>\n",
       "      <td>384999</td>\n",
       "      <td>False</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>5</td>\n",
       "      <td>-16.393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>125.995</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113996</th>\n",
       "      <td>22</td>\n",
       "      <td>385000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>85.239</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113997</th>\n",
       "      <td>22</td>\n",
       "      <td>271466</td>\n",
       "      <td>False</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>132.378</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113998</th>\n",
       "      <td>41</td>\n",
       "      <td>283893</td>\n",
       "      <td>False</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>135.960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113999</th>\n",
       "      <td>22</td>\n",
       "      <td>241826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>79.198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  duration_ms  explicit  danceability  energy  key  \\\n",
       "0               73       230666     False         0.676  0.4610    1   \n",
       "1               55       149610     False         0.420  0.1660    1   \n",
       "2               57       210826     False         0.438  0.3590    0   \n",
       "3               71       201933     False         0.266  0.0596    0   \n",
       "4               82       198853     False         0.618  0.4430    2   \n",
       "...            ...          ...       ...           ...     ...  ...   \n",
       "113995          21       384999     False         0.172  0.2350    5   \n",
       "113996          22       385000     False         0.174  0.1170    0   \n",
       "113997          22       271466     False         0.629  0.3290    0   \n",
       "113998          41       283893     False         0.587  0.5060    7   \n",
       "113999          22       241826     False         0.526  0.4870    1   \n",
       "\n",
       "        loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0         -6.746     0       0.1430        0.0322          0.000001    0.3580   \n",
       "1        -17.235     1       0.0763        0.9240          0.000006    0.1010   \n",
       "2         -9.734     1       0.0557        0.2100          0.000000    0.1170   \n",
       "3        -18.515     1       0.0363        0.9050          0.000071    0.1320   \n",
       "4         -9.681     1       0.0526        0.4690          0.000000    0.0829   \n",
       "...          ...   ...          ...           ...               ...       ...   \n",
       "113995   -16.393     1       0.0422        0.6400          0.928000    0.0863   \n",
       "113996   -18.318     0       0.0401        0.9940          0.976000    0.1050   \n",
       "113997   -10.895     0       0.0420        0.8670          0.000000    0.0839   \n",
       "113998   -10.889     1       0.0297        0.3810          0.000000    0.2700   \n",
       "113999   -10.204     0       0.0725        0.6810          0.000000    0.0893   \n",
       "\n",
       "        valence    tempo  time_signature  \n",
       "0        0.7150   87.917               4  \n",
       "1        0.2670   77.489               4  \n",
       "2        0.1200   76.332               4  \n",
       "3        0.1430  181.740               3  \n",
       "4        0.1670  119.949               4  \n",
       "...         ...      ...             ...  \n",
       "113995   0.0339  125.995               5  \n",
       "113996   0.0350   85.239               4  \n",
       "113997   0.7430  132.378               4  \n",
       "113998   0.4130  135.960               4  \n",
       "113999   0.7080   79.198               4  \n",
       "\n",
       "[114000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[columnsToKeep]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63301/2517655219.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 0 0 ... 0 0 0]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'explicit'] = df['explicit'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Bool to numerical data for explicit row\n",
    "df.loc[:, 'explicit'] = df['explicit'].astype(int)\n",
    "\n",
    "# One hot encoding for nominal categroies\n",
    "df = pd.get_dummies(df, columns=['key', 'time_signature'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "      <th>time_signature_0</th>\n",
       "      <th>time_signature_1</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>21</td>\n",
       "      <td>384999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-16.393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113996</th>\n",
       "      <td>22</td>\n",
       "      <td>385000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-18.318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113997</th>\n",
       "      <td>22</td>\n",
       "      <td>271466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>-10.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113998</th>\n",
       "      <td>41</td>\n",
       "      <td>283893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>-10.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113999</th>\n",
       "      <td>22</td>\n",
       "      <td>241826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>-10.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  duration_ms  explicit  danceability  energy  loudness  \\\n",
       "0               73       230666         0         0.676  0.4610    -6.746   \n",
       "1               55       149610         0         0.420  0.1660   -17.235   \n",
       "2               57       210826         0         0.438  0.3590    -9.734   \n",
       "3               71       201933         0         0.266  0.0596   -18.515   \n",
       "4               82       198853         0         0.618  0.4430    -9.681   \n",
       "...            ...          ...       ...           ...     ...       ...   \n",
       "113995          21       384999         0         0.172  0.2350   -16.393   \n",
       "113996          22       385000         0         0.174  0.1170   -18.318   \n",
       "113997          22       271466         0         0.629  0.3290   -10.895   \n",
       "113998          41       283893         0         0.587  0.5060   -10.889   \n",
       "113999          22       241826         0         0.526  0.4870   -10.204   \n",
       "\n",
       "        mode  speechiness  acousticness  instrumentalness  ...  key_7  key_8  \\\n",
       "0          0       0.1430        0.0322          0.000001  ...      0      0   \n",
       "1          1       0.0763        0.9240          0.000006  ...      0      0   \n",
       "2          1       0.0557        0.2100          0.000000  ...      0      0   \n",
       "3          1       0.0363        0.9050          0.000071  ...      0      0   \n",
       "4          1       0.0526        0.4690          0.000000  ...      0      0   \n",
       "...      ...          ...           ...               ...  ...    ...    ...   \n",
       "113995     1       0.0422        0.6400          0.928000  ...      0      0   \n",
       "113996     0       0.0401        0.9940          0.976000  ...      0      0   \n",
       "113997     0       0.0420        0.8670          0.000000  ...      0      0   \n",
       "113998     1       0.0297        0.3810          0.000000  ...      1      0   \n",
       "113999     0       0.0725        0.6810          0.000000  ...      0      0   \n",
       "\n",
       "        key_9  key_10  key_11  time_signature_0  time_signature_1  \\\n",
       "0           0       0       0                 0                 0   \n",
       "1           0       0       0                 0                 0   \n",
       "2           0       0       0                 0                 0   \n",
       "3           0       0       0                 0                 0   \n",
       "4           0       0       0                 0                 0   \n",
       "...       ...     ...     ...               ...               ...   \n",
       "113995      0       0       0                 0                 0   \n",
       "113996      0       0       0                 0                 0   \n",
       "113997      0       0       0                 0                 0   \n",
       "113998      0       0       0                 0                 0   \n",
       "113999      0       0       0                 0                 0   \n",
       "\n",
       "        time_signature_3  time_signature_4  time_signature_5  \n",
       "0                      0                 1                 0  \n",
       "1                      0                 1                 0  \n",
       "2                      0                 1                 0  \n",
       "3                      1                 0                 0  \n",
       "4                      0                 1                 0  \n",
       "...                  ...               ...               ...  \n",
       "113995                 0                 0                 1  \n",
       "113996                 0                 1                 0  \n",
       "113997                 0                 1                 0  \n",
       "113998                 0                 1                 0  \n",
       "113999                 0                 1                 0  \n",
       "\n",
       "[114000 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(df):\n",
    "    min_vals = df.min()\n",
    "    max_vals = df.max()\n",
    "\n",
    "    feature_range = max_vals - min_vals\n",
    "\n",
    "    # Check if any feature has zero range\n",
    "    zero_range_features = feature_range[feature_range == 0].index\n",
    "\n",
    "    # Remove features with zero range from normalization\n",
    "    valid_features = feature_range[feature_range != 0].index\n",
    "    df_normalized = (df[valid_features] - min_vals[valid_features]) / feature_range[valid_features]\n",
    "\n",
    "    # Concatenate back the zero range features\n",
    "    if not zero_range_features.empty:\n",
    "        df_normalized = pd.concat([df_normalized, df[zero_range_features]], axis=1)\n",
    "\n",
    "    return df_normalized\n",
    "\n",
    "def standard_scaling(df):\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    return (df - mean) / std\n",
    "\n",
    "responseFrame = df.pop('valence')\n",
    "predictorFrame = df\n",
    "\n",
    "# Min-Max scaling for predictor variables\n",
    "df_normalized = min_max_scaling(predictorFrame)\n",
    "\n",
    "# Standard scaling for predictor variables\n",
    "df_standardized = standard_scaling(predictorFrame)\n",
    "\n",
    "predictorFrame_scaled = df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Variance Explained: [ 1.09444981e-01  6.03669565e-02  4.94908486e-02  4.64556536e-02\n",
      "  4.19001649e-02  4.01805007e-02  3.90068322e-02  3.86327331e-02\n",
      "  3.83258611e-02  3.78149378e-02  3.76791965e-02  3.73347702e-02\n",
      "  3.71835490e-02  3.68971519e-02  3.65401991e-02  3.55663890e-02\n",
      "  3.47790275e-02  3.42192638e-02  3.35724112e-02  3.22060906e-02\n",
      "  3.03396302e-02  2.71356023e-02  2.48980742e-02  2.37158517e-02\n",
      "  1.98644489e-02  1.11528113e-02  5.29606309e-03  1.67410189e-17\n",
      " -2.76444643e-17]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained Variance: [0.10944498 0.16981194 0.21930279 0.26575844 0.3076586  0.34783911\n",
      " 0.38684594 0.42547867 0.46380453 0.50161947 0.53929867 0.57663344\n",
      " 0.61381699 0.65071414 0.68725434 0.72282073 0.75759975 0.79181902\n",
      " 0.82539143 0.85759752 0.88793715 0.91507275 0.93997083 0.96368668\n",
      " 0.98355113 0.99470394 1.         1.         1.        ]\n",
      "Number of components to retain 95.0% variance: 24\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the covariance matrix\n",
    "cov_matrix = np.cov(df_standardized, rowvar=False)\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort eigenvalues and corresponding eigenvectors\n",
    "sorted_indices = eigenvalues.argsort()[::-1]\n",
    "eigenvalues = eigenvalues[sorted_indices]\n",
    "eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "# Proportion of Variance Explained\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "print(\"Proportion of Variance Explained:\", explained_variance_ratio)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='-')\n",
    "plt.title('PVE')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('PVE Ratio')\n",
    "plt.show()\n",
    "\n",
    "# Cumulative explained variance\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "print(\"Cumulative Explained Variance:\", cumulative_variance)\n",
    "target_variance = 0.95\n",
    "n_components = np.where(cumulative_variance >= target_variance)[0][0] + 1\n",
    "print(\"Number of components to retain {}% variance:\".format(target_variance * 100), n_components)\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='-')\n",
    "plt.axhline(y=target_variance, color='r', linestyle='--', label='{}% variance'.format(target_variance * 100))\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Variance Ratio')\n",
    "plt.legend()\n",
    "\n",
    "# Transforming to the new space\n",
    "transformed_data = np.dot(df_standardized, eigenvectors[:, :n_components])\n",
    "principal_df = pd.DataFrame(data=transformed_data, columns=[f\"PC{i}\" for i in range(1, n_components + 1)])\n",
    "\n",
    "# Concatenate the principal components DataFrame with the original DataFrame\n",
    "# final_df = pd.concat([principal_df, df.reset_index()], axis=1)\n",
    "# final_df\n",
    "\n",
    "predictorFrame_scaled = principal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "def reluDer(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "def tanhDer(z):\n",
    "    return 1 - z**2\n",
    "\n",
    "def linearDer(z):\n",
    "    return 1\n",
    "\n",
    "activationDict = {'relu': relu, 'tanh': tanh, 'linear': linear}\n",
    "activationDerivativeDict = {'relu': reluDer, 'tanh': tanhDer, 'linear': linearDer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, inputNumNeuron, numNeurons, activationName, batchSize):\n",
    "        self.batchSize = batchSize\n",
    "        self.inputNumNeuron = inputNumNeuron\n",
    "        self.numNeurons = numNeurons\n",
    "        self.activationName = activationName\n",
    "        self.activation = activationDict[self.activationName]\n",
    "        self.activationDerivative = activationDerivativeDict[self.activationName]\n",
    "        self.dZ_state = np.empty((numNeurons, batchSize))\n",
    "        self.Z_state = np.empty((numNeurons, batchSize))\n",
    "        self.A_state = np.empty((numNeurons, batchSize))\n",
    "        self.dW_state = np.zeros((self.numNeurons, self.inputNumNeuron))\n",
    "        self.db_state = np.zeros((self.numNeurons, 1))\n",
    "        self.initWeights()\n",
    "\n",
    "    def initWeights(self):\n",
    "        # Random initialization unfortunately failed.\n",
    "        # self.W = np.random.randn(self.numNeurons, self.inputNumNeuron)\n",
    "        # self.b = np.random.randn(self.numNeurons, 1)\n",
    "\n",
    "        # Xavier initialization for weights\n",
    "        self.W = np.random.randn(self.numNeurons, self.inputNumNeuron) * np.sqrt(1 / self.inputNumNeuron)\n",
    "        # Initializing biases with zeros\n",
    "        self.b = np.zeros((self.numNeurons, 1))\n",
    "        \n",
    "    def updateForwardState(self, inputToLayer):\n",
    "        # print('\\nupdateForwardState():\\n', 'inputToLayer:', inputToLayer.shape, 'self.W', self.W.shape, 'self.b', self.b.shape)\n",
    "        inducedLocal = np.matmul(self.W, inputToLayer) + self.b\n",
    "        output = self.activation(inducedLocal)\n",
    "        self.Z_state = inducedLocal\n",
    "        self.A_state = output\n",
    "        return output\n",
    "    \n",
    "    def predict(self, inputToLayer, printVals=False):\n",
    "        inducedLocal = np.matmul(self.W, inputToLayer) + self.b\n",
    "        output = self.activation(inducedLocal)\n",
    "        if printVals:\n",
    "            print('inp:', self.b, self.W, 'out:', output)\n",
    "        return output\n",
    "\n",
    "    def updateDeltaState(self, dA):\n",
    "        # Derivative of loss over the weihts of this layer\n",
    "        # print('\\nupdateDeltaState():\\n', 'dA:', dA.shape, 'self.Z_state', self.Z_state.shape)\n",
    "        derActivation = self.activationDerivative(self.Z_state)\n",
    "        dZ = np.multiply(dA, derActivation)\n",
    "        self.dZ_state = dZ\n",
    "\n",
    "    def calculateChange(self, A_input):\n",
    "        self.dW_state = (1 / self.batchSize) * np.dot(self.dZ_state, A_input.T)\n",
    "        self.db_state = (1 / self.batchSize) * np.sum(self.dZ_state, axis=1, keepdims=True)\n",
    "        # print('\\ncalculateChange():\\n', 'self.dW_state:', self.dW_state, 'self.db_state', self.db_state, 'A_input:', A_input.T, 'self.Z_state', self.Z_state)\n",
    "        # print('\\ncalculateChange():\\n', 'A_input:', A_input.T.shape, 'self.Z_state', self.Z_state.shape, 'self.dW_state', self.dW_state.shape, 'self.db_state', self.db_state.shape)\n",
    "\n",
    "    def updateWeightsAndBias(self, lr):\n",
    "        self.W = self.W - lr * self.dW_state\n",
    "        self.b = self.b - lr * self.db_state\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"Input Dim: \" + str(self.inputNumNeuron) + \", Number of Neurons: \" + str(self.numNeurons) + \"\\n Activation: \" + self.activationName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss_history = []\n",
    "        self.test_loss_history = []\n",
    "\n",
    "    def addLayer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def loss(self, predictions, y):\n",
    "        # MSE\n",
    "        batchSize = y.size\n",
    "        error = y - predictions\n",
    "        squaredError = np.dot(error.T, error)\n",
    "        mse = (1 / batchSize) * squaredError\n",
    "        return mse\n",
    "    \n",
    "    def lossDer(self, predictions, y):\n",
    "        # MSE Derivative\n",
    "        batchSize = y.size\n",
    "        error = y - predictions\n",
    "        mseDer = (-2 / batchSize) * np.sum(error, axis=0, keepdims=True)\n",
    "        return mseDer\n",
    "    \n",
    "    def predict(self, testPredictor):\n",
    "        output = testPredictor\n",
    "        for layer in self.layers:\n",
    "            printVals = True if False else False\n",
    "            output = layer.predict(output, printVals)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, trainPredictor):\n",
    "        output = trainPredictor\n",
    "        for layer in self.layers:\n",
    "            output = layer.updateForwardState(output)\n",
    "        return output\n",
    "    \n",
    "    def backprop(self, predictions, y, x, lr):\n",
    "        # Update Delta State\n",
    "        for layerNumber in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[layerNumber]\n",
    "            inputToLayer = self.layers[layerNumber - 1].A_state if layerNumber > 0 else x\n",
    "            \n",
    "            # Output Layer\n",
    "            if(layer == self.layers[-1]):\n",
    "                y_reshaped = np.reshape(y, (1, y.size))\n",
    "                lossDerivative = self.lossDer(predictions, y_reshaped)\n",
    "                # print('\\nbackpropFirst():\\n', 'predictions:', predictions.shape, 'y_reshaped:', y_reshaped.shape, 'lossDerivative:', lossDerivative.shape, 'inputToLayer', inputToLayer.shape)\n",
    "                layer.updateDeltaState(lossDerivative)\n",
    "                layer.calculateChange(inputToLayer)\n",
    "            # Hidden Layers\n",
    "            else:\n",
    "                dZ_next = nextLayer.dZ_state\n",
    "                W_next = nextLayer.W\n",
    "                dA = np.dot(W_next.T, dZ_next)\n",
    "                # print('\\nbackpropAlt():\\n', 'dZ_next:', dZ_next.shape, 'W_next', W_next.shape, 'dA:', dA.shape)\n",
    "                layer.updateDeltaState(dA)\n",
    "                layer.calculateChange(inputToLayer)\n",
    "\n",
    "            nextLayer = layer\n",
    "\n",
    "        # Update Weights and Bias\n",
    "        for layerNumber in range(len(self.layers)):\n",
    "            layer = self.layers[layerNumber]\n",
    "            layer.updateWeightsAndBias(lr)\n",
    "\n",
    "    def fit(self, mini_batches_x, mini_batches_y, mini_test_x, mini_test_y, lr=1e-2, epochAmount=10):\n",
    "        for epoch in range(epochAmount):\n",
    "            print('-----------EPOCH-----------    -----> ', epoch + 1)\n",
    "            # Train using mini-batches\n",
    "            for mini_batch_X, mini_batch_Y in zip(mini_batches_x, mini_batches_y):\n",
    "                predictions = self.forward(mini_batch_X)\n",
    "                self.backprop(predictions, mini_batch_Y, mini_batch_X, lr)\n",
    "\n",
    "            predictions = self.predict(mini_batch_X)\n",
    "            trainLoss = np.squeeze(self.loss(predictions.T, mini_batch_Y.T))\n",
    "            print(f'Train Loss:', trainLoss)\n",
    "            self.loss_history.append((epoch, trainLoss))\n",
    "\n",
    "            testError = np.squeeze(self.testLoss(mini_test_x.T, mini_test_y))\n",
    "            self.test_loss_history.append((epoch, testError))\n",
    "\n",
    "        print('Final Train Loss:', trainLoss)\n",
    "\n",
    "    def testLoss(self, test_x, test_y):\n",
    "        predictions = np.squeeze(self.predict(test_x))\n",
    "        lossMSE = self.loss(predictions, test_y)\n",
    "        return lossMSE\n",
    "    \n",
    "    def testLossR2(self, test_x, test_y):\n",
    "        predictions = np.squeeze(self.predict(test_x))\n",
    "        mean_observed = np.mean(test_y)\n",
    "        total_sum_squares = np.sum((test_y - mean_observed) ** 2)\n",
    "        residual_sum_squares = np.sum((test_y - predictions) ** 2)\n",
    "        r2 = 1 - (residual_sum_squares / total_sum_squares)\n",
    "        return r2\n",
    "    \n",
    "    def plot_loss_history(self):\n",
    "        iterations, losses = zip(*self.loss_history)\n",
    "        _, testLosses = zip(*self.test_loss_history)\n",
    "        plt.plot(iterations, losses)\n",
    "        plt.plot(iterations, testLosses)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Training Loss')\n",
    "        plt.title(f'Training Loss over Epochs NN (lr = {1e4}, epoch = {5000})')\n",
    "        plt.legend(['Train', 'Test'])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def save_weights(self, filename):\n",
    "        # Create a dictionary to hold weights and biases of all layers\n",
    "        weights_dict = {}\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            weights_dict[f\"Layer_{i}_W\"] = layer.W\n",
    "            weights_dict[f\"Layer_{i}_b\"] = layer.b\n",
    "\n",
    "        # Save the weights dictionary to a file\n",
    "        np.savez(filename, **weights_dict)\n",
    "\n",
    "    def load_weights(self, filename):\n",
    "        # Load the weights dictionary from the file\n",
    "        data = np.load(filename)\n",
    "\n",
    "        # Iterate through layers and load weights and biases\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer.W = data[f\"Layer_{i}_W\"]\n",
    "            layer.b = data[f\"Layer_{i}_b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseData = responseFrame.to_numpy()\n",
    "predictorData = predictorFrame_scaled.to_numpy()\n",
    "\n",
    "# Full batch gradient descent\n",
    "batchSize = predictorData.shape[0]\n",
    "# batchSize = 1\n",
    "trainSplit = 0.8\n",
    "valSplit = 0.1\n",
    "testSplit = 0.1\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(predictorData))\n",
    "np.random.shuffle(indices)\n",
    "trainIndices = indices[:int(trainSplit * len(indices))]\n",
    "valIndices = indices[int(trainSplit* len(indices)):int((trainSplit + valSplit) * len(indices))]\n",
    "testIndices = indices[int((trainSplit + valSplit) * len(indices)):]\n",
    "\n",
    "trainPredictor, testPredictor, valPredictor = predictorData[trainIndices], predictorData[testIndices], predictorData[valIndices]\n",
    "trainResponse, testResponse, valResponse = responseData[trainIndices], responseData[testIndices], responseData[valIndices]\n",
    "\n",
    "trainResponse = np.expand_dims(trainResponse, axis=1)\n",
    "\n",
    "# Function to create mini-batches\n",
    "def create_mini_batches(data, batch_size):\n",
    "    mini_batches = []\n",
    "    data_size = len(data)\n",
    "    num_batches = data_size // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        mini_batch = data[start_idx:end_idx]\n",
    "        mini_batches.append(mini_batch.T)\n",
    "    \n",
    "    if data_size % batch_size != 0:\n",
    "        mini_batch = data[num_batches * batch_size:]\n",
    "        mini_batches.append(mini_batch.T)\n",
    "    \n",
    "    return np.array(mini_batches)\n",
    "\n",
    "# Create mini-batches\n",
    "mini_batches_X = create_mini_batches(trainPredictor, batch_size= batchSize)\n",
    "mini_batches_Y = create_mini_batches(trainResponse, batch_size= batchSize)\n",
    "miniTestX = testPredictor\n",
    "miniTestY = testResponse\n",
    "miniValX = valPredictor\n",
    "miniValY = valResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------EPOCH-----------    ----->  1\n",
      "Train Loss: 0.1688501316150984\n",
      "-----------EPOCH-----------    ----->  2\n",
      "Train Loss: 0.1507109993760507\n",
      "-----------EPOCH-----------    ----->  3\n",
      "Train Loss: 0.13701507216523343\n",
      "-----------EPOCH-----------    ----->  4\n",
      "Train Loss: 0.1263762454242636\n",
      "-----------EPOCH-----------    ----->  5\n",
      "Train Loss: 0.11793698076635341\n",
      "-----------EPOCH-----------    ----->  6\n",
      "Train Loss: 0.1111239607162476\n",
      "-----------EPOCH-----------    ----->  7\n",
      "Train Loss: 0.10553164443974457\n",
      "-----------EPOCH-----------    ----->  8\n",
      "Train Loss: 0.10088542153934242\n",
      "-----------EPOCH-----------    ----->  9\n",
      "Train Loss: 0.09697701122820228\n",
      "-----------EPOCH-----------    ----->  10\n",
      "Train Loss: 0.0936448577406267\n",
      "-----------EPOCH-----------    ----->  11\n",
      "Train Loss: 0.0907725944504833\n",
      "-----------EPOCH-----------    ----->  12\n",
      "Train Loss: 0.08827319597117111\n",
      "-----------EPOCH-----------    ----->  13\n",
      "Train Loss: 0.08608029200679823\n",
      "-----------EPOCH-----------    ----->  14\n",
      "Train Loss: 0.08414149556088926\n",
      "-----------EPOCH-----------    ----->  15\n",
      "Train Loss: 0.08241585976880655\n",
      "-----------EPOCH-----------    ----->  16\n",
      "Train Loss: 0.08087354150506496\n",
      "-----------EPOCH-----------    ----->  17\n",
      "Train Loss: 0.07948332819946896\n",
      "-----------EPOCH-----------    ----->  18\n",
      "Train Loss: 0.07822188691626582\n",
      "-----------EPOCH-----------    ----->  19\n",
      "Train Loss: 0.07707298707188476\n",
      "-----------EPOCH-----------    ----->  20\n",
      "Train Loss: 0.07601966247656804\n",
      "-----------EPOCH-----------    ----->  21\n",
      "Train Loss: 0.07504996707529696\n",
      "-----------EPOCH-----------    ----->  22\n",
      "Train Loss: 0.07415402592291023\n",
      "-----------EPOCH-----------    ----->  23\n",
      "Train Loss: 0.07332472614402738\n",
      "-----------EPOCH-----------    ----->  24\n",
      "Train Loss: 0.07255279728433486\n",
      "-----------EPOCH-----------    ----->  25\n",
      "Train Loss: 0.07183200331923266\n",
      "-----------EPOCH-----------    ----->  26\n",
      "Train Loss: 0.07115851259602275\n",
      "-----------EPOCH-----------    ----->  27\n",
      "Train Loss: 0.07052576872095566\n",
      "-----------EPOCH-----------    ----->  28\n",
      "Train Loss: 0.06993068487244988\n",
      "-----------EPOCH-----------    ----->  29\n",
      "Train Loss: 0.06936980056493192\n",
      "-----------EPOCH-----------    ----->  30\n",
      "Train Loss: 0.06884041583322047\n",
      "-----------EPOCH-----------    ----->  31\n",
      "Train Loss: 0.0683403374888409\n",
      "-----------EPOCH-----------    ----->  32\n",
      "Train Loss: 0.0678657060329571\n",
      "-----------EPOCH-----------    ----->  33\n",
      "Train Loss: 0.06741360955587163\n",
      "-----------EPOCH-----------    ----->  34\n",
      "Train Loss: 0.06698416495097435\n",
      "-----------EPOCH-----------    ----->  35\n",
      "Train Loss: 0.06657505746739621\n",
      "-----------EPOCH-----------    ----->  36\n",
      "Train Loss: 0.0661848408479642\n",
      "-----------EPOCH-----------    ----->  37\n",
      "Train Loss: 0.06581257690147907\n",
      "-----------EPOCH-----------    ----->  38\n",
      "Train Loss: 0.06545611149503552\n",
      "-----------EPOCH-----------    ----->  39\n",
      "Train Loss: 0.06511388679274857\n",
      "-----------EPOCH-----------    ----->  40\n",
      "Train Loss: 0.06478611054165095\n",
      "-----------EPOCH-----------    ----->  41\n",
      "Train Loss: 0.06447167985493468\n",
      "-----------EPOCH-----------    ----->  42\n",
      "Train Loss: 0.06416975294082888\n",
      "-----------EPOCH-----------    ----->  43\n",
      "Train Loss: 0.06387860379996953\n",
      "-----------EPOCH-----------    ----->  44\n",
      "Train Loss: 0.06359685704654369\n",
      "-----------EPOCH-----------    ----->  45\n",
      "Train Loss: 0.06332361087906863\n",
      "-----------EPOCH-----------    ----->  46\n",
      "Train Loss: 0.06305945821683474\n",
      "-----------EPOCH-----------    ----->  47\n",
      "Train Loss: 0.06280505046269737\n",
      "-----------EPOCH-----------    ----->  48\n",
      "Train Loss: 0.06255890515860527\n",
      "-----------EPOCH-----------    ----->  49\n",
      "Train Loss: 0.06232118995189185\n",
      "-----------EPOCH-----------    ----->  50\n",
      "Train Loss: 0.062091298006869036\n",
      "-----------EPOCH-----------    ----->  51\n",
      "Train Loss: 0.06186862334479743\n",
      "-----------EPOCH-----------    ----->  52\n",
      "Train Loss: 0.06165254681975147\n",
      "-----------EPOCH-----------    ----->  53\n",
      "Train Loss: 0.06144230960480206\n",
      "-----------EPOCH-----------    ----->  54\n",
      "Train Loss: 0.06123859815437386\n",
      "-----------EPOCH-----------    ----->  55\n",
      "Train Loss: 0.06104088208301917\n",
      "-----------EPOCH-----------    ----->  56\n",
      "Train Loss: 0.060849289750792616\n",
      "-----------EPOCH-----------    ----->  57\n",
      "Train Loss: 0.06066346357993489\n",
      "-----------EPOCH-----------    ----->  58\n",
      "Train Loss: 0.06048324664623552\n",
      "-----------EPOCH-----------    ----->  59\n",
      "Train Loss: 0.06030730733749534\n",
      "-----------EPOCH-----------    ----->  60\n",
      "Train Loss: 0.06013547309480803\n",
      "-----------EPOCH-----------    ----->  61\n",
      "Train Loss: 0.059968823241908796\n",
      "-----------EPOCH-----------    ----->  62\n",
      "Train Loss: 0.059806359862426786\n",
      "-----------EPOCH-----------    ----->  63\n",
      "Train Loss: 0.059647893490559524\n",
      "-----------EPOCH-----------    ----->  64\n",
      "Train Loss: 0.05949362312557016\n",
      "-----------EPOCH-----------    ----->  65\n",
      "Train Loss: 0.05934355405675418\n",
      "-----------EPOCH-----------    ----->  66\n",
      "Train Loss: 0.05919739595643062\n",
      "-----------EPOCH-----------    ----->  67\n",
      "Train Loss: 0.05905493891184513\n",
      "-----------EPOCH-----------    ----->  68\n",
      "Train Loss: 0.0589160671697953\n",
      "-----------EPOCH-----------    ----->  69\n",
      "Train Loss: 0.05878087606336014\n",
      "-----------EPOCH-----------    ----->  70\n",
      "Train Loss: 0.05864859928086876\n",
      "-----------EPOCH-----------    ----->  71\n",
      "Train Loss: 0.05851923980192812\n",
      "-----------EPOCH-----------    ----->  72\n",
      "Train Loss: 0.05839270261090295\n",
      "-----------EPOCH-----------    ----->  73\n",
      "Train Loss: 0.05826877203916225\n",
      "-----------EPOCH-----------    ----->  74\n",
      "Train Loss: 0.05814761045319762\n",
      "-----------EPOCH-----------    ----->  75\n",
      "Train Loss: 0.05802912440165688\n",
      "-----------EPOCH-----------    ----->  76\n",
      "Train Loss: 0.05791341162008379\n",
      "-----------EPOCH-----------    ----->  77\n",
      "Train Loss: 0.057800239829935415\n",
      "-----------EPOCH-----------    ----->  78\n",
      "Train Loss: 0.05768952351184558\n",
      "-----------EPOCH-----------    ----->  79\n",
      "Train Loss: 0.05758097085734299\n",
      "-----------EPOCH-----------    ----->  80\n",
      "Train Loss: 0.05747465729654209\n",
      "-----------EPOCH-----------    ----->  81\n",
      "Train Loss: 0.05737080034703399\n",
      "-----------EPOCH-----------    ----->  82\n",
      "Train Loss: 0.05726937447390673\n",
      "-----------EPOCH-----------    ----->  83\n",
      "Train Loss: 0.057170177549841106\n",
      "-----------EPOCH-----------    ----->  84\n",
      "Train Loss: 0.05707327463598747\n",
      "-----------EPOCH-----------    ----->  85\n",
      "Train Loss: 0.05697859310936128\n",
      "-----------EPOCH-----------    ----->  86\n",
      "Train Loss: 0.05688573106544184\n",
      "-----------EPOCH-----------    ----->  87\n",
      "Train Loss: 0.05679476672223339\n",
      "-----------EPOCH-----------    ----->  88\n",
      "Train Loss: 0.05670570987415556\n",
      "-----------EPOCH-----------    ----->  89\n",
      "Train Loss: 0.056618337184404205\n",
      "-----------EPOCH-----------    ----->  90\n",
      "Train Loss: 0.05653282056324446\n",
      "-----------EPOCH-----------    ----->  91\n",
      "Train Loss: 0.056448829020029755\n",
      "-----------EPOCH-----------    ----->  92\n",
      "Train Loss: 0.05636633852519887\n",
      "-----------EPOCH-----------    ----->  93\n",
      "Train Loss: 0.056285467405261136\n",
      "-----------EPOCH-----------    ----->  94\n",
      "Train Loss: 0.05620599175008623\n",
      "-----------EPOCH-----------    ----->  95\n",
      "Train Loss: 0.05612753880347584\n",
      "-----------EPOCH-----------    ----->  96\n",
      "Train Loss: 0.05605036001573348\n",
      "-----------EPOCH-----------    ----->  97\n",
      "Train Loss: 0.05597458692524945\n",
      "-----------EPOCH-----------    ----->  98\n",
      "Train Loss: 0.05590014792667364\n",
      "-----------EPOCH-----------    ----->  99\n",
      "Train Loss: 0.05582694413933547\n",
      "-----------EPOCH-----------    ----->  100\n",
      "Train Loss: 0.055755068360813724\n",
      "-----------EPOCH-----------    ----->  101\n",
      "Train Loss: 0.05568451375742103\n",
      "-----------EPOCH-----------    ----->  102\n",
      "Train Loss: 0.055615290092850114\n",
      "-----------EPOCH-----------    ----->  103\n",
      "Train Loss: 0.0555473072137201\n",
      "-----------EPOCH-----------    ----->  104\n",
      "Train Loss: 0.05548062720901831\n",
      "-----------EPOCH-----------    ----->  105\n",
      "Train Loss: 0.055415061744715464\n",
      "-----------EPOCH-----------    ----->  106\n",
      "Train Loss: 0.05535074337557419\n",
      "-----------EPOCH-----------    ----->  107\n",
      "Train Loss: 0.05528753083028017\n",
      "-----------EPOCH-----------    ----->  108\n",
      "Train Loss: 0.0552252793327077\n",
      "-----------EPOCH-----------    ----->  109\n",
      "Train Loss: 0.05516394400552998\n",
      "-----------EPOCH-----------    ----->  110\n",
      "Train Loss: 0.05510332152152347\n",
      "-----------EPOCH-----------    ----->  111\n",
      "Train Loss: 0.05504356644237102\n",
      "-----------EPOCH-----------    ----->  112\n",
      "Train Loss: 0.05498463158664009\n",
      "-----------EPOCH-----------    ----->  113\n",
      "Train Loss: 0.05492658560701216\n",
      "-----------EPOCH-----------    ----->  114\n",
      "Train Loss: 0.05486935895421901\n",
      "-----------EPOCH-----------    ----->  115\n",
      "Train Loss: 0.054812972159448976\n",
      "-----------EPOCH-----------    ----->  116\n",
      "Train Loss: 0.05475734305835975\n",
      "-----------EPOCH-----------    ----->  117\n",
      "Train Loss: 0.05470246995929894\n",
      "-----------EPOCH-----------    ----->  118\n",
      "Train Loss: 0.05464835705272216\n",
      "-----------EPOCH-----------    ----->  119\n",
      "Train Loss: 0.05459505215803648\n",
      "-----------EPOCH-----------    ----->  120\n",
      "Train Loss: 0.05454245720882663\n",
      "-----------EPOCH-----------    ----->  121\n",
      "Train Loss: 0.05449067162392757\n",
      "-----------EPOCH-----------    ----->  122\n",
      "Train Loss: 0.054439624828650474\n",
      "-----------EPOCH-----------    ----->  123\n",
      "Train Loss: 0.05438926531032369\n",
      "-----------EPOCH-----------    ----->  124\n",
      "Train Loss: 0.054339483981746185\n",
      "-----------EPOCH-----------    ----->  125\n",
      "Train Loss: 0.054290339689692324\n",
      "-----------EPOCH-----------    ----->  126\n",
      "Train Loss: 0.054241795913752375\n",
      "-----------EPOCH-----------    ----->  127\n",
      "Train Loss: 0.05419387081148327\n",
      "-----------EPOCH-----------    ----->  128\n",
      "Train Loss: 0.05414665076303304\n",
      "-----------EPOCH-----------    ----->  129\n",
      "Train Loss: 0.054100096596758386\n",
      "-----------EPOCH-----------    ----->  130\n",
      "Train Loss: 0.05405418575963919\n",
      "-----------EPOCH-----------    ----->  131\n",
      "Train Loss: 0.05400897530865577\n",
      "-----------EPOCH-----------    ----->  132\n",
      "Train Loss: 0.05396416275493085\n",
      "-----------EPOCH-----------    ----->  133\n",
      "Train Loss: 0.05391983986944831\n",
      "-----------EPOCH-----------    ----->  134\n",
      "Train Loss: 0.053876050698365145\n",
      "-----------EPOCH-----------    ----->  135\n",
      "Train Loss: 0.053832784784656584\n",
      "-----------EPOCH-----------    ----->  136\n",
      "Train Loss: 0.053790088350751684\n",
      "-----------EPOCH-----------    ----->  137\n",
      "Train Loss: 0.05374787214448982\n",
      "-----------EPOCH-----------    ----->  138\n",
      "Train Loss: 0.05370624292019148\n",
      "-----------EPOCH-----------    ----->  139\n",
      "Train Loss: 0.05366515503839458\n",
      "-----------EPOCH-----------    ----->  140\n",
      "Train Loss: 0.05362461530868087\n",
      "-----------EPOCH-----------    ----->  141\n",
      "Train Loss: 0.05358463061533196\n",
      "-----------EPOCH-----------    ----->  142\n",
      "Train Loss: 0.05354513858593356\n",
      "-----------EPOCH-----------    ----->  143\n",
      "Train Loss: 0.05350609017082888\n",
      "-----------EPOCH-----------    ----->  144\n",
      "Train Loss: 0.05346753683038917\n",
      "-----------EPOCH-----------    ----->  145\n",
      "Train Loss: 0.05342927930836752\n",
      "-----------EPOCH-----------    ----->  146\n",
      "Train Loss: 0.05339145246218425\n",
      "-----------EPOCH-----------    ----->  147\n",
      "Train Loss: 0.05335402528910167\n",
      "-----------EPOCH-----------    ----->  148\n",
      "Train Loss: 0.0533170302855703\n",
      "-----------EPOCH-----------    ----->  149\n",
      "Train Loss: 0.053280405376107835\n",
      "-----------EPOCH-----------    ----->  150\n",
      "Train Loss: 0.0532440460448267\n",
      "-----------EPOCH-----------    ----->  151\n",
      "Train Loss: 0.053208061920781896\n",
      "-----------EPOCH-----------    ----->  152\n",
      "Train Loss: 0.05317249287457247\n",
      "-----------EPOCH-----------    ----->  153\n",
      "Train Loss: 0.053137139293718695\n",
      "-----------EPOCH-----------    ----->  154\n",
      "Train Loss: 0.053102125949477344\n",
      "-----------EPOCH-----------    ----->  155\n",
      "Train Loss: 0.053067513010936915\n",
      "-----------EPOCH-----------    ----->  156\n",
      "Train Loss: 0.053033295397394035\n",
      "-----------EPOCH-----------    ----->  157\n",
      "Train Loss: 0.05299962112023188\n",
      "-----------EPOCH-----------    ----->  158\n",
      "Train Loss: 0.05296635264410819\n",
      "-----------EPOCH-----------    ----->  159\n",
      "Train Loss: 0.05293338162008896\n",
      "-----------EPOCH-----------    ----->  160\n",
      "Train Loss: 0.05290080727890161\n",
      "-----------EPOCH-----------    ----->  161\n",
      "Train Loss: 0.052868567993333636\n",
      "-----------EPOCH-----------    ----->  162\n",
      "Train Loss: 0.05283660500043359\n",
      "-----------EPOCH-----------    ----->  163\n",
      "Train Loss: 0.05280487933857682\n",
      "-----------EPOCH-----------    ----->  164\n",
      "Train Loss: 0.052773420377027105\n",
      "-----------EPOCH-----------    ----->  165\n",
      "Train Loss: 0.05274219757112985\n",
      "-----------EPOCH-----------    ----->  166\n",
      "Train Loss: 0.05271126988635407\n",
      "-----------EPOCH-----------    ----->  167\n",
      "Train Loss: 0.0526806559275591\n",
      "-----------EPOCH-----------    ----->  168\n",
      "Train Loss: 0.05265039143960697\n",
      "-----------EPOCH-----------    ----->  169\n",
      "Train Loss: 0.0526204005630936\n",
      "-----------EPOCH-----------    ----->  170\n",
      "Train Loss: 0.05259061705473912\n",
      "-----------EPOCH-----------    ----->  171\n",
      "Train Loss: 0.052561129451068014\n",
      "-----------EPOCH-----------    ----->  172\n",
      "Train Loss: 0.05253191880609254\n",
      "-----------EPOCH-----------    ----->  173\n",
      "Train Loss: 0.0525029536329132\n",
      "-----------EPOCH-----------    ----->  174\n",
      "Train Loss: 0.052474225673758125\n",
      "-----------EPOCH-----------    ----->  175\n",
      "Train Loss: 0.052445708224489844\n",
      "-----------EPOCH-----------    ----->  176\n",
      "Train Loss: 0.05241749463710527\n",
      "-----------EPOCH-----------    ----->  177\n",
      "Train Loss: 0.05238954558957192\n",
      "-----------EPOCH-----------    ----->  178\n",
      "Train Loss: 0.05236193954373565\n",
      "-----------EPOCH-----------    ----->  179\n",
      "Train Loss: 0.05233455304893116\n",
      "-----------EPOCH-----------    ----->  180\n",
      "Train Loss: 0.05230738125488593\n",
      "-----------EPOCH-----------    ----->  181\n",
      "Train Loss: 0.052280521516972586\n",
      "-----------EPOCH-----------    ----->  182\n",
      "Train Loss: 0.05225395788236936\n",
      "-----------EPOCH-----------    ----->  183\n",
      "Train Loss: 0.05222763073283667\n",
      "-----------EPOCH-----------    ----->  184\n",
      "Train Loss: 0.052201514311203866\n",
      "-----------EPOCH-----------    ----->  185\n",
      "Train Loss: 0.05217561477555271\n",
      "-----------EPOCH-----------    ----->  186\n",
      "Train Loss: 0.05214991200764328\n",
      "-----------EPOCH-----------    ----->  187\n",
      "Train Loss: 0.05212444429842483\n",
      "-----------EPOCH-----------    ----->  188\n",
      "Train Loss: 0.05209918671307226\n",
      "-----------EPOCH-----------    ----->  189\n",
      "Train Loss: 0.05207416179751142\n",
      "-----------EPOCH-----------    ----->  190\n",
      "Train Loss: 0.05204936200056958\n",
      "-----------EPOCH-----------    ----->  191\n",
      "Train Loss: 0.052024726905000006\n",
      "-----------EPOCH-----------    ----->  192\n",
      "Train Loss: 0.052000326568757076\n",
      "-----------EPOCH-----------    ----->  193\n",
      "Train Loss: 0.05197612905569724\n",
      "-----------EPOCH-----------    ----->  194\n",
      "Train Loss: 0.05195205048812644\n",
      "-----------EPOCH-----------    ----->  195\n",
      "Train Loss: 0.05192816551067883\n",
      "-----------EPOCH-----------    ----->  196\n",
      "Train Loss: 0.05190445892316543\n",
      "-----------EPOCH-----------    ----->  197\n",
      "Train Loss: 0.0518809439458296\n",
      "-----------EPOCH-----------    ----->  198\n",
      "Train Loss: 0.051857531557717766\n",
      "-----------EPOCH-----------    ----->  199\n",
      "Train Loss: 0.05183432427614453\n",
      "-----------EPOCH-----------    ----->  200\n",
      "Train Loss: 0.05181127630394807\n",
      "-----------EPOCH-----------    ----->  201\n",
      "Train Loss: 0.05178841301357587\n",
      "-----------EPOCH-----------    ----->  202\n",
      "Train Loss: 0.05176571637485043\n",
      "-----------EPOCH-----------    ----->  203\n",
      "Train Loss: 0.05174322414584806\n",
      "-----------EPOCH-----------    ----->  204\n",
      "Train Loss: 0.05172091756036781\n",
      "-----------EPOCH-----------    ----->  205\n",
      "Train Loss: 0.05169877335093406\n",
      "-----------EPOCH-----------    ----->  206\n",
      "Train Loss: 0.051676800588774024\n",
      "-----------EPOCH-----------    ----->  207\n",
      "Train Loss: 0.05165495942277339\n",
      "-----------EPOCH-----------    ----->  208\n",
      "Train Loss: 0.05163329820312707\n",
      "-----------EPOCH-----------    ----->  209\n",
      "Train Loss: 0.05161176772865466\n",
      "-----------EPOCH-----------    ----->  210\n",
      "Train Loss: 0.05159027213895138\n",
      "-----------EPOCH-----------    ----->  211\n",
      "Train Loss: 0.051568894597035\n",
      "-----------EPOCH-----------    ----->  212\n",
      "Train Loss: 0.05154762359486964\n",
      "-----------EPOCH-----------    ----->  213\n",
      "Train Loss: 0.05152643485789526\n",
      "-----------EPOCH-----------    ----->  214\n",
      "Train Loss: 0.05150530346516477\n",
      "-----------EPOCH-----------    ----->  215\n",
      "Train Loss: 0.05148430349702663\n",
      "-----------EPOCH-----------    ----->  216\n",
      "Train Loss: 0.05146345399021146\n",
      "-----------EPOCH-----------    ----->  217\n",
      "Train Loss: 0.051442736627482735\n",
      "-----------EPOCH-----------    ----->  218\n",
      "Train Loss: 0.051422153600428476\n",
      "-----------EPOCH-----------    ----->  219\n",
      "Train Loss: 0.05140168196923776\n",
      "-----------EPOCH-----------    ----->  220\n",
      "Train Loss: 0.05138133627681695\n",
      "-----------EPOCH-----------    ----->  221\n",
      "Train Loss: 0.05136120159966845\n",
      "-----------EPOCH-----------    ----->  222\n",
      "Train Loss: 0.05134118683504998\n",
      "-----------EPOCH-----------    ----->  223\n",
      "Train Loss: 0.051321269993482514\n",
      "-----------EPOCH-----------    ----->  224\n",
      "Train Loss: 0.0513014422469247\n",
      "-----------EPOCH-----------    ----->  225\n",
      "Train Loss: 0.05128177298194663\n",
      "-----------EPOCH-----------    ----->  226\n",
      "Train Loss: 0.05126220571883911\n",
      "-----------EPOCH-----------    ----->  227\n",
      "Train Loss: 0.05124279210024413\n",
      "-----------EPOCH-----------    ----->  228\n",
      "Train Loss: 0.0512235256836497\n",
      "-----------EPOCH-----------    ----->  229\n",
      "Train Loss: 0.05120434216324215\n",
      "-----------EPOCH-----------    ----->  230\n",
      "Train Loss: 0.051185294669751046\n",
      "-----------EPOCH-----------    ----->  231\n",
      "Train Loss: 0.05116632028149548\n",
      "-----------EPOCH-----------    ----->  232\n",
      "Train Loss: 0.051147482876823996\n",
      "-----------EPOCH-----------    ----->  233\n",
      "Train Loss: 0.05112877164211338\n",
      "-----------EPOCH-----------    ----->  234\n",
      "Train Loss: 0.05111015139989484\n",
      "-----------EPOCH-----------    ----->  235\n",
      "Train Loss: 0.05109164917362478\n",
      "-----------EPOCH-----------    ----->  236\n",
      "Train Loss: 0.05107325605622155\n",
      "-----------EPOCH-----------    ----->  237\n",
      "Train Loss: 0.051054986898385835\n",
      "-----------EPOCH-----------    ----->  238\n",
      "Train Loss: 0.051036831347064764\n",
      "-----------EPOCH-----------    ----->  239\n",
      "Train Loss: 0.05101878291925319\n",
      "-----------EPOCH-----------    ----->  240\n",
      "Train Loss: 0.05100087441760266\n",
      "-----------EPOCH-----------    ----->  241\n",
      "Train Loss: 0.05098308614898818\n",
      "-----------EPOCH-----------    ----->  242\n",
      "Train Loss: 0.050965365829386565\n",
      "-----------EPOCH-----------    ----->  243\n",
      "Train Loss: 0.05094773906238481\n",
      "-----------EPOCH-----------    ----->  244\n",
      "Train Loss: 0.0509302175786957\n",
      "-----------EPOCH-----------    ----->  245\n",
      "Train Loss: 0.05091275669180828\n",
      "-----------EPOCH-----------    ----->  246\n",
      "Train Loss: 0.050895402141328636\n",
      "-----------EPOCH-----------    ----->  247\n",
      "Train Loss: 0.05087812655969454\n",
      "-----------EPOCH-----------    ----->  248\n",
      "Train Loss: 0.05086091865505372\n",
      "-----------EPOCH-----------    ----->  249\n",
      "Train Loss: 0.050843830400796236\n",
      "-----------EPOCH-----------    ----->  250\n",
      "Train Loss: 0.05082682119738864\n",
      "-----------EPOCH-----------    ----->  251\n",
      "Train Loss: 0.050809917618552844\n",
      "-----------EPOCH-----------    ----->  252\n",
      "Train Loss: 0.050793067623879536\n",
      "-----------EPOCH-----------    ----->  253\n",
      "Train Loss: 0.05077610237915723\n",
      "-----------EPOCH-----------    ----->  254\n",
      "Train Loss: 0.050759201422725796\n",
      "-----------EPOCH-----------    ----->  255\n",
      "Train Loss: 0.050742403378676915\n",
      "-----------EPOCH-----------    ----->  256\n",
      "Train Loss: 0.050725659496610905\n",
      "-----------EPOCH-----------    ----->  257\n",
      "Train Loss: 0.05070895725951197\n",
      "-----------EPOCH-----------    ----->  258\n",
      "Train Loss: 0.05069232122491611\n",
      "-----------EPOCH-----------    ----->  259\n",
      "Train Loss: 0.05067579119247238\n",
      "-----------EPOCH-----------    ----->  260\n",
      "Train Loss: 0.050659401059175144\n",
      "-----------EPOCH-----------    ----->  261\n",
      "Train Loss: 0.050643073877467845\n",
      "-----------EPOCH-----------    ----->  262\n",
      "Train Loss: 0.05062682175560842\n",
      "-----------EPOCH-----------    ----->  263\n",
      "Train Loss: 0.05061063128954811\n",
      "-----------EPOCH-----------    ----->  264\n",
      "Train Loss: 0.050594558013728315\n",
      "-----------EPOCH-----------    ----->  265\n",
      "Train Loss: 0.05057862306768427\n",
      "-----------EPOCH-----------    ----->  266\n",
      "Train Loss: 0.0505627201033699\n",
      "-----------EPOCH-----------    ----->  267\n",
      "Train Loss: 0.05054689573301803\n",
      "-----------EPOCH-----------    ----->  268\n",
      "Train Loss: 0.050531135568070894\n",
      "-----------EPOCH-----------    ----->  269\n",
      "Train Loss: 0.050515451610594245\n",
      "-----------EPOCH-----------    ----->  270\n",
      "Train Loss: 0.050499886773516564\n",
      "-----------EPOCH-----------    ----->  271\n",
      "Train Loss: 0.05048441953929511\n",
      "-----------EPOCH-----------    ----->  272\n",
      "Train Loss: 0.050469014904148526\n",
      "-----------EPOCH-----------    ----->  273\n",
      "Train Loss: 0.05045373790415922\n",
      "-----------EPOCH-----------    ----->  274\n",
      "Train Loss: 0.050438563775091955\n",
      "-----------EPOCH-----------    ----->  275\n",
      "Train Loss: 0.05042350112056109\n",
      "-----------EPOCH-----------    ----->  276\n",
      "Train Loss: 0.050408553747513185\n",
      "-----------EPOCH-----------    ----->  277\n",
      "Train Loss: 0.050393694783627166\n",
      "-----------EPOCH-----------    ----->  278\n",
      "Train Loss: 0.05037892983960632\n",
      "-----------EPOCH-----------    ----->  279\n",
      "Train Loss: 0.05036425167080589\n",
      "-----------EPOCH-----------    ----->  280\n",
      "Train Loss: 0.05034965484820522\n",
      "-----------EPOCH-----------    ----->  281\n",
      "Train Loss: 0.0503351502748788\n",
      "-----------EPOCH-----------    ----->  282\n",
      "Train Loss: 0.05032067157110323\n",
      "-----------EPOCH-----------    ----->  283\n",
      "Train Loss: 0.05030618580572225\n",
      "-----------EPOCH-----------    ----->  284\n",
      "Train Loss: 0.05029169251310191\n",
      "-----------EPOCH-----------    ----->  285\n",
      "Train Loss: 0.05027730198883971\n",
      "-----------EPOCH-----------    ----->  286\n",
      "Train Loss: 0.05026301742877629\n",
      "-----------EPOCH-----------    ----->  287\n",
      "Train Loss: 0.050248769425516635\n",
      "-----------EPOCH-----------    ----->  288\n",
      "Train Loss: 0.05023460704546291\n",
      "-----------EPOCH-----------    ----->  289\n",
      "Train Loss: 0.05022047399487104\n",
      "-----------EPOCH-----------    ----->  290\n",
      "Train Loss: 0.05020640738608364\n",
      "-----------EPOCH-----------    ----->  291\n",
      "Train Loss: 0.05019241807332626\n",
      "-----------EPOCH-----------    ----->  292\n",
      "Train Loss: 0.050178566098860226\n",
      "-----------EPOCH-----------    ----->  293\n",
      "Train Loss: 0.05016478767908715\n",
      "-----------EPOCH-----------    ----->  294\n",
      "Train Loss: 0.050151068173245966\n",
      "-----------EPOCH-----------    ----->  295\n",
      "Train Loss: 0.05013743449897495\n",
      "-----------EPOCH-----------    ----->  296\n",
      "Train Loss: 0.05012389263352228\n",
      "-----------EPOCH-----------    ----->  297\n",
      "Train Loss: 0.05011042960072413\n",
      "-----------EPOCH-----------    ----->  298\n",
      "Train Loss: 0.05009704869980091\n",
      "-----------EPOCH-----------    ----->  299\n",
      "Train Loss: 0.05008373302828335\n",
      "-----------EPOCH-----------    ----->  300\n",
      "Train Loss: 0.05007049228985203\n",
      "-----------EPOCH-----------    ----->  301\n",
      "Train Loss: 0.05005732320398189\n",
      "-----------EPOCH-----------    ----->  302\n",
      "Train Loss: 0.05004421714558732\n",
      "-----------EPOCH-----------    ----->  303\n",
      "Train Loss: 0.05003114263362828\n",
      "-----------EPOCH-----------    ----->  304\n",
      "Train Loss: 0.050018099298769866\n",
      "-----------EPOCH-----------    ----->  305\n",
      "Train Loss: 0.05000516075208113\n",
      "-----------EPOCH-----------    ----->  306\n",
      "Train Loss: 0.04999231810098969\n",
      "-----------EPOCH-----------    ----->  307\n",
      "Train Loss: 0.049979548795338405\n",
      "-----------EPOCH-----------    ----->  308\n",
      "Train Loss: 0.049966835612845435\n",
      "-----------EPOCH-----------    ----->  309\n",
      "Train Loss: 0.04995416893458796\n",
      "-----------EPOCH-----------    ----->  310\n",
      "Train Loss: 0.04994156684576722\n",
      "-----------EPOCH-----------    ----->  311\n",
      "Train Loss: 0.04992904681370339\n",
      "-----------EPOCH-----------    ----->  312\n",
      "Train Loss: 0.04991658778329171\n",
      "-----------EPOCH-----------    ----->  313\n",
      "Train Loss: 0.04990419738864933\n",
      "-----------EPOCH-----------    ----->  314\n",
      "Train Loss: 0.04989180290700956\n",
      "-----------EPOCH-----------    ----->  315\n",
      "Train Loss: 0.04987944758706052\n",
      "-----------EPOCH-----------    ----->  316\n",
      "Train Loss: 0.04986715615418826\n",
      "-----------EPOCH-----------    ----->  317\n",
      "Train Loss: 0.04985492815723391\n",
      "-----------EPOCH-----------    ----->  318\n",
      "Train Loss: 0.04984276874775775\n",
      "-----------EPOCH-----------    ----->  319\n",
      "Train Loss: 0.04983065682236599\n",
      "-----------EPOCH-----------    ----->  320\n",
      "Train Loss: 0.04981859451762957\n",
      "-----------EPOCH-----------    ----->  321\n",
      "Train Loss: 0.04980659346687725\n",
      "-----------EPOCH-----------    ----->  322\n",
      "Train Loss: 0.049794641155781076\n",
      "-----------EPOCH-----------    ----->  323\n",
      "Train Loss: 0.04978276201319108\n",
      "-----------EPOCH-----------    ----->  324\n",
      "Train Loss: 0.04977095228553313\n",
      "-----------EPOCH-----------    ----->  325\n",
      "Train Loss: 0.04975920285406092\n",
      "-----------EPOCH-----------    ----->  326\n",
      "Train Loss: 0.049747478305095134\n",
      "-----------EPOCH-----------    ----->  327\n",
      "Train Loss: 0.049735825871879955\n",
      "-----------EPOCH-----------    ----->  328\n",
      "Train Loss: 0.049724241357246506\n",
      "-----------EPOCH-----------    ----->  329\n",
      "Train Loss: 0.04971271735201226\n",
      "-----------EPOCH-----------    ----->  330\n",
      "Train Loss: 0.04970124407536894\n",
      "-----------EPOCH-----------    ----->  331\n",
      "Train Loss: 0.04968983531147483\n",
      "-----------EPOCH-----------    ----->  332\n",
      "Train Loss: 0.04967844473955206\n",
      "-----------EPOCH-----------    ----->  333\n",
      "Train Loss: 0.04966708128450495\n",
      "-----------EPOCH-----------    ----->  334\n",
      "Train Loss: 0.049655770290898675\n",
      "-----------EPOCH-----------    ----->  335\n",
      "Train Loss: 0.049644545803079726\n",
      "-----------EPOCH-----------    ----->  336\n",
      "Train Loss: 0.04963336778029986\n",
      "-----------EPOCH-----------    ----->  337\n",
      "Train Loss: 0.04962224298133698\n",
      "-----------EPOCH-----------    ----->  338\n",
      "Train Loss: 0.04961115418517045\n",
      "-----------EPOCH-----------    ----->  339\n",
      "Train Loss: 0.049600106573161565\n",
      "-----------EPOCH-----------    ----->  340\n",
      "Train Loss: 0.04958911124450465\n",
      "-----------EPOCH-----------    ----->  341\n",
      "Train Loss: 0.04957816681537912\n",
      "-----------EPOCH-----------    ----->  342\n",
      "Train Loss: 0.049567275127092206\n",
      "-----------EPOCH-----------    ----->  343\n",
      "Train Loss: 0.04955641810755613\n",
      "-----------EPOCH-----------    ----->  344\n",
      "Train Loss: 0.0495455955370162\n",
      "-----------EPOCH-----------    ----->  345\n",
      "Train Loss: 0.04953481225244102\n",
      "-----------EPOCH-----------    ----->  346\n",
      "Train Loss: 0.04952405038669445\n",
      "-----------EPOCH-----------    ----->  347\n",
      "Train Loss: 0.04951333548082909\n",
      "-----------EPOCH-----------    ----->  348\n",
      "Train Loss: 0.04950267940324496\n",
      "-----------EPOCH-----------    ----->  349\n",
      "Train Loss: 0.04949204797901346\n",
      "-----------EPOCH-----------    ----->  350\n",
      "Train Loss: 0.04948145334198003\n",
      "-----------EPOCH-----------    ----->  351\n",
      "Train Loss: 0.04947092267121688\n",
      "-----------EPOCH-----------    ----->  352\n",
      "Train Loss: 0.04946043048284663\n",
      "-----------EPOCH-----------    ----->  353\n",
      "Train Loss: 0.049449972994294475\n",
      "-----------EPOCH-----------    ----->  354\n",
      "Train Loss: 0.04943955055307471\n",
      "-----------EPOCH-----------    ----->  355\n",
      "Train Loss: 0.04942917172815764\n",
      "-----------EPOCH-----------    ----->  356\n",
      "Train Loss: 0.049418809499643765\n",
      "-----------EPOCH-----------    ----->  357\n",
      "Train Loss: 0.04940848724266884\n",
      "-----------EPOCH-----------    ----->  358\n",
      "Train Loss: 0.04939819324295819\n",
      "-----------EPOCH-----------    ----->  359\n",
      "Train Loss: 0.04938793894778587\n",
      "-----------EPOCH-----------    ----->  360\n",
      "Train Loss: 0.049377740472439535\n",
      "-----------EPOCH-----------    ----->  361\n",
      "Train Loss: 0.049367591498215006\n",
      "-----------EPOCH-----------    ----->  362\n",
      "Train Loss: 0.0493574829762754\n",
      "-----------EPOCH-----------    ----->  363\n",
      "Train Loss: 0.0493474163030555\n",
      "-----------EPOCH-----------    ----->  364\n",
      "Train Loss: 0.04933738806367134\n",
      "-----------EPOCH-----------    ----->  365\n",
      "Train Loss: 0.04932739360824691\n",
      "-----------EPOCH-----------    ----->  366\n",
      "Train Loss: 0.04931743476775456\n",
      "-----------EPOCH-----------    ----->  367\n",
      "Train Loss: 0.04930750490037485\n",
      "-----------EPOCH-----------    ----->  368\n",
      "Train Loss: 0.049297595740313185\n",
      "-----------EPOCH-----------    ----->  369\n",
      "Train Loss: 0.04928772278545227\n",
      "-----------EPOCH-----------    ----->  370\n",
      "Train Loss: 0.0492779235838941\n",
      "-----------EPOCH-----------    ----->  371\n",
      "Train Loss: 0.04926819434375913\n",
      "-----------EPOCH-----------    ----->  372\n",
      "Train Loss: 0.04925853038079533\n",
      "-----------EPOCH-----------    ----->  373\n",
      "Train Loss: 0.04924891152880913\n",
      "-----------EPOCH-----------    ----->  374\n",
      "Train Loss: 0.04923934103577105\n",
      "-----------EPOCH-----------    ----->  375\n",
      "Train Loss: 0.049229811638333607\n",
      "-----------EPOCH-----------    ----->  376\n",
      "Train Loss: 0.04922032431874063\n",
      "-----------EPOCH-----------    ----->  377\n",
      "Train Loss: 0.04921086827747169\n",
      "-----------EPOCH-----------    ----->  378\n",
      "Train Loss: 0.04920145601271267\n",
      "-----------EPOCH-----------    ----->  379\n",
      "Train Loss: 0.049192076004124355\n",
      "-----------EPOCH-----------    ----->  380\n",
      "Train Loss: 0.04918271940161488\n",
      "-----------EPOCH-----------    ----->  381\n",
      "Train Loss: 0.04917339555115847\n",
      "-----------EPOCH-----------    ----->  382\n",
      "Train Loss: 0.049164106423764974\n",
      "-----------EPOCH-----------    ----->  383\n",
      "Train Loss: 0.04915486199446301\n",
      "-----------EPOCH-----------    ----->  384\n",
      "Train Loss: 0.049145656477241374\n",
      "-----------EPOCH-----------    ----->  385\n",
      "Train Loss: 0.049136496865843295\n",
      "-----------EPOCH-----------    ----->  386\n",
      "Train Loss: 0.04912736558912452\n",
      "-----------EPOCH-----------    ----->  387\n",
      "Train Loss: 0.04911824202761978\n",
      "-----------EPOCH-----------    ----->  388\n",
      "Train Loss: 0.049109163143739316\n",
      "-----------EPOCH-----------    ----->  389\n",
      "Train Loss: 0.04910013409406027\n",
      "-----------EPOCH-----------    ----->  390\n",
      "Train Loss: 0.0490911384047003\n",
      "-----------EPOCH-----------    ----->  391\n",
      "Train Loss: 0.049082177308113935\n",
      "-----------EPOCH-----------    ----->  392\n",
      "Train Loss: 0.04907324166559192\n",
      "-----------EPOCH-----------    ----->  393\n",
      "Train Loss: 0.04906432389850415\n",
      "-----------EPOCH-----------    ----->  394\n",
      "Train Loss: 0.0490554048928993\n",
      "-----------EPOCH-----------    ----->  395\n",
      "Train Loss: 0.0490465243288587\n",
      "-----------EPOCH-----------    ----->  396\n",
      "Train Loss: 0.049037672006691305\n",
      "-----------EPOCH-----------    ----->  397\n",
      "Train Loss: 0.04902885184524794\n",
      "-----------EPOCH-----------    ----->  398\n",
      "Train Loss: 0.0490200668746815\n",
      "-----------EPOCH-----------    ----->  399\n",
      "Train Loss: 0.04901131985623241\n",
      "-----------EPOCH-----------    ----->  400\n",
      "Train Loss: 0.0490026162256419\n",
      "-----------EPOCH-----------    ----->  401\n",
      "Train Loss: 0.04899393677686904\n",
      "-----------EPOCH-----------    ----->  402\n",
      "Train Loss: 0.04898528085366745\n",
      "-----------EPOCH-----------    ----->  403\n",
      "Train Loss: 0.0489766601420634\n",
      "-----------EPOCH-----------    ----->  404\n",
      "Train Loss: 0.04896807864379848\n",
      "-----------EPOCH-----------    ----->  405\n",
      "Train Loss: 0.04895952043607765\n",
      "-----------EPOCH-----------    ----->  406\n",
      "Train Loss: 0.048950979304614686\n",
      "-----------EPOCH-----------    ----->  407\n",
      "Train Loss: 0.04894248893082148\n",
      "-----------EPOCH-----------    ----->  408\n",
      "Train Loss: 0.048934015727005224\n",
      "-----------EPOCH-----------    ----->  409\n",
      "Train Loss: 0.04892557758286123\n",
      "-----------EPOCH-----------    ----->  410\n",
      "Train Loss: 0.04891717725380933\n",
      "-----------EPOCH-----------    ----->  411\n",
      "Train Loss: 0.04890881184269171\n",
      "-----------EPOCH-----------    ----->  412\n",
      "Train Loss: 0.04890047595688838\n",
      "-----------EPOCH-----------    ----->  413\n",
      "Train Loss: 0.04889216147663366\n",
      "-----------EPOCH-----------    ----->  414\n",
      "Train Loss: 0.04888388297225833\n",
      "-----------EPOCH-----------    ----->  415\n",
      "Train Loss: 0.04887566245396525\n",
      "-----------EPOCH-----------    ----->  416\n",
      "Train Loss: 0.04886747860307651\n",
      "-----------EPOCH-----------    ----->  417\n",
      "Train Loss: 0.04885932628619108\n",
      "-----------EPOCH-----------    ----->  418\n",
      "Train Loss: 0.04885117655318924\n",
      "-----------EPOCH-----------    ----->  419\n",
      "Train Loss: 0.048843053871617276\n",
      "-----------EPOCH-----------    ----->  420\n",
      "Train Loss: 0.04883496563707654\n",
      "-----------EPOCH-----------    ----->  421\n",
      "Train Loss: 0.04882690113450733\n",
      "-----------EPOCH-----------    ----->  422\n",
      "Train Loss: 0.0488188465839711\n",
      "-----------EPOCH-----------    ----->  423\n",
      "Train Loss: 0.04881081225884488\n",
      "-----------EPOCH-----------    ----->  424\n",
      "Train Loss: 0.04880281737043985\n",
      "-----------EPOCH-----------    ----->  425\n",
      "Train Loss: 0.048794857682110754\n",
      "-----------EPOCH-----------    ----->  426\n",
      "Train Loss: 0.0487869351876109\n",
      "-----------EPOCH-----------    ----->  427\n",
      "Train Loss: 0.04877904408975869\n",
      "-----------EPOCH-----------    ----->  428\n",
      "Train Loss: 0.04877117052354934\n",
      "-----------EPOCH-----------    ----->  429\n",
      "Train Loss: 0.04876332945872561\n",
      "-----------EPOCH-----------    ----->  430\n",
      "Train Loss: 0.04875550404086427\n",
      "-----------EPOCH-----------    ----->  431\n",
      "Train Loss: 0.048747702739066555\n",
      "-----------EPOCH-----------    ----->  432\n",
      "Train Loss: 0.04873993795254952\n",
      "-----------EPOCH-----------    ----->  433\n",
      "Train Loss: 0.048732193402209224\n",
      "-----------EPOCH-----------    ----->  434\n",
      "Train Loss: 0.04872446220700146\n",
      "-----------EPOCH-----------    ----->  435\n",
      "Train Loss: 0.04871673718096385\n",
      "-----------EPOCH-----------    ----->  436\n",
      "Train Loss: 0.04870903480875453\n",
      "-----------EPOCH-----------    ----->  437\n",
      "Train Loss: 0.04870134726664741\n",
      "-----------EPOCH-----------    ----->  438\n",
      "Train Loss: 0.048693679991265844\n",
      "-----------EPOCH-----------    ----->  439\n",
      "Train Loss: 0.04868604073091177\n",
      "-----------EPOCH-----------    ----->  440\n",
      "Train Loss: 0.04867842275029328\n",
      "-----------EPOCH-----------    ----->  441\n",
      "Train Loss: 0.04867083032719049\n",
      "-----------EPOCH-----------    ----->  442\n",
      "Train Loss: 0.04866325302958166\n",
      "-----------EPOCH-----------    ----->  443\n",
      "Train Loss: 0.048655700895992623\n",
      "-----------EPOCH-----------    ----->  444\n",
      "Train Loss: 0.04864816414829595\n",
      "-----------EPOCH-----------    ----->  445\n",
      "Train Loss: 0.048640635605488355\n",
      "-----------EPOCH-----------    ----->  446\n",
      "Train Loss: 0.04863308403262578\n",
      "-----------EPOCH-----------    ----->  447\n",
      "Train Loss: 0.048625551820269515\n",
      "-----------EPOCH-----------    ----->  448\n",
      "Train Loss: 0.04861802948984515\n",
      "-----------EPOCH-----------    ----->  449\n",
      "Train Loss: 0.04861051734692669\n",
      "-----------EPOCH-----------    ----->  450\n",
      "Train Loss: 0.0486029902044464\n",
      "-----------EPOCH-----------    ----->  451\n",
      "Train Loss: 0.048595481809918295\n",
      "-----------EPOCH-----------    ----->  452\n",
      "Train Loss: 0.048587982141128146\n",
      "-----------EPOCH-----------    ----->  453\n",
      "Train Loss: 0.04858051365608482\n",
      "-----------EPOCH-----------    ----->  454\n",
      "Train Loss: 0.04857306794204185\n",
      "-----------EPOCH-----------    ----->  455\n",
      "Train Loss: 0.048565644770004746\n",
      "-----------EPOCH-----------    ----->  456\n",
      "Train Loss: 0.048558241048730716\n",
      "-----------EPOCH-----------    ----->  457\n",
      "Train Loss: 0.048550859717770824\n",
      "-----------EPOCH-----------    ----->  458\n",
      "Train Loss: 0.04854350146445524\n",
      "-----------EPOCH-----------    ----->  459\n",
      "Train Loss: 0.048536169193062015\n",
      "-----------EPOCH-----------    ----->  460\n",
      "Train Loss: 0.048528859786183855\n",
      "-----------EPOCH-----------    ----->  461\n",
      "Train Loss: 0.048521568611311086\n",
      "-----------EPOCH-----------    ----->  462\n",
      "Train Loss: 0.04851430054626985\n",
      "-----------EPOCH-----------    ----->  463\n",
      "Train Loss: 0.0485070476634823\n",
      "-----------EPOCH-----------    ----->  464\n",
      "Train Loss: 0.04849981681960877\n",
      "-----------EPOCH-----------    ----->  465\n",
      "Train Loss: 0.04849261321822398\n",
      "-----------EPOCH-----------    ----->  466\n",
      "Train Loss: 0.04848545798003632\n",
      "-----------EPOCH-----------    ----->  467\n",
      "Train Loss: 0.0484783420460805\n",
      "-----------EPOCH-----------    ----->  468\n",
      "Train Loss: 0.04847124994525972\n",
      "-----------EPOCH-----------    ----->  469\n",
      "Train Loss: 0.048464167419563796\n",
      "-----------EPOCH-----------    ----->  470\n",
      "Train Loss: 0.04845709185144207\n",
      "-----------EPOCH-----------    ----->  471\n",
      "Train Loss: 0.04845002024669645\n",
      "-----------EPOCH-----------    ----->  472\n",
      "Train Loss: 0.048442960591829155\n",
      "-----------EPOCH-----------    ----->  473\n",
      "Train Loss: 0.048435918111479195\n",
      "-----------EPOCH-----------    ----->  474\n",
      "Train Loss: 0.04842889403694403\n",
      "-----------EPOCH-----------    ----->  475\n",
      "Train Loss: 0.0484218913093987\n",
      "-----------EPOCH-----------    ----->  476\n",
      "Train Loss: 0.04841492015053475\n",
      "-----------EPOCH-----------    ----->  477\n",
      "Train Loss: 0.048407989716419436\n",
      "-----------EPOCH-----------    ----->  478\n",
      "Train Loss: 0.048401094256403446\n",
      "-----------EPOCH-----------    ----->  479\n",
      "Train Loss: 0.04839421261597361\n",
      "-----------EPOCH-----------    ----->  480\n",
      "Train Loss: 0.048387357263524444\n",
      "-----------EPOCH-----------    ----->  481\n",
      "Train Loss: 0.04838052971614338\n",
      "-----------EPOCH-----------    ----->  482\n",
      "Train Loss: 0.048373726145840776\n",
      "-----------EPOCH-----------    ----->  483\n",
      "Train Loss: 0.04836692014715264\n",
      "-----------EPOCH-----------    ----->  484\n",
      "Train Loss: 0.04836012297887266\n",
      "-----------EPOCH-----------    ----->  485\n",
      "Train Loss: 0.04835335046183101\n",
      "-----------EPOCH-----------    ----->  486\n",
      "Train Loss: 0.048346599836987456\n",
      "-----------EPOCH-----------    ----->  487\n",
      "Train Loss: 0.04833988309545917\n",
      "-----------EPOCH-----------    ----->  488\n",
      "Train Loss: 0.048333183263011795\n",
      "-----------EPOCH-----------    ----->  489\n",
      "Train Loss: 0.04832649023879137\n",
      "-----------EPOCH-----------    ----->  490\n",
      "Train Loss: 0.04831981384586913\n",
      "-----------EPOCH-----------    ----->  491\n",
      "Train Loss: 0.048313157306931066\n",
      "-----------EPOCH-----------    ----->  492\n",
      "Train Loss: 0.04830650354486475\n",
      "-----------EPOCH-----------    ----->  493\n",
      "Train Loss: 0.04829986769326425\n",
      "-----------EPOCH-----------    ----->  494\n",
      "Train Loss: 0.04829324755200983\n",
      "-----------EPOCH-----------    ----->  495\n",
      "Train Loss: 0.04828664187873076\n",
      "-----------EPOCH-----------    ----->  496\n",
      "Train Loss: 0.048280050688261696\n",
      "-----------EPOCH-----------    ----->  497\n",
      "Train Loss: 0.048273478511953787\n",
      "-----------EPOCH-----------    ----->  498\n",
      "Train Loss: 0.04826692993155152\n",
      "-----------EPOCH-----------    ----->  499\n",
      "Train Loss: 0.048260398419475714\n",
      "-----------EPOCH-----------    ----->  500\n",
      "Train Loss: 0.04825389341665104\n",
      "-----------EPOCH-----------    ----->  501\n",
      "Train Loss: 0.048247425298475775\n",
      "-----------EPOCH-----------    ----->  502\n",
      "Train Loss: 0.04824097159875217\n",
      "-----------EPOCH-----------    ----->  503\n",
      "Train Loss: 0.04823453826508486\n",
      "-----------EPOCH-----------    ----->  504\n",
      "Train Loss: 0.04822812278272594\n",
      "-----------EPOCH-----------    ----->  505\n",
      "Train Loss: 0.04822171770620795\n",
      "-----------EPOCH-----------    ----->  506\n",
      "Train Loss: 0.04821532379214584\n",
      "-----------EPOCH-----------    ----->  507\n",
      "Train Loss: 0.048208949215147935\n",
      "-----------EPOCH-----------    ----->  508\n",
      "Train Loss: 0.04820258781182592\n",
      "-----------EPOCH-----------    ----->  509\n",
      "Train Loss: 0.048196243034359036\n",
      "-----------EPOCH-----------    ----->  510\n",
      "Train Loss: 0.04818991801553328\n",
      "-----------EPOCH-----------    ----->  511\n",
      "Train Loss: 0.04818360767367392\n",
      "-----------EPOCH-----------    ----->  512\n",
      "Train Loss: 0.04817732344686472\n",
      "-----------EPOCH-----------    ----->  513\n",
      "Train Loss: 0.04817106297832041\n",
      "-----------EPOCH-----------    ----->  514\n",
      "Train Loss: 0.048164806419142066\n",
      "-----------EPOCH-----------    ----->  515\n",
      "Train Loss: 0.04815857367157523\n",
      "-----------EPOCH-----------    ----->  516\n",
      "Train Loss: 0.048152367075899365\n",
      "-----------EPOCH-----------    ----->  517\n",
      "Train Loss: 0.04814618477527137\n",
      "-----------EPOCH-----------    ----->  518\n",
      "Train Loss: 0.04814001396603874\n",
      "-----------EPOCH-----------    ----->  519\n",
      "Train Loss: 0.048133859813729786\n",
      "-----------EPOCH-----------    ----->  520\n",
      "Train Loss: 0.04812773097360385\n",
      "-----------EPOCH-----------    ----->  521\n",
      "Train Loss: 0.048121626258041665\n",
      "-----------EPOCH-----------    ----->  522\n",
      "Train Loss: 0.04811554346533086\n",
      "-----------EPOCH-----------    ----->  523\n",
      "Train Loss: 0.04810949031545304\n",
      "-----------EPOCH-----------    ----->  524\n",
      "Train Loss: 0.04810345566432297\n",
      "-----------EPOCH-----------    ----->  525\n",
      "Train Loss: 0.048097434515388074\n",
      "-----------EPOCH-----------    ----->  526\n",
      "Train Loss: 0.04809142837228968\n",
      "-----------EPOCH-----------    ----->  527\n",
      "Train Loss: 0.04808543507163151\n",
      "-----------EPOCH-----------    ----->  528\n",
      "Train Loss: 0.04807945670105951\n",
      "-----------EPOCH-----------    ----->  529\n",
      "Train Loss: 0.04807348169727163\n",
      "-----------EPOCH-----------    ----->  530\n",
      "Train Loss: 0.04806753200460532\n",
      "-----------EPOCH-----------    ----->  531\n",
      "Train Loss: 0.048061609450457225\n",
      "-----------EPOCH-----------    ----->  532\n",
      "Train Loss: 0.04805570741111169\n",
      "-----------EPOCH-----------    ----->  533\n",
      "Train Loss: 0.04804982393446801\n",
      "-----------EPOCH-----------    ----->  534\n",
      "Train Loss: 0.04804394823656512\n",
      "-----------EPOCH-----------    ----->  535\n",
      "Train Loss: 0.04803809031464659\n",
      "-----------EPOCH-----------    ----->  536\n",
      "Train Loss: 0.0480322491977742\n",
      "-----------EPOCH-----------    ----->  537\n",
      "Train Loss: 0.04802640553934298\n",
      "-----------EPOCH-----------    ----->  538\n",
      "Train Loss: 0.04802054365131836\n",
      "-----------EPOCH-----------    ----->  539\n",
      "Train Loss: 0.048014698247882535\n",
      "-----------EPOCH-----------    ----->  540\n",
      "Train Loss: 0.04800886988817902\n",
      "-----------EPOCH-----------    ----->  541\n",
      "Train Loss: 0.048003058862412434\n",
      "-----------EPOCH-----------    ----->  542\n",
      "Train Loss: 0.047997258806664694\n",
      "-----------EPOCH-----------    ----->  543\n",
      "Train Loss: 0.04799147967149131\n",
      "-----------EPOCH-----------    ----->  544\n",
      "Train Loss: 0.04798571894344889\n",
      "-----------EPOCH-----------    ----->  545\n",
      "Train Loss: 0.04797996669563206\n",
      "-----------EPOCH-----------    ----->  546\n",
      "Train Loss: 0.04797422326223083\n",
      "-----------EPOCH-----------    ----->  547\n",
      "Train Loss: 0.04796849393425895\n",
      "-----------EPOCH-----------    ----->  548\n",
      "Train Loss: 0.04796278489499491\n",
      "-----------EPOCH-----------    ----->  549\n",
      "Train Loss: 0.047957094635167244\n",
      "-----------EPOCH-----------    ----->  550\n",
      "Train Loss: 0.047951423582641074\n",
      "-----------EPOCH-----------    ----->  551\n",
      "Train Loss: 0.0479457707934962\n",
      "-----------EPOCH-----------    ----->  552\n",
      "Train Loss: 0.04794013904267729\n",
      "-----------EPOCH-----------    ----->  553\n",
      "Train Loss: 0.04793452518155727\n",
      "-----------EPOCH-----------    ----->  554\n",
      "Train Loss: 0.04792893029226297\n",
      "-----------EPOCH-----------    ----->  555\n",
      "Train Loss: 0.047923358390128304\n",
      "-----------EPOCH-----------    ----->  556\n",
      "Train Loss: 0.04791780658711371\n",
      "-----------EPOCH-----------    ----->  557\n",
      "Train Loss: 0.04791226521117595\n",
      "-----------EPOCH-----------    ----->  558\n",
      "Train Loss: 0.04790674133141488\n",
      "-----------EPOCH-----------    ----->  559\n",
      "Train Loss: 0.04790121957473541\n",
      "-----------EPOCH-----------    ----->  560\n",
      "Train Loss: 0.047895712692132934\n",
      "-----------EPOCH-----------    ----->  561\n",
      "Train Loss: 0.04789022453226081\n",
      "-----------EPOCH-----------    ----->  562\n",
      "Train Loss: 0.04788475370414761\n",
      "-----------EPOCH-----------    ----->  563\n",
      "Train Loss: 0.04787930085374636\n",
      "-----------EPOCH-----------    ----->  564\n",
      "Train Loss: 0.04787387085939199\n",
      "-----------EPOCH-----------    ----->  565\n",
      "Train Loss: 0.04786843972650262\n",
      "-----------EPOCH-----------    ----->  566\n",
      "Train Loss: 0.047863024123097564\n",
      "-----------EPOCH-----------    ----->  567\n",
      "Train Loss: 0.047857630761025415\n",
      "-----------EPOCH-----------    ----->  568\n",
      "Train Loss: 0.04785225843089414\n",
      "-----------EPOCH-----------    ----->  569\n",
      "Train Loss: 0.047846901090575045\n",
      "-----------EPOCH-----------    ----->  570\n",
      "Train Loss: 0.047841563895088\n",
      "-----------EPOCH-----------    ----->  571\n",
      "Train Loss: 0.04783624437920716\n",
      "-----------EPOCH-----------    ----->  572\n",
      "Train Loss: 0.04783094312721503\n",
      "-----------EPOCH-----------    ----->  573\n",
      "Train Loss: 0.04782565345726629\n",
      "-----------EPOCH-----------    ----->  574\n",
      "Train Loss: 0.047820378228403994\n",
      "-----------EPOCH-----------    ----->  575\n",
      "Train Loss: 0.047815121876437716\n",
      "-----------EPOCH-----------    ----->  576\n",
      "Train Loss: 0.04780988302523943\n",
      "-----------EPOCH-----------    ----->  577\n",
      "Train Loss: 0.04780466412444134\n",
      "-----------EPOCH-----------    ----->  578\n",
      "Train Loss: 0.04779946033982968\n",
      "-----------EPOCH-----------    ----->  579\n",
      "Train Loss: 0.047794269535379914\n",
      "-----------EPOCH-----------    ----->  580\n",
      "Train Loss: 0.04778908411451352\n",
      "-----------EPOCH-----------    ----->  581\n",
      "Train Loss: 0.047783915739423664\n",
      "-----------EPOCH-----------    ----->  582\n",
      "Train Loss: 0.04777876187921851\n",
      "-----------EPOCH-----------    ----->  583\n",
      "Train Loss: 0.04777361294325293\n",
      "-----------EPOCH-----------    ----->  584\n",
      "Train Loss: 0.047768472392935434\n",
      "-----------EPOCH-----------    ----->  585\n",
      "Train Loss: 0.04776334849832845\n",
      "-----------EPOCH-----------    ----->  586\n",
      "Train Loss: 0.0477582356656169\n",
      "-----------EPOCH-----------    ----->  587\n",
      "Train Loss: 0.04775313668082717\n",
      "-----------EPOCH-----------    ----->  588\n",
      "Train Loss: 0.047748054804679176\n",
      "-----------EPOCH-----------    ----->  589\n",
      "Train Loss: 0.04774297924292549\n",
      "-----------EPOCH-----------    ----->  590\n",
      "Train Loss: 0.04773790911849329\n",
      "-----------EPOCH-----------    ----->  591\n",
      "Train Loss: 0.04773285099488185\n",
      "-----------EPOCH-----------    ----->  592\n",
      "Train Loss: 0.04772780370224845\n",
      "-----------EPOCH-----------    ----->  593\n",
      "Train Loss: 0.04772276798614593\n",
      "-----------EPOCH-----------    ----->  594\n",
      "Train Loss: 0.04771774268969596\n",
      "-----------EPOCH-----------    ----->  595\n",
      "Train Loss: 0.04771273397732763\n",
      "-----------EPOCH-----------    ----->  596\n",
      "Train Loss: 0.047707737571078095\n",
      "-----------EPOCH-----------    ----->  597\n",
      "Train Loss: 0.04770275077537883\n",
      "-----------EPOCH-----------    ----->  598\n",
      "Train Loss: 0.04769777605977549\n",
      "-----------EPOCH-----------    ----->  599\n",
      "Train Loss: 0.04769281575352695\n",
      "-----------EPOCH-----------    ----->  600\n",
      "Train Loss: 0.04768786705905449\n",
      "-----------EPOCH-----------    ----->  601\n",
      "Train Loss: 0.04768292718370885\n",
      "-----------EPOCH-----------    ----->  602\n",
      "Train Loss: 0.047677993117951206\n",
      "-----------EPOCH-----------    ----->  603\n",
      "Train Loss: 0.04767306860244014\n",
      "-----------EPOCH-----------    ----->  604\n",
      "Train Loss: 0.04766815310513734\n",
      "-----------EPOCH-----------    ----->  605\n",
      "Train Loss: 0.047663246715749764\n",
      "-----------EPOCH-----------    ----->  606\n",
      "Train Loss: 0.04765834102142185\n",
      "-----------EPOCH-----------    ----->  607\n",
      "Train Loss: 0.04765344559242505\n",
      "-----------EPOCH-----------    ----->  608\n",
      "Train Loss: 0.04764854881649282\n",
      "-----------EPOCH-----------    ----->  609\n",
      "Train Loss: 0.047643646540060244\n",
      "-----------EPOCH-----------    ----->  610\n",
      "Train Loss: 0.04763874782515684\n",
      "-----------EPOCH-----------    ----->  611\n",
      "Train Loss: 0.04763385136914542\n",
      "-----------EPOCH-----------    ----->  612\n",
      "Train Loss: 0.04762895771677085\n",
      "-----------EPOCH-----------    ----->  613\n",
      "Train Loss: 0.047624067973970896\n",
      "-----------EPOCH-----------    ----->  614\n",
      "Train Loss: 0.04761919147559319\n",
      "-----------EPOCH-----------    ----->  615\n",
      "Train Loss: 0.047614325653301544\n",
      "-----------EPOCH-----------    ----->  616\n",
      "Train Loss: 0.04760946230824045\n",
      "-----------EPOCH-----------    ----->  617\n",
      "Train Loss: 0.04760459754628025\n",
      "-----------EPOCH-----------    ----->  618\n",
      "Train Loss: 0.04759974077790054\n",
      "-----------EPOCH-----------    ----->  619\n",
      "Train Loss: 0.047594895303214195\n",
      "-----------EPOCH-----------    ----->  620\n",
      "Train Loss: 0.047590059323237274\n",
      "-----------EPOCH-----------    ----->  621\n",
      "Train Loss: 0.04758523698268777\n",
      "-----------EPOCH-----------    ----->  622\n",
      "Train Loss: 0.047580435178125845\n",
      "-----------EPOCH-----------    ----->  623\n",
      "Train Loss: 0.04757564871205282\n",
      "-----------EPOCH-----------    ----->  624\n",
      "Train Loss: 0.047570873986460066\n",
      "-----------EPOCH-----------    ----->  625\n",
      "Train Loss: 0.047566108571090705\n",
      "-----------EPOCH-----------    ----->  626\n",
      "Train Loss: 0.04756134859652478\n",
      "-----------EPOCH-----------    ----->  627\n",
      "Train Loss: 0.04755661159317217\n",
      "-----------EPOCH-----------    ----->  628\n",
      "Train Loss: 0.0475518928502046\n",
      "-----------EPOCH-----------    ----->  629\n",
      "Train Loss: 0.04754718875271515\n",
      "-----------EPOCH-----------    ----->  630\n",
      "Train Loss: 0.047542498691291624\n",
      "-----------EPOCH-----------    ----->  631\n",
      "Train Loss: 0.04753781564193064\n",
      "-----------EPOCH-----------    ----->  632\n",
      "Train Loss: 0.04753313644578582\n",
      "-----------EPOCH-----------    ----->  633\n",
      "Train Loss: 0.04752846610953291\n",
      "-----------EPOCH-----------    ----->  634\n",
      "Train Loss: 0.04752380065009155\n",
      "-----------EPOCH-----------    ----->  635\n",
      "Train Loss: 0.04751914035227836\n",
      "-----------EPOCH-----------    ----->  636\n",
      "Train Loss: 0.04751449014347676\n",
      "-----------EPOCH-----------    ----->  637\n",
      "Train Loss: 0.047509846658772004\n",
      "-----------EPOCH-----------    ----->  638\n",
      "Train Loss: 0.047505210351514025\n",
      "-----------EPOCH-----------    ----->  639\n",
      "Train Loss: 0.04750058538799322\n",
      "-----------EPOCH-----------    ----->  640\n",
      "Train Loss: 0.04749597260415219\n",
      "-----------EPOCH-----------    ----->  641\n",
      "Train Loss: 0.04749137016545237\n",
      "-----------EPOCH-----------    ----->  642\n",
      "Train Loss: 0.047486775539414335\n",
      "-----------EPOCH-----------    ----->  643\n",
      "Train Loss: 0.04748219114069818\n",
      "-----------EPOCH-----------    ----->  644\n",
      "Train Loss: 0.047477612059524936\n",
      "-----------EPOCH-----------    ----->  645\n",
      "Train Loss: 0.04747303918542806\n",
      "-----------EPOCH-----------    ----->  646\n",
      "Train Loss: 0.04746847356264569\n",
      "-----------EPOCH-----------    ----->  647\n",
      "Train Loss: 0.047463916604472835\n",
      "-----------EPOCH-----------    ----->  648\n",
      "Train Loss: 0.04745937255049874\n",
      "-----------EPOCH-----------    ----->  649\n",
      "Train Loss: 0.04745484067222075\n",
      "-----------EPOCH-----------    ----->  650\n",
      "Train Loss: 0.047450317736592966\n",
      "-----------EPOCH-----------    ----->  651\n",
      "Train Loss: 0.04744580697856426\n",
      "-----------EPOCH-----------    ----->  652\n",
      "Train Loss: 0.047441314597936546\n",
      "-----------EPOCH-----------    ----->  653\n",
      "Train Loss: 0.04743683946001622\n",
      "-----------EPOCH-----------    ----->  654\n",
      "Train Loss: 0.047432381104936534\n",
      "-----------EPOCH-----------    ----->  655\n",
      "Train Loss: 0.047427932367831695\n",
      "-----------EPOCH-----------    ----->  656\n",
      "Train Loss: 0.04742349284040241\n",
      "-----------EPOCH-----------    ----->  657\n",
      "Train Loss: 0.04741906033073435\n",
      "-----------EPOCH-----------    ----->  658\n",
      "Train Loss: 0.047414638226213744\n",
      "-----------EPOCH-----------    ----->  659\n",
      "Train Loss: 0.04741022389564904\n",
      "-----------EPOCH-----------    ----->  660\n",
      "Train Loss: 0.047405809714159794\n",
      "-----------EPOCH-----------    ----->  661\n",
      "Train Loss: 0.0474014007632209\n",
      "-----------EPOCH-----------    ----->  662\n",
      "Train Loss: 0.047397001867588745\n",
      "-----------EPOCH-----------    ----->  663\n",
      "Train Loss: 0.0473926136739545\n",
      "-----------EPOCH-----------    ----->  664\n",
      "Train Loss: 0.04738823756847188\n",
      "-----------EPOCH-----------    ----->  665\n",
      "Train Loss: 0.047383871287251855\n",
      "-----------EPOCH-----------    ----->  666\n",
      "Train Loss: 0.047379510678891235\n",
      "-----------EPOCH-----------    ----->  667\n",
      "Train Loss: 0.04737515836588213\n",
      "-----------EPOCH-----------    ----->  668\n",
      "Train Loss: 0.04737081798465164\n",
      "-----------EPOCH-----------    ----->  669\n",
      "Train Loss: 0.04736649127287755\n",
      "-----------EPOCH-----------    ----->  670\n",
      "Train Loss: 0.04736218009315443\n",
      "-----------EPOCH-----------    ----->  671\n",
      "Train Loss: 0.04735787719160965\n",
      "-----------EPOCH-----------    ----->  672\n",
      "Train Loss: 0.04735358116277658\n",
      "-----------EPOCH-----------    ----->  673\n",
      "Train Loss: 0.04734929710935472\n",
      "-----------EPOCH-----------    ----->  674\n",
      "Train Loss: 0.047345013651017544\n",
      "-----------EPOCH-----------    ----->  675\n",
      "Train Loss: 0.047340741300604464\n",
      "-----------EPOCH-----------    ----->  676\n",
      "Train Loss: 0.047336484043167905\n",
      "-----------EPOCH-----------    ----->  677\n",
      "Train Loss: 0.04733224473666092\n",
      "-----------EPOCH-----------    ----->  678\n",
      "Train Loss: 0.04732801508478366\n",
      "-----------EPOCH-----------    ----->  679\n",
      "Train Loss: 0.0473237826979973\n",
      "-----------EPOCH-----------    ----->  680\n",
      "Train Loss: 0.047319559631973665\n",
      "-----------EPOCH-----------    ----->  681\n",
      "Train Loss: 0.04731534589851708\n",
      "-----------EPOCH-----------    ----->  682\n",
      "Train Loss: 0.04731114052433033\n",
      "-----------EPOCH-----------    ----->  683\n",
      "Train Loss: 0.047306943266881785\n",
      "-----------EPOCH-----------    ----->  684\n",
      "Train Loss: 0.047302745141114724\n",
      "-----------EPOCH-----------    ----->  685\n",
      "Train Loss: 0.047298554003727816\n",
      "-----------EPOCH-----------    ----->  686\n",
      "Train Loss: 0.04729436729198241\n",
      "-----------EPOCH-----------    ----->  687\n",
      "Train Loss: 0.04729017841472652\n",
      "-----------EPOCH-----------    ----->  688\n",
      "Train Loss: 0.04728598389277249\n",
      "-----------EPOCH-----------    ----->  689\n",
      "Train Loss: 0.04728178006369238\n",
      "-----------EPOCH-----------    ----->  690\n",
      "Train Loss: 0.04727757953760887\n",
      "-----------EPOCH-----------    ----->  691\n",
      "Train Loss: 0.04727337774261717\n",
      "-----------EPOCH-----------    ----->  692\n",
      "Train Loss: 0.04726917108178512\n",
      "-----------EPOCH-----------    ----->  693\n",
      "Train Loss: 0.047264971919883485\n",
      "-----------EPOCH-----------    ----->  694\n",
      "Train Loss: 0.04726078116479184\n",
      "-----------EPOCH-----------    ----->  695\n",
      "Train Loss: 0.0472565977767766\n",
      "-----------EPOCH-----------    ----->  696\n",
      "Train Loss: 0.04725241514480819\n",
      "-----------EPOCH-----------    ----->  697\n",
      "Train Loss: 0.04724823762200561\n",
      "-----------EPOCH-----------    ----->  698\n",
      "Train Loss: 0.04724407172944357\n",
      "-----------EPOCH-----------    ----->  699\n",
      "Train Loss: 0.047239916702048884\n",
      "-----------EPOCH-----------    ----->  700\n",
      "Train Loss: 0.04723576760665587\n",
      "-----------EPOCH-----------    ----->  701\n",
      "Train Loss: 0.047231625534780636\n",
      "-----------EPOCH-----------    ----->  702\n",
      "Train Loss: 0.04722749280053552\n",
      "-----------EPOCH-----------    ----->  703\n",
      "Train Loss: 0.04722337212904723\n",
      "-----------EPOCH-----------    ----->  704\n",
      "Train Loss: 0.047219255962123\n",
      "-----------EPOCH-----------    ----->  705\n",
      "Train Loss: 0.04721514712903294\n",
      "-----------EPOCH-----------    ----->  706\n",
      "Train Loss: 0.047211042662036094\n",
      "-----------EPOCH-----------    ----->  707\n",
      "Train Loss: 0.04720694472463815\n",
      "-----------EPOCH-----------    ----->  708\n",
      "Train Loss: 0.047202849767665644\n",
      "-----------EPOCH-----------    ----->  709\n",
      "Train Loss: 0.04719876618495999\n",
      "-----------EPOCH-----------    ----->  710\n",
      "Train Loss: 0.047194692423399694\n",
      "-----------EPOCH-----------    ----->  711\n",
      "Train Loss: 0.04719062387892053\n",
      "-----------EPOCH-----------    ----->  712\n",
      "Train Loss: 0.047186538567116285\n",
      "-----------EPOCH-----------    ----->  713\n",
      "Train Loss: 0.047182457525986425\n",
      "-----------EPOCH-----------    ----->  714\n",
      "Train Loss: 0.04717838633482237\n",
      "-----------EPOCH-----------    ----->  715\n",
      "Train Loss: 0.04717432644925253\n",
      "-----------EPOCH-----------    ----->  716\n",
      "Train Loss: 0.04717027234769822\n",
      "-----------EPOCH-----------    ----->  717\n",
      "Train Loss: 0.04716622414864182\n",
      "-----------EPOCH-----------    ----->  718\n",
      "Train Loss: 0.0471621809951699\n",
      "-----------EPOCH-----------    ----->  719\n",
      "Train Loss: 0.04715814658416438\n",
      "-----------EPOCH-----------    ----->  720\n",
      "Train Loss: 0.04715411791833058\n",
      "-----------EPOCH-----------    ----->  721\n",
      "Train Loss: 0.04715009277910677\n",
      "-----------EPOCH-----------    ----->  722\n",
      "Train Loss: 0.04714607427988098\n",
      "-----------EPOCH-----------    ----->  723\n",
      "Train Loss: 0.047142066611421285\n",
      "-----------EPOCH-----------    ----->  724\n",
      "Train Loss: 0.04713806631880648\n",
      "-----------EPOCH-----------    ----->  725\n",
      "Train Loss: 0.047134072462634076\n",
      "-----------EPOCH-----------    ----->  726\n",
      "Train Loss: 0.047130087108332365\n",
      "-----------EPOCH-----------    ----->  727\n",
      "Train Loss: 0.047126108215026837\n",
      "-----------EPOCH-----------    ----->  728\n",
      "Train Loss: 0.04712214221288983\n",
      "-----------EPOCH-----------    ----->  729\n",
      "Train Loss: 0.04711818460256803\n",
      "-----------EPOCH-----------    ----->  730\n",
      "Train Loss: 0.047114228708359775\n",
      "-----------EPOCH-----------    ----->  731\n",
      "Train Loss: 0.04711027954099647\n",
      "-----------EPOCH-----------    ----->  732\n",
      "Train Loss: 0.04710633784297381\n",
      "-----------EPOCH-----------    ----->  733\n",
      "Train Loss: 0.04710240446426841\n",
      "-----------EPOCH-----------    ----->  734\n",
      "Train Loss: 0.04709846674153421\n",
      "-----------EPOCH-----------    ----->  735\n",
      "Train Loss: 0.04709453617897314\n",
      "-----------EPOCH-----------    ----->  736\n",
      "Train Loss: 0.04709061252843022\n",
      "-----------EPOCH-----------    ----->  737\n",
      "Train Loss: 0.04708670005859094\n",
      "-----------EPOCH-----------    ----->  738\n",
      "Train Loss: 0.04708279634936266\n",
      "-----------EPOCH-----------    ----->  739\n",
      "Train Loss: 0.04707889972898611\n",
      "-----------EPOCH-----------    ----->  740\n",
      "Train Loss: 0.04707500848021891\n",
      "-----------EPOCH-----------    ----->  741\n",
      "Train Loss: 0.04707112053768372\n",
      "-----------EPOCH-----------    ----->  742\n",
      "Train Loss: 0.04706724399026321\n",
      "-----------EPOCH-----------    ----->  743\n",
      "Train Loss: 0.04706337934436086\n",
      "-----------EPOCH-----------    ----->  744\n",
      "Train Loss: 0.04705952401665928\n",
      "-----------EPOCH-----------    ----->  745\n",
      "Train Loss: 0.047055674902930895\n",
      "-----------EPOCH-----------    ----->  746\n",
      "Train Loss: 0.047051830349584926\n",
      "-----------EPOCH-----------    ----->  747\n",
      "Train Loss: 0.04704799281210317\n",
      "-----------EPOCH-----------    ----->  748\n",
      "Train Loss: 0.047044162665887235\n",
      "-----------EPOCH-----------    ----->  749\n",
      "Train Loss: 0.04704033876133064\n",
      "-----------EPOCH-----------    ----->  750\n",
      "Train Loss: 0.047036520577919065\n",
      "-----------EPOCH-----------    ----->  751\n",
      "Train Loss: 0.04703270428732105\n",
      "-----------EPOCH-----------    ----->  752\n",
      "Train Loss: 0.04702889701509699\n",
      "-----------EPOCH-----------    ----->  753\n",
      "Train Loss: 0.04702509256092888\n",
      "-----------EPOCH-----------    ----->  754\n",
      "Train Loss: 0.04702129660994902\n",
      "-----------EPOCH-----------    ----->  755\n",
      "Train Loss: 0.04701751020354824\n",
      "-----------EPOCH-----------    ----->  756\n",
      "Train Loss: 0.04701373419585304\n",
      "-----------EPOCH-----------    ----->  757\n",
      "Train Loss: 0.04700996353054741\n",
      "-----------EPOCH-----------    ----->  758\n",
      "Train Loss: 0.04700619695846195\n",
      "-----------EPOCH-----------    ----->  759\n",
      "Train Loss: 0.04700243463680421\n",
      "-----------EPOCH-----------    ----->  760\n",
      "Train Loss: 0.046998678774957704\n",
      "-----------EPOCH-----------    ----->  761\n",
      "Train Loss: 0.04699492842407871\n",
      "-----------EPOCH-----------    ----->  762\n",
      "Train Loss: 0.04699117644211598\n",
      "-----------EPOCH-----------    ----->  763\n",
      "Train Loss: 0.04698742930692326\n",
      "-----------EPOCH-----------    ----->  764\n",
      "Train Loss: 0.04698368385540924\n",
      "-----------EPOCH-----------    ----->  765\n",
      "Train Loss: 0.04697994680226028\n",
      "-----------EPOCH-----------    ----->  766\n",
      "Train Loss: 0.046976217833554476\n",
      "-----------EPOCH-----------    ----->  767\n",
      "Train Loss: 0.046972498322514336\n",
      "-----------EPOCH-----------    ----->  768\n",
      "Train Loss: 0.04696877793674058\n",
      "-----------EPOCH-----------    ----->  769\n",
      "Train Loss: 0.04696506171717427\n",
      "-----------EPOCH-----------    ----->  770\n",
      "Train Loss: 0.046961349620176\n",
      "-----------EPOCH-----------    ----->  771\n",
      "Train Loss: 0.04695764194067612\n",
      "-----------EPOCH-----------    ----->  772\n",
      "Train Loss: 0.04695394467771339\n",
      "-----------EPOCH-----------    ----->  773\n",
      "Train Loss: 0.046950254573868505\n",
      "-----------EPOCH-----------    ----->  774\n",
      "Train Loss: 0.046946565393932126\n",
      "-----------EPOCH-----------    ----->  775\n",
      "Train Loss: 0.04694287667346215\n",
      "-----------EPOCH-----------    ----->  776\n",
      "Train Loss: 0.04693919669171562\n",
      "-----------EPOCH-----------    ----->  777\n",
      "Train Loss: 0.046935518795004565\n",
      "-----------EPOCH-----------    ----->  778\n",
      "Train Loss: 0.04693184564083893\n",
      "-----------EPOCH-----------    ----->  779\n",
      "Train Loss: 0.04692817705555883\n",
      "-----------EPOCH-----------    ----->  780\n",
      "Train Loss: 0.04692451381580088\n",
      "-----------EPOCH-----------    ----->  781\n",
      "Train Loss: 0.046920856720120085\n",
      "-----------EPOCH-----------    ----->  782\n",
      "Train Loss: 0.04691720740967797\n",
      "-----------EPOCH-----------    ----->  783\n",
      "Train Loss: 0.04691356480783828\n",
      "-----------EPOCH-----------    ----->  784\n",
      "Train Loss: 0.04690992911820052\n",
      "-----------EPOCH-----------    ----->  785\n",
      "Train Loss: 0.04690629743646686\n",
      "-----------EPOCH-----------    ----->  786\n",
      "Train Loss: 0.04690266841170652\n",
      "-----------EPOCH-----------    ----->  787\n",
      "Train Loss: 0.04689903279351173\n",
      "-----------EPOCH-----------    ----->  788\n",
      "Train Loss: 0.04689540054027314\n",
      "-----------EPOCH-----------    ----->  789\n",
      "Train Loss: 0.04689177625488923\n",
      "-----------EPOCH-----------    ----->  790\n",
      "Train Loss: 0.04688815125598983\n",
      "-----------EPOCH-----------    ----->  791\n",
      "Train Loss: 0.04688452944815841\n",
      "-----------EPOCH-----------    ----->  792\n",
      "Train Loss: 0.046880915782451446\n",
      "-----------EPOCH-----------    ----->  793\n",
      "Train Loss: 0.046877309910711686\n",
      "-----------EPOCH-----------    ----->  794\n",
      "Train Loss: 0.04687371104287636\n",
      "-----------EPOCH-----------    ----->  795\n",
      "Train Loss: 0.04687011208076823\n",
      "-----------EPOCH-----------    ----->  796\n",
      "Train Loss: 0.04686652131754932\n",
      "-----------EPOCH-----------    ----->  797\n",
      "Train Loss: 0.04686294017310247\n",
      "-----------EPOCH-----------    ----->  798\n",
      "Train Loss: 0.04685936734142646\n",
      "-----------EPOCH-----------    ----->  799\n",
      "Train Loss: 0.04685580089156057\n",
      "-----------EPOCH-----------    ----->  800\n",
      "Train Loss: 0.04685223923622303\n",
      "-----------EPOCH-----------    ----->  801\n",
      "Train Loss: 0.046848684362948576\n",
      "-----------EPOCH-----------    ----->  802\n",
      "Train Loss: 0.04684513320679446\n",
      "-----------EPOCH-----------    ----->  803\n",
      "Train Loss: 0.046841586802581506\n",
      "-----------EPOCH-----------    ----->  804\n",
      "Train Loss: 0.04683804779524143\n",
      "-----------EPOCH-----------    ----->  805\n",
      "Train Loss: 0.0468345113983567\n",
      "-----------EPOCH-----------    ----->  806\n",
      "Train Loss: 0.046830978179879273\n",
      "-----------EPOCH-----------    ----->  807\n",
      "Train Loss: 0.046827447459640195\n",
      "-----------EPOCH-----------    ----->  808\n",
      "Train Loss: 0.04682392209383828\n",
      "-----------EPOCH-----------    ----->  809\n",
      "Train Loss: 0.046820401401973945\n",
      "-----------EPOCH-----------    ----->  810\n",
      "Train Loss: 0.046816884206267284\n",
      "-----------EPOCH-----------    ----->  811\n",
      "Train Loss: 0.04681337110520106\n",
      "-----------EPOCH-----------    ----->  812\n",
      "Train Loss: 0.04680986442502117\n",
      "-----------EPOCH-----------    ----->  813\n",
      "Train Loss: 0.04680636323024996\n",
      "-----------EPOCH-----------    ----->  814\n",
      "Train Loss: 0.04680287056989794\n",
      "-----------EPOCH-----------    ----->  815\n",
      "Train Loss: 0.046799383548150185\n",
      "-----------EPOCH-----------    ----->  816\n",
      "Train Loss: 0.04679589563827718\n",
      "-----------EPOCH-----------    ----->  817\n",
      "Train Loss: 0.04679241211868928\n",
      "-----------EPOCH-----------    ----->  818\n",
      "Train Loss: 0.04678893192407066\n",
      "-----------EPOCH-----------    ----->  819\n",
      "Train Loss: 0.04678545372400579\n",
      "-----------EPOCH-----------    ----->  820\n",
      "Train Loss: 0.04678197643637324\n",
      "-----------EPOCH-----------    ----->  821\n",
      "Train Loss: 0.046778502861347555\n",
      "-----------EPOCH-----------    ----->  822\n",
      "Train Loss: 0.04677502842656241\n",
      "-----------EPOCH-----------    ----->  823\n",
      "Train Loss: 0.04677155513925244\n",
      "-----------EPOCH-----------    ----->  824\n",
      "Train Loss: 0.046768083746959066\n",
      "-----------EPOCH-----------    ----->  825\n",
      "Train Loss: 0.0467646164904308\n",
      "-----------EPOCH-----------    ----->  826\n",
      "Train Loss: 0.046761155522053476\n",
      "-----------EPOCH-----------    ----->  827\n",
      "Train Loss: 0.04675769454112452\n",
      "-----------EPOCH-----------    ----->  828\n",
      "Train Loss: 0.04675425161770098\n",
      "-----------EPOCH-----------    ----->  829\n",
      "Train Loss: 0.04675081413566028\n",
      "-----------EPOCH-----------    ----->  830\n",
      "Train Loss: 0.046747381449470694\n",
      "-----------EPOCH-----------    ----->  831\n",
      "Train Loss: 0.046743955122889015\n",
      "-----------EPOCH-----------    ----->  832\n",
      "Train Loss: 0.046740533500182736\n",
      "-----------EPOCH-----------    ----->  833\n",
      "Train Loss: 0.04673711473373608\n",
      "-----------EPOCH-----------    ----->  834\n",
      "Train Loss: 0.046733699379833085\n",
      "-----------EPOCH-----------    ----->  835\n",
      "Train Loss: 0.046730291216954316\n",
      "-----------EPOCH-----------    ----->  836\n",
      "Train Loss: 0.04672688700282648\n",
      "-----------EPOCH-----------    ----->  837\n",
      "Train Loss: 0.04672348778393658\n",
      "-----------EPOCH-----------    ----->  838\n",
      "Train Loss: 0.04672009853626032\n",
      "-----------EPOCH-----------    ----->  839\n",
      "Train Loss: 0.04671671475321929\n",
      "-----------EPOCH-----------    ----->  840\n",
      "Train Loss: 0.046713337427693\n",
      "-----------EPOCH-----------    ----->  841\n",
      "Train Loss: 0.04670996584326512\n",
      "-----------EPOCH-----------    ----->  842\n",
      "Train Loss: 0.046706603501582684\n",
      "-----------EPOCH-----------    ----->  843\n",
      "Train Loss: 0.046703251797306417\n",
      "-----------EPOCH-----------    ----->  844\n",
      "Train Loss: 0.04669990344607711\n",
      "-----------EPOCH-----------    ----->  845\n",
      "Train Loss: 0.04669655706989287\n",
      "-----------EPOCH-----------    ----->  846\n",
      "Train Loss: 0.046693213932053015\n",
      "-----------EPOCH-----------    ----->  847\n",
      "Train Loss: 0.04668987537099333\n",
      "-----------EPOCH-----------    ----->  848\n",
      "Train Loss: 0.0466865385834108\n",
      "-----------EPOCH-----------    ----->  849\n",
      "Train Loss: 0.046683208059783675\n",
      "-----------EPOCH-----------    ----->  850\n",
      "Train Loss: 0.04667987752071665\n",
      "-----------EPOCH-----------    ----->  851\n",
      "Train Loss: 0.04667655557986345\n",
      "-----------EPOCH-----------    ----->  852\n",
      "Train Loss: 0.04667323563098621\n",
      "-----------EPOCH-----------    ----->  853\n",
      "Train Loss: 0.04666991374670606\n",
      "-----------EPOCH-----------    ----->  854\n",
      "Train Loss: 0.046666596724579755\n",
      "-----------EPOCH-----------    ----->  855\n",
      "Train Loss: 0.046663286377977745\n",
      "-----------EPOCH-----------    ----->  856\n",
      "Train Loss: 0.046659977596846494\n",
      "-----------EPOCH-----------    ----->  857\n",
      "Train Loss: 0.04665666897452897\n",
      "-----------EPOCH-----------    ----->  858\n",
      "Train Loss: 0.04665336871070817\n",
      "-----------EPOCH-----------    ----->  859\n",
      "Train Loss: 0.046650079798481375\n",
      "-----------EPOCH-----------    ----->  860\n",
      "Train Loss: 0.046646795455136426\n",
      "-----------EPOCH-----------    ----->  861\n",
      "Train Loss: 0.04664351691462856\n",
      "-----------EPOCH-----------    ----->  862\n",
      "Train Loss: 0.046640235954691404\n",
      "-----------EPOCH-----------    ----->  863\n",
      "Train Loss: 0.04663696410870065\n",
      "-----------EPOCH-----------    ----->  864\n",
      "Train Loss: 0.046633699417275944\n",
      "-----------EPOCH-----------    ----->  865\n",
      "Train Loss: 0.04663043340462335\n",
      "-----------EPOCH-----------    ----->  866\n",
      "Train Loss: 0.046627168216272996\n",
      "-----------EPOCH-----------    ----->  867\n",
      "Train Loss: 0.04662390584354448\n",
      "-----------EPOCH-----------    ----->  868\n",
      "Train Loss: 0.04662064950668659\n",
      "-----------EPOCH-----------    ----->  869\n",
      "Train Loss: 0.04661740009841396\n",
      "-----------EPOCH-----------    ----->  870\n",
      "Train Loss: 0.046614153338356494\n",
      "-----------EPOCH-----------    ----->  871\n",
      "Train Loss: 0.04661090790691432\n",
      "-----------EPOCH-----------    ----->  872\n",
      "Train Loss: 0.046607664876635285\n",
      "-----------EPOCH-----------    ----->  873\n",
      "Train Loss: 0.04660442537800438\n",
      "-----------EPOCH-----------    ----->  874\n",
      "Train Loss: 0.046601193770636144\n",
      "-----------EPOCH-----------    ----->  875\n",
      "Train Loss: 0.04659797036691965\n",
      "-----------EPOCH-----------    ----->  876\n",
      "Train Loss: 0.04659474942999586\n",
      "-----------EPOCH-----------    ----->  877\n",
      "Train Loss: 0.04659153362894328\n",
      "-----------EPOCH-----------    ----->  878\n",
      "Train Loss: 0.04658832022016767\n",
      "-----------EPOCH-----------    ----->  879\n",
      "Train Loss: 0.046585114483899445\n",
      "-----------EPOCH-----------    ----->  880\n",
      "Train Loss: 0.04658191384681487\n",
      "-----------EPOCH-----------    ----->  881\n",
      "Train Loss: 0.046578710941809605\n",
      "-----------EPOCH-----------    ----->  882\n",
      "Train Loss: 0.04657551029594089\n",
      "-----------EPOCH-----------    ----->  883\n",
      "Train Loss: 0.046572314291794266\n",
      "-----------EPOCH-----------    ----->  884\n",
      "Train Loss: 0.04656911774020472\n",
      "-----------EPOCH-----------    ----->  885\n",
      "Train Loss: 0.046565927686385\n",
      "-----------EPOCH-----------    ----->  886\n",
      "Train Loss: 0.04656274164416637\n",
      "-----------EPOCH-----------    ----->  887\n",
      "Train Loss: 0.046559558391586264\n",
      "-----------EPOCH-----------    ----->  888\n",
      "Train Loss: 0.04655637784220888\n",
      "-----------EPOCH-----------    ----->  889\n",
      "Train Loss: 0.04655319999681431\n",
      "-----------EPOCH-----------    ----->  890\n",
      "Train Loss: 0.04655002377137332\n",
      "-----------EPOCH-----------    ----->  891\n",
      "Train Loss: 0.046546852270802345\n",
      "-----------EPOCH-----------    ----->  892\n",
      "Train Loss: 0.04654368636730129\n",
      "-----------EPOCH-----------    ----->  893\n",
      "Train Loss: 0.04654051842016457\n",
      "-----------EPOCH-----------    ----->  894\n",
      "Train Loss: 0.04653735614633634\n",
      "-----------EPOCH-----------    ----->  895\n",
      "Train Loss: 0.04653419622190929\n",
      "-----------EPOCH-----------    ----->  896\n",
      "Train Loss: 0.04653104301712797\n",
      "-----------EPOCH-----------    ----->  897\n",
      "Train Loss: 0.04652789730844157\n",
      "-----------EPOCH-----------    ----->  898\n",
      "Train Loss: 0.04652475404495172\n",
      "-----------EPOCH-----------    ----->  899\n",
      "Train Loss: 0.046521615158602744\n",
      "-----------EPOCH-----------    ----->  900\n",
      "Train Loss: 0.04651847997919622\n",
      "-----------EPOCH-----------    ----->  901\n",
      "Train Loss: 0.04651534421379674\n",
      "-----------EPOCH-----------    ----->  902\n",
      "Train Loss: 0.046512213077704825\n",
      "-----------EPOCH-----------    ----->  903\n",
      "Train Loss: 0.046509084450449045\n",
      "-----------EPOCH-----------    ----->  904\n",
      "Train Loss: 0.0465059631432942\n",
      "-----------EPOCH-----------    ----->  905\n",
      "Train Loss: 0.04650284845008527\n",
      "-----------EPOCH-----------    ----->  906\n",
      "Train Loss: 0.04649973725228328\n",
      "-----------EPOCH-----------    ----->  907\n",
      "Train Loss: 0.046496628982973895\n",
      "-----------EPOCH-----------    ----->  908\n",
      "Train Loss: 0.04649352052271317\n",
      "-----------EPOCH-----------    ----->  909\n",
      "Train Loss: 0.04649041464854981\n",
      "-----------EPOCH-----------    ----->  910\n",
      "Train Loss: 0.046487306450521355\n",
      "-----------EPOCH-----------    ----->  911\n",
      "Train Loss: 0.04648419862248844\n",
      "-----------EPOCH-----------    ----->  912\n",
      "Train Loss: 0.046481093711394\n",
      "-----------EPOCH-----------    ----->  913\n",
      "Train Loss: 0.046477992731345126\n",
      "-----------EPOCH-----------    ----->  914\n",
      "Train Loss: 0.04647489506384062\n",
      "-----------EPOCH-----------    ----->  915\n",
      "Train Loss: 0.04647180247268353\n",
      "-----------EPOCH-----------    ----->  916\n",
      "Train Loss: 0.04646871841814913\n",
      "-----------EPOCH-----------    ----->  917\n",
      "Train Loss: 0.04646563997593058\n",
      "-----------EPOCH-----------    ----->  918\n",
      "Train Loss: 0.0464625595722575\n",
      "-----------EPOCH-----------    ----->  919\n",
      "Train Loss: 0.04645948501051163\n",
      "-----------EPOCH-----------    ----->  920\n",
      "Train Loss: 0.04645641659862225\n",
      "-----------EPOCH-----------    ----->  921\n",
      "Train Loss: 0.04645335689829168\n",
      "-----------EPOCH-----------    ----->  922\n",
      "Train Loss: 0.04645030272281287\n",
      "-----------EPOCH-----------    ----->  923\n",
      "Train Loss: 0.046447249825593714\n",
      "-----------EPOCH-----------    ----->  924\n",
      "Train Loss: 0.04644419750733389\n",
      "-----------EPOCH-----------    ----->  925\n",
      "Train Loss: 0.046441143914867894\n",
      "-----------EPOCH-----------    ----->  926\n",
      "Train Loss: 0.04643808849369554\n",
      "-----------EPOCH-----------    ----->  927\n",
      "Train Loss: 0.04643503035075352\n",
      "-----------EPOCH-----------    ----->  928\n",
      "Train Loss: 0.04643197714317616\n",
      "-----------EPOCH-----------    ----->  929\n",
      "Train Loss: 0.04642892562730106\n",
      "-----------EPOCH-----------    ----->  930\n",
      "Train Loss: 0.046425873901086205\n",
      "-----------EPOCH-----------    ----->  931\n",
      "Train Loss: 0.04642282585002139\n",
      "-----------EPOCH-----------    ----->  932\n",
      "Train Loss: 0.04641977855077566\n",
      "-----------EPOCH-----------    ----->  933\n",
      "Train Loss: 0.046416725544312525\n",
      "-----------EPOCH-----------    ----->  934\n",
      "Train Loss: 0.04641367569383414\n",
      "-----------EPOCH-----------    ----->  935\n",
      "Train Loss: 0.04641062827083288\n",
      "-----------EPOCH-----------    ----->  936\n",
      "Train Loss: 0.046407582669630014\n",
      "-----------EPOCH-----------    ----->  937\n",
      "Train Loss: 0.04640453886280107\n",
      "-----------EPOCH-----------    ----->  938\n",
      "Train Loss: 0.04640149520829734\n",
      "-----------EPOCH-----------    ----->  939\n",
      "Train Loss: 0.04639845175985992\n",
      "-----------EPOCH-----------    ----->  940\n",
      "Train Loss: 0.04639541144631082\n",
      "-----------EPOCH-----------    ----->  941\n",
      "Train Loss: 0.04639237616116161\n",
      "-----------EPOCH-----------    ----->  942\n",
      "Train Loss: 0.04638934611594604\n",
      "-----------EPOCH-----------    ----->  943\n",
      "Train Loss: 0.04638632008027253\n",
      "-----------EPOCH-----------    ----->  944\n",
      "Train Loss: 0.046383293363209274\n",
      "-----------EPOCH-----------    ----->  945\n",
      "Train Loss: 0.04638027047797711\n",
      "-----------EPOCH-----------    ----->  946\n",
      "Train Loss: 0.04637725364327642\n",
      "-----------EPOCH-----------    ----->  947\n",
      "Train Loss: 0.04637423810177835\n",
      "-----------EPOCH-----------    ----->  948\n",
      "Train Loss: 0.046371225010655326\n",
      "-----------EPOCH-----------    ----->  949\n",
      "Train Loss: 0.04636821525353804\n",
      "-----------EPOCH-----------    ----->  950\n",
      "Train Loss: 0.04636521049458457\n",
      "-----------EPOCH-----------    ----->  951\n",
      "Train Loss: 0.04636220782690517\n",
      "-----------EPOCH-----------    ----->  952\n",
      "Train Loss: 0.046359208343265235\n",
      "-----------EPOCH-----------    ----->  953\n",
      "Train Loss: 0.04635621249655926\n",
      "-----------EPOCH-----------    ----->  954\n",
      "Train Loss: 0.04635322157477852\n",
      "-----------EPOCH-----------    ----->  955\n",
      "Train Loss: 0.046350236330724444\n",
      "-----------EPOCH-----------    ----->  956\n",
      "Train Loss: 0.04634725904620174\n",
      "-----------EPOCH-----------    ----->  957\n",
      "Train Loss: 0.046344286128462635\n",
      "-----------EPOCH-----------    ----->  958\n",
      "Train Loss: 0.04634132048872399\n",
      "-----------EPOCH-----------    ----->  959\n",
      "Train Loss: 0.04633836571536422\n",
      "-----------EPOCH-----------    ----->  960\n",
      "Train Loss: 0.04633541446547434\n",
      "-----------EPOCH-----------    ----->  961\n",
      "Train Loss: 0.046332463297102396\n",
      "-----------EPOCH-----------    ----->  962\n",
      "Train Loss: 0.046329513391845635\n",
      "-----------EPOCH-----------    ----->  963\n",
      "Train Loss: 0.04632657039646627\n",
      "-----------EPOCH-----------    ----->  964\n",
      "Train Loss: 0.0463236310139901\n",
      "-----------EPOCH-----------    ----->  965\n",
      "Train Loss: 0.04632069279632492\n",
      "-----------EPOCH-----------    ----->  966\n",
      "Train Loss: 0.04631775863508847\n",
      "-----------EPOCH-----------    ----->  967\n",
      "Train Loss: 0.04631483240806653\n",
      "-----------EPOCH-----------    ----->  968\n",
      "Train Loss: 0.046311909404367996\n",
      "-----------EPOCH-----------    ----->  969\n",
      "Train Loss: 0.04630899010724864\n",
      "-----------EPOCH-----------    ----->  970\n",
      "Train Loss: 0.04630607350953994\n",
      "-----------EPOCH-----------    ----->  971\n",
      "Train Loss: 0.04630315967314567\n",
      "-----------EPOCH-----------    ----->  972\n",
      "Train Loss: 0.0463002462616946\n",
      "-----------EPOCH-----------    ----->  973\n",
      "Train Loss: 0.04629733776977954\n",
      "-----------EPOCH-----------    ----->  974\n",
      "Train Loss: 0.04629443390443806\n",
      "-----------EPOCH-----------    ----->  975\n",
      "Train Loss: 0.04629153253245917\n",
      "-----------EPOCH-----------    ----->  976\n",
      "Train Loss: 0.046288637783250916\n",
      "-----------EPOCH-----------    ----->  977\n",
      "Train Loss: 0.04628575079208449\n",
      "-----------EPOCH-----------    ----->  978\n",
      "Train Loss: 0.046282868223764526\n",
      "-----------EPOCH-----------    ----->  979\n",
      "Train Loss: 0.04627999002408427\n",
      "-----------EPOCH-----------    ----->  980\n",
      "Train Loss: 0.04627711447140644\n",
      "-----------EPOCH-----------    ----->  981\n",
      "Train Loss: 0.04627424237505473\n",
      "-----------EPOCH-----------    ----->  982\n",
      "Train Loss: 0.04627137714844655\n",
      "-----------EPOCH-----------    ----->  983\n",
      "Train Loss: 0.04626851846574432\n",
      "-----------EPOCH-----------    ----->  984\n",
      "Train Loss: 0.04626566205155672\n",
      "-----------EPOCH-----------    ----->  985\n",
      "Train Loss: 0.04626280836518289\n",
      "-----------EPOCH-----------    ----->  986\n",
      "Train Loss: 0.046259957256519046\n",
      "-----------EPOCH-----------    ----->  987\n",
      "Train Loss: 0.04625710859722237\n",
      "-----------EPOCH-----------    ----->  988\n",
      "Train Loss: 0.04625426156401341\n",
      "-----------EPOCH-----------    ----->  989\n",
      "Train Loss: 0.04625141462360585\n",
      "-----------EPOCH-----------    ----->  990\n",
      "Train Loss: 0.046248570350879516\n",
      "-----------EPOCH-----------    ----->  991\n",
      "Train Loss: 0.046245729625772884\n",
      "-----------EPOCH-----------    ----->  992\n",
      "Train Loss: 0.046242895021506525\n",
      "-----------EPOCH-----------    ----->  993\n",
      "Train Loss: 0.046240066270945596\n",
      "-----------EPOCH-----------    ----->  994\n",
      "Train Loss: 0.046237244572996675\n",
      "-----------EPOCH-----------    ----->  995\n",
      "Train Loss: 0.04623442561030365\n",
      "-----------EPOCH-----------    ----->  996\n",
      "Train Loss: 0.046231610627831494\n",
      "-----------EPOCH-----------    ----->  997\n",
      "Train Loss: 0.04622880159647826\n",
      "-----------EPOCH-----------    ----->  998\n",
      "Train Loss: 0.04622600028384137\n",
      "-----------EPOCH-----------    ----->  999\n",
      "Train Loss: 0.046223204702706557\n",
      "-----------EPOCH-----------    ----->  1000\n",
      "Train Loss: 0.04622041158160407\n",
      "-----------EPOCH-----------    ----->  1001\n",
      "Train Loss: 0.04621761793436629\n",
      "-----------EPOCH-----------    ----->  1002\n",
      "Train Loss: 0.046214824793338986\n",
      "-----------EPOCH-----------    ----->  1003\n",
      "Train Loss: 0.04621203432606136\n",
      "-----------EPOCH-----------    ----->  1004\n",
      "Train Loss: 0.04620924193472034\n",
      "-----------EPOCH-----------    ----->  1005\n",
      "Train Loss: 0.04620645280317729\n",
      "-----------EPOCH-----------    ----->  1006\n",
      "Train Loss: 0.04620366751370886\n",
      "-----------EPOCH-----------    ----->  1007\n",
      "Train Loss: 0.04620088236643966\n",
      "-----------EPOCH-----------    ----->  1008\n",
      "Train Loss: 0.04619809579343414\n",
      "-----------EPOCH-----------    ----->  1009\n",
      "Train Loss: 0.04619531236392801\n",
      "-----------EPOCH-----------    ----->  1010\n",
      "Train Loss: 0.046192530110916376\n",
      "-----------EPOCH-----------    ----->  1011\n",
      "Train Loss: 0.046189749214346876\n",
      "-----------EPOCH-----------    ----->  1012\n",
      "Train Loss: 0.046186969984746765\n",
      "-----------EPOCH-----------    ----->  1013\n",
      "Train Loss: 0.0461841926413218\n",
      "-----------EPOCH-----------    ----->  1014\n",
      "Train Loss: 0.04618142016281376\n",
      "-----------EPOCH-----------    ----->  1015\n",
      "Train Loss: 0.046178650368331964\n",
      "-----------EPOCH-----------    ----->  1016\n",
      "Train Loss: 0.046175884120302026\n",
      "-----------EPOCH-----------    ----->  1017\n",
      "Train Loss: 0.046173119565970325\n",
      "-----------EPOCH-----------    ----->  1018\n",
      "Train Loss: 0.04617035666115826\n",
      "-----------EPOCH-----------    ----->  1019\n",
      "Train Loss: 0.046167598164626\n",
      "-----------EPOCH-----------    ----->  1020\n",
      "Train Loss: 0.04616483825342514\n",
      "-----------EPOCH-----------    ----->  1021\n",
      "Train Loss: 0.04616208256433288\n",
      "-----------EPOCH-----------    ----->  1022\n",
      "Train Loss: 0.04615933305862872\n",
      "-----------EPOCH-----------    ----->  1023\n",
      "Train Loss: 0.04615659084521258\n",
      "-----------EPOCH-----------    ----->  1024\n",
      "Train Loss: 0.04615385198822789\n",
      "-----------EPOCH-----------    ----->  1025\n",
      "Train Loss: 0.04615111610651051\n",
      "-----------EPOCH-----------    ----->  1026\n",
      "Train Loss: 0.04614838570304325\n",
      "-----------EPOCH-----------    ----->  1027\n",
      "Train Loss: 0.04614565893418704\n",
      "-----------EPOCH-----------    ----->  1028\n",
      "Train Loss: 0.04614292914320364\n",
      "-----------EPOCH-----------    ----->  1029\n",
      "Train Loss: 0.04614020248313425\n",
      "-----------EPOCH-----------    ----->  1030\n",
      "Train Loss: 0.04613747855167631\n",
      "-----------EPOCH-----------    ----->  1031\n",
      "Train Loss: 0.04613475966446383\n",
      "-----------EPOCH-----------    ----->  1032\n",
      "Train Loss: 0.046132044412767824\n",
      "-----------EPOCH-----------    ----->  1033\n",
      "Train Loss: 0.04612932982525988\n",
      "-----------EPOCH-----------    ----->  1034\n",
      "Train Loss: 0.046126615098419865\n",
      "-----------EPOCH-----------    ----->  1035\n",
      "Train Loss: 0.04612390013545517\n",
      "-----------EPOCH-----------    ----->  1036\n",
      "Train Loss: 0.04612118823070954\n",
      "-----------EPOCH-----------    ----->  1037\n",
      "Train Loss: 0.04611848133136575\n",
      "-----------EPOCH-----------    ----->  1038\n",
      "Train Loss: 0.046115778036504886\n",
      "-----------EPOCH-----------    ----->  1039\n",
      "Train Loss: 0.04611307932089666\n",
      "-----------EPOCH-----------    ----->  1040\n",
      "Train Loss: 0.04611037841216907\n",
      "-----------EPOCH-----------    ----->  1041\n",
      "Train Loss: 0.04610768328810767\n",
      "-----------EPOCH-----------    ----->  1042\n",
      "Train Loss: 0.046104989789721565\n",
      "-----------EPOCH-----------    ----->  1043\n",
      "Train Loss: 0.0461022952398177\n",
      "-----------EPOCH-----------    ----->  1044\n",
      "Train Loss: 0.04609960429112633\n",
      "-----------EPOCH-----------    ----->  1045\n",
      "Train Loss: 0.046096911589190534\n",
      "-----------EPOCH-----------    ----->  1046\n",
      "Train Loss: 0.046094218300043135\n",
      "-----------EPOCH-----------    ----->  1047\n",
      "Train Loss: 0.04609152998609629\n",
      "-----------EPOCH-----------    ----->  1048\n",
      "Train Loss: 0.04608884575608755\n",
      "-----------EPOCH-----------    ----->  1049\n",
      "Train Loss: 0.04608616228992669\n",
      "-----------EPOCH-----------    ----->  1050\n",
      "Train Loss: 0.04608347636105742\n",
      "-----------EPOCH-----------    ----->  1051\n",
      "Train Loss: 0.04608079757672586\n",
      "-----------EPOCH-----------    ----->  1052\n",
      "Train Loss: 0.0460781160478963\n",
      "-----------EPOCH-----------    ----->  1053\n",
      "Train Loss: 0.04607543841683337\n",
      "-----------EPOCH-----------    ----->  1054\n",
      "Train Loss: 0.04607276371556053\n",
      "-----------EPOCH-----------    ----->  1055\n",
      "Train Loss: 0.04607009389425368\n",
      "-----------EPOCH-----------    ----->  1056\n",
      "Train Loss: 0.04606742771204076\n",
      "-----------EPOCH-----------    ----->  1057\n",
      "Train Loss: 0.04606476311861906\n",
      "-----------EPOCH-----------    ----->  1058\n",
      "Train Loss: 0.04606210217232437\n",
      "-----------EPOCH-----------    ----->  1059\n",
      "Train Loss: 0.04605944317706249\n",
      "-----------EPOCH-----------    ----->  1060\n",
      "Train Loss: 0.04605678717931108\n",
      "-----------EPOCH-----------    ----->  1061\n",
      "Train Loss: 0.04605413141746644\n",
      "-----------EPOCH-----------    ----->  1062\n",
      "Train Loss: 0.04605147804057121\n",
      "-----------EPOCH-----------    ----->  1063\n",
      "Train Loss: 0.04604882726968759\n",
      "-----------EPOCH-----------    ----->  1064\n",
      "Train Loss: 0.04604617806289087\n",
      "-----------EPOCH-----------    ----->  1065\n",
      "Train Loss: 0.046043530079323755\n",
      "-----------EPOCH-----------    ----->  1066\n",
      "Train Loss: 0.04604088690024564\n",
      "-----------EPOCH-----------    ----->  1067\n",
      "Train Loss: 0.04603825198588468\n",
      "-----------EPOCH-----------    ----->  1068\n",
      "Train Loss: 0.04603561865441943\n",
      "-----------EPOCH-----------    ----->  1069\n",
      "Train Loss: 0.04603298994081053\n",
      "-----------EPOCH-----------    ----->  1070\n",
      "Train Loss: 0.04603036680436814\n",
      "-----------EPOCH-----------    ----->  1071\n",
      "Train Loss: 0.04602774925599688\n",
      "-----------EPOCH-----------    ----->  1072\n",
      "Train Loss: 0.0460251357063106\n",
      "-----------EPOCH-----------    ----->  1073\n",
      "Train Loss: 0.04602252496328222\n",
      "-----------EPOCH-----------    ----->  1074\n",
      "Train Loss: 0.046019919187134405\n",
      "-----------EPOCH-----------    ----->  1075\n",
      "Train Loss: 0.046017318241622626\n",
      "-----------EPOCH-----------    ----->  1076\n",
      "Train Loss: 0.046014720283844505\n",
      "-----------EPOCH-----------    ----->  1077\n",
      "Train Loss: 0.04601211793643382\n",
      "-----------EPOCH-----------    ----->  1078\n",
      "Train Loss: 0.0460095033960205\n",
      "-----------EPOCH-----------    ----->  1079\n",
      "Train Loss: 0.04600688973557302\n",
      "-----------EPOCH-----------    ----->  1080\n",
      "Train Loss: 0.046004281444909395\n",
      "-----------EPOCH-----------    ----->  1081\n",
      "Train Loss: 0.046001677646941276\n",
      "-----------EPOCH-----------    ----->  1082\n",
      "Train Loss: 0.04599907570773561\n",
      "-----------EPOCH-----------    ----->  1083\n",
      "Train Loss: 0.04599647809942855\n",
      "-----------EPOCH-----------    ----->  1084\n",
      "Train Loss: 0.04599388555823159\n",
      "-----------EPOCH-----------    ----->  1085\n",
      "Train Loss: 0.045991296207611464\n",
      "-----------EPOCH-----------    ----->  1086\n",
      "Train Loss: 0.04598871147730376\n",
      "-----------EPOCH-----------    ----->  1087\n",
      "Train Loss: 0.04598612766030974\n",
      "-----------EPOCH-----------    ----->  1088\n",
      "Train Loss: 0.04598353734791156\n",
      "-----------EPOCH-----------    ----->  1089\n",
      "Train Loss: 0.045980946017635645\n",
      "-----------EPOCH-----------    ----->  1090\n",
      "Train Loss: 0.04597835802275725\n",
      "-----------EPOCH-----------    ----->  1091\n",
      "Train Loss: 0.04597577348758948\n",
      "-----------EPOCH-----------    ----->  1092\n",
      "Train Loss: 0.04597319193541665\n",
      "-----------EPOCH-----------    ----->  1093\n",
      "Train Loss: 0.045970614476162734\n",
      "-----------EPOCH-----------    ----->  1094\n",
      "Train Loss: 0.04596804218852813\n",
      "-----------EPOCH-----------    ----->  1095\n",
      "Train Loss: 0.04596547243369255\n",
      "-----------EPOCH-----------    ----->  1096\n",
      "Train Loss: 0.04596290596275201\n",
      "-----------EPOCH-----------    ----->  1097\n",
      "Train Loss: 0.04596033824573563\n",
      "-----------EPOCH-----------    ----->  1098\n",
      "Train Loss: 0.045957772695357856\n",
      "-----------EPOCH-----------    ----->  1099\n",
      "Train Loss: 0.045955206583112446\n",
      "-----------EPOCH-----------    ----->  1100\n",
      "Train Loss: 0.04595264454843016\n",
      "-----------EPOCH-----------    ----->  1101\n",
      "Train Loss: 0.04595008375134118\n",
      "-----------EPOCH-----------    ----->  1102\n",
      "Train Loss: 0.04594752395358856\n",
      "-----------EPOCH-----------    ----->  1103\n",
      "Train Loss: 0.045944968342383895\n",
      "-----------EPOCH-----------    ----->  1104\n",
      "Train Loss: 0.04594241492256842\n",
      "-----------EPOCH-----------    ----->  1105\n",
      "Train Loss: 0.045939866639187386\n",
      "-----------EPOCH-----------    ----->  1106\n",
      "Train Loss: 0.045937323018540706\n",
      "-----------EPOCH-----------    ----->  1107\n",
      "Train Loss: 0.045934782153491824\n",
      "-----------EPOCH-----------    ----->  1108\n",
      "Train Loss: 0.04593224783036\n",
      "-----------EPOCH-----------    ----->  1109\n",
      "Train Loss: 0.045929719117802914\n",
      "-----------EPOCH-----------    ----->  1110\n",
      "Train Loss: 0.04592719194791945\n",
      "-----------EPOCH-----------    ----->  1111\n",
      "Train Loss: 0.04592466280189379\n",
      "-----------EPOCH-----------    ----->  1112\n",
      "Train Loss: 0.0459221348068121\n",
      "-----------EPOCH-----------    ----->  1113\n",
      "Train Loss: 0.045919613251937316\n",
      "-----------EPOCH-----------    ----->  1114\n",
      "Train Loss: 0.0459170952886534\n",
      "-----------EPOCH-----------    ----->  1115\n",
      "Train Loss: 0.045914581901446073\n",
      "-----------EPOCH-----------    ----->  1116\n",
      "Train Loss: 0.04591207105521692\n",
      "-----------EPOCH-----------    ----->  1117\n",
      "Train Loss: 0.04590956118699517\n",
      "-----------EPOCH-----------    ----->  1118\n",
      "Train Loss: 0.045907053773580835\n",
      "-----------EPOCH-----------    ----->  1119\n",
      "Train Loss: 0.045904547437594\n",
      "-----------EPOCH-----------    ----->  1120\n",
      "Train Loss: 0.045902045437810485\n",
      "-----------EPOCH-----------    ----->  1121\n",
      "Train Loss: 0.0458995485253957\n",
      "-----------EPOCH-----------    ----->  1122\n",
      "Train Loss: 0.045897053373965845\n",
      "-----------EPOCH-----------    ----->  1123\n",
      "Train Loss: 0.04589456024099165\n",
      "-----------EPOCH-----------    ----->  1124\n",
      "Train Loss: 0.04589206899118438\n",
      "-----------EPOCH-----------    ----->  1125\n",
      "Train Loss: 0.04588957956099949\n",
      "-----------EPOCH-----------    ----->  1126\n",
      "Train Loss: 0.04588709390868773\n",
      "-----------EPOCH-----------    ----->  1127\n",
      "Train Loss: 0.04588461505870462\n",
      "-----------EPOCH-----------    ----->  1128\n",
      "Train Loss: 0.04588213938538608\n",
      "-----------EPOCH-----------    ----->  1129\n",
      "Train Loss: 0.045879664304891724\n",
      "-----------EPOCH-----------    ----->  1130\n",
      "Train Loss: 0.04587719092436316\n",
      "-----------EPOCH-----------    ----->  1131\n",
      "Train Loss: 0.04587472091545316\n",
      "-----------EPOCH-----------    ----->  1132\n",
      "Train Loss: 0.045872256325153814\n",
      "-----------EPOCH-----------    ----->  1133\n",
      "Train Loss: 0.045869798512566375\n",
      "-----------EPOCH-----------    ----->  1134\n",
      "Train Loss: 0.045867344411202014\n",
      "-----------EPOCH-----------    ----->  1135\n",
      "Train Loss: 0.04586489261854643\n",
      "-----------EPOCH-----------    ----->  1136\n",
      "Train Loss: 0.04586244120716658\n",
      "-----------EPOCH-----------    ----->  1137\n",
      "Train Loss: 0.04585998673131152\n",
      "-----------EPOCH-----------    ----->  1138\n",
      "Train Loss: 0.04585753773060997\n",
      "-----------EPOCH-----------    ----->  1139\n",
      "Train Loss: 0.04585509437814349\n",
      "-----------EPOCH-----------    ----->  1140\n",
      "Train Loss: 0.04585264998855248\n",
      "-----------EPOCH-----------    ----->  1141\n",
      "Train Loss: 0.045850203446138826\n",
      "-----------EPOCH-----------    ----->  1142\n",
      "Train Loss: 0.045847760532824036\n",
      "-----------EPOCH-----------    ----->  1143\n",
      "Train Loss: 0.04584532048284967\n",
      "-----------EPOCH-----------    ----->  1144\n",
      "Train Loss: 0.045842885097045774\n",
      "-----------EPOCH-----------    ----->  1145\n",
      "Train Loss: 0.04584045104957795\n",
      "-----------EPOCH-----------    ----->  1146\n",
      "Train Loss: 0.045838020678219855\n",
      "-----------EPOCH-----------    ----->  1147\n",
      "Train Loss: 0.04583558956798281\n",
      "-----------EPOCH-----------    ----->  1148\n",
      "Train Loss: 0.045833163927009604\n",
      "-----------EPOCH-----------    ----->  1149\n",
      "Train Loss: 0.04583074161883406\n",
      "-----------EPOCH-----------    ----->  1150\n",
      "Train Loss: 0.045828319164959566\n",
      "-----------EPOCH-----------    ----->  1151\n",
      "Train Loss: 0.04582589745122102\n",
      "-----------EPOCH-----------    ----->  1152\n",
      "Train Loss: 0.04582347861112625\n",
      "-----------EPOCH-----------    ----->  1153\n",
      "Train Loss: 0.045821067314706504\n",
      "-----------EPOCH-----------    ----->  1154\n",
      "Train Loss: 0.04581865809447592\n",
      "-----------EPOCH-----------    ----->  1155\n",
      "Train Loss: 0.04581625063194578\n",
      "-----------EPOCH-----------    ----->  1156\n",
      "Train Loss: 0.04581384155298098\n",
      "-----------EPOCH-----------    ----->  1157\n",
      "Train Loss: 0.04581143191344051\n",
      "-----------EPOCH-----------    ----->  1158\n",
      "Train Loss: 0.04580902379119076\n",
      "-----------EPOCH-----------    ----->  1159\n",
      "Train Loss: 0.045806614203151644\n",
      "-----------EPOCH-----------    ----->  1160\n",
      "Train Loss: 0.04580420363455641\n",
      "-----------EPOCH-----------    ----->  1161\n",
      "Train Loss: 0.0458017867029663\n",
      "-----------EPOCH-----------    ----->  1162\n",
      "Train Loss: 0.045799371803899674\n",
      "-----------EPOCH-----------    ----->  1163\n",
      "Train Loss: 0.04579696415297725\n",
      "-----------EPOCH-----------    ----->  1164\n",
      "Train Loss: 0.04579456222701362\n",
      "-----------EPOCH-----------    ----->  1165\n",
      "Train Loss: 0.045792166443689636\n",
      "-----------EPOCH-----------    ----->  1166\n",
      "Train Loss: 0.04578977366923937\n",
      "-----------EPOCH-----------    ----->  1167\n",
      "Train Loss: 0.04578738132326305\n",
      "-----------EPOCH-----------    ----->  1168\n",
      "Train Loss: 0.0457849934787388\n",
      "-----------EPOCH-----------    ----->  1169\n",
      "Train Loss: 0.04578261187072052\n",
      "-----------EPOCH-----------    ----->  1170\n",
      "Train Loss: 0.04578023369104063\n",
      "-----------EPOCH-----------    ----->  1171\n",
      "Train Loss: 0.04577785788275944\n",
      "-----------EPOCH-----------    ----->  1172\n",
      "Train Loss: 0.045775486141469604\n",
      "-----------EPOCH-----------    ----->  1173\n",
      "Train Loss: 0.04577311848314704\n",
      "-----------EPOCH-----------    ----->  1174\n",
      "Train Loss: 0.0457707530979327\n",
      "-----------EPOCH-----------    ----->  1175\n",
      "Train Loss: 0.04576838966812336\n",
      "-----------EPOCH-----------    ----->  1176\n",
      "Train Loss: 0.04576602889714931\n",
      "-----------EPOCH-----------    ----->  1177\n",
      "Train Loss: 0.04576367162113524\n",
      "-----------EPOCH-----------    ----->  1178\n",
      "Train Loss: 0.04576131021522089\n",
      "-----------EPOCH-----------    ----->  1179\n",
      "Train Loss: 0.04575895150360158\n",
      "-----------EPOCH-----------    ----->  1180\n",
      "Train Loss: 0.0457565948382223\n",
      "-----------EPOCH-----------    ----->  1181\n",
      "Train Loss: 0.04575423835099739\n",
      "-----------EPOCH-----------    ----->  1182\n",
      "Train Loss: 0.04575188781331869\n",
      "-----------EPOCH-----------    ----->  1183\n",
      "Train Loss: 0.0457495413430085\n",
      "-----------EPOCH-----------    ----->  1184\n",
      "Train Loss: 0.045747199274561695\n",
      "-----------EPOCH-----------    ----->  1185\n",
      "Train Loss: 0.045744859911656416\n",
      "-----------EPOCH-----------    ----->  1186\n",
      "Train Loss: 0.045742522937734634\n",
      "-----------EPOCH-----------    ----->  1187\n",
      "Train Loss: 0.045740188950409356\n",
      "-----------EPOCH-----------    ----->  1188\n",
      "Train Loss: 0.045737859272807165\n",
      "-----------EPOCH-----------    ----->  1189\n",
      "Train Loss: 0.045735534574950984\n",
      "-----------EPOCH-----------    ----->  1190\n",
      "Train Loss: 0.0457332139984608\n",
      "-----------EPOCH-----------    ----->  1191\n",
      "Train Loss: 0.04573090154615116\n",
      "-----------EPOCH-----------    ----->  1192\n",
      "Train Loss: 0.04572859197640647\n",
      "-----------EPOCH-----------    ----->  1193\n",
      "Train Loss: 0.04572628876065249\n",
      "-----------EPOCH-----------    ----->  1194\n",
      "Train Loss: 0.04572399110050574\n",
      "-----------EPOCH-----------    ----->  1195\n",
      "Train Loss: 0.04572169778253694\n",
      "-----------EPOCH-----------    ----->  1196\n",
      "Train Loss: 0.04571940794142445\n",
      "-----------EPOCH-----------    ----->  1197\n",
      "Train Loss: 0.04571711998198697\n",
      "-----------EPOCH-----------    ----->  1198\n",
      "Train Loss: 0.045714836973830796\n",
      "-----------EPOCH-----------    ----->  1199\n",
      "Train Loss: 0.04571255694180025\n",
      "-----------EPOCH-----------    ----->  1200\n",
      "Train Loss: 0.04571027631215404\n",
      "-----------EPOCH-----------    ----->  1201\n",
      "Train Loss: 0.04570800234319248\n",
      "-----------EPOCH-----------    ----->  1202\n",
      "Train Loss: 0.0457057320333187\n",
      "-----------EPOCH-----------    ----->  1203\n",
      "Train Loss: 0.045703462991981296\n",
      "-----------EPOCH-----------    ----->  1204\n",
      "Train Loss: 0.04570119796781163\n",
      "-----------EPOCH-----------    ----->  1205\n",
      "Train Loss: 0.04569893660437395\n",
      "-----------EPOCH-----------    ----->  1206\n",
      "Train Loss: 0.045696680205005245\n",
      "-----------EPOCH-----------    ----->  1207\n",
      "Train Loss: 0.04569442756778506\n",
      "-----------EPOCH-----------    ----->  1208\n",
      "Train Loss: 0.04569217595887253\n",
      "-----------EPOCH-----------    ----->  1209\n",
      "Train Loss: 0.04568992493444936\n",
      "-----------EPOCH-----------    ----->  1210\n",
      "Train Loss: 0.04568767630753573\n",
      "-----------EPOCH-----------    ----->  1211\n",
      "Train Loss: 0.04568543200122496\n",
      "-----------EPOCH-----------    ----->  1212\n",
      "Train Loss: 0.04568319098066526\n",
      "-----------EPOCH-----------    ----->  1213\n",
      "Train Loss: 0.04568094935242755\n",
      "-----------EPOCH-----------    ----->  1214\n",
      "Train Loss: 0.0456787118484319\n",
      "-----------EPOCH-----------    ----->  1215\n",
      "Train Loss: 0.04567647641665758\n",
      "-----------EPOCH-----------    ----->  1216\n",
      "Train Loss: 0.04567424341080034\n",
      "-----------EPOCH-----------    ----->  1217\n",
      "Train Loss: 0.04567201339367005\n",
      "-----------EPOCH-----------    ----->  1218\n",
      "Train Loss: 0.04566978550402077\n",
      "-----------EPOCH-----------    ----->  1219\n",
      "Train Loss: 0.04566756179909806\n",
      "-----------EPOCH-----------    ----->  1220\n",
      "Train Loss: 0.04566534377079181\n",
      "-----------EPOCH-----------    ----->  1221\n",
      "Train Loss: 0.045663127042565865\n",
      "-----------EPOCH-----------    ----->  1222\n",
      "Train Loss: 0.045660912503534115\n",
      "-----------EPOCH-----------    ----->  1223\n",
      "Train Loss: 0.045658699687027904\n",
      "-----------EPOCH-----------    ----->  1224\n",
      "Train Loss: 0.04565648913543761\n",
      "-----------EPOCH-----------    ----->  1225\n",
      "Train Loss: 0.04565428413741334\n",
      "-----------EPOCH-----------    ----->  1226\n",
      "Train Loss: 0.04565208446541033\n",
      "-----------EPOCH-----------    ----->  1227\n",
      "Train Loss: 0.04564988666120905\n",
      "-----------EPOCH-----------    ----->  1228\n",
      "Train Loss: 0.045647686857740746\n",
      "-----------EPOCH-----------    ----->  1229\n",
      "Train Loss: 0.04564548393011846\n",
      "-----------EPOCH-----------    ----->  1230\n",
      "Train Loss: 0.04564328284833393\n",
      "-----------EPOCH-----------    ----->  1231\n",
      "Train Loss: 0.04564108331355266\n",
      "-----------EPOCH-----------    ----->  1232\n",
      "Train Loss: 0.045638887449679116\n",
      "-----------EPOCH-----------    ----->  1233\n",
      "Train Loss: 0.045636695887296935\n",
      "-----------EPOCH-----------    ----->  1234\n",
      "Train Loss: 0.04563450513956675\n",
      "-----------EPOCH-----------    ----->  1235\n",
      "Train Loss: 0.04563231395274594\n",
      "-----------EPOCH-----------    ----->  1236\n",
      "Train Loss: 0.04563012202411549\n",
      "-----------EPOCH-----------    ----->  1237\n",
      "Train Loss: 0.045627931634624\n",
      "-----------EPOCH-----------    ----->  1238\n",
      "Train Loss: 0.045625745998636114\n",
      "-----------EPOCH-----------    ----->  1239\n",
      "Train Loss: 0.045623563115270944\n",
      "-----------EPOCH-----------    ----->  1240\n",
      "Train Loss: 0.04562138392151109\n",
      "-----------EPOCH-----------    ----->  1241\n",
      "Train Loss: 0.04561920807905981\n",
      "-----------EPOCH-----------    ----->  1242\n",
      "Train Loss: 0.04561703365066593\n",
      "-----------EPOCH-----------    ----->  1243\n",
      "Train Loss: 0.045614863091409226\n",
      "-----------EPOCH-----------    ----->  1244\n",
      "Train Loss: 0.04561269385184431\n",
      "-----------EPOCH-----------    ----->  1245\n",
      "Train Loss: 0.04561053152729779\n",
      "-----------EPOCH-----------    ----->  1246\n",
      "Train Loss: 0.04560837212612467\n",
      "-----------EPOCH-----------    ----->  1247\n",
      "Train Loss: 0.045606210889197224\n",
      "-----------EPOCH-----------    ----->  1248\n",
      "Train Loss: 0.045604053099835694\n",
      "-----------EPOCH-----------    ----->  1249\n",
      "Train Loss: 0.045601896047008796\n",
      "-----------EPOCH-----------    ----->  1250\n",
      "Train Loss: 0.04559974204861896\n",
      "-----------EPOCH-----------    ----->  1251\n",
      "Train Loss: 0.045597592482905236\n",
      "-----------EPOCH-----------    ----->  1252\n",
      "Train Loss: 0.04559544431855769\n",
      "-----------EPOCH-----------    ----->  1253\n",
      "Train Loss: 0.04559329609883991\n",
      "-----------EPOCH-----------    ----->  1254\n",
      "Train Loss: 0.04559114883448387\n",
      "-----------EPOCH-----------    ----->  1255\n",
      "Train Loss: 0.04558900144925179\n",
      "-----------EPOCH-----------    ----->  1256\n",
      "Train Loss: 0.045586854511409015\n",
      "-----------EPOCH-----------    ----->  1257\n",
      "Train Loss: 0.04558471270999768\n",
      "-----------EPOCH-----------    ----->  1258\n",
      "Train Loss: 0.04558257706126292\n",
      "-----------EPOCH-----------    ----->  1259\n",
      "Train Loss: 0.045580444335403696\n",
      "-----------EPOCH-----------    ----->  1260\n",
      "Train Loss: 0.04557831282317122\n",
      "-----------EPOCH-----------    ----->  1261\n",
      "Train Loss: 0.04557618238221863\n",
      "-----------EPOCH-----------    ----->  1262\n",
      "Train Loss: 0.045574051953425544\n",
      "-----------EPOCH-----------    ----->  1263\n",
      "Train Loss: 0.04557192143327743\n",
      "-----------EPOCH-----------    ----->  1264\n",
      "Train Loss: 0.045569796642560126\n",
      "-----------EPOCH-----------    ----->  1265\n",
      "Train Loss: 0.04556767716069458\n",
      "-----------EPOCH-----------    ----->  1266\n",
      "Train Loss: 0.04556555868602034\n",
      "-----------EPOCH-----------    ----->  1267\n",
      "Train Loss: 0.045563444761218916\n",
      "-----------EPOCH-----------    ----->  1268\n",
      "Train Loss: 0.045561333590959305\n",
      "-----------EPOCH-----------    ----->  1269\n",
      "Train Loss: 0.045559225006935725\n",
      "-----------EPOCH-----------    ----->  1270\n",
      "Train Loss: 0.045557118468388384\n",
      "-----------EPOCH-----------    ----->  1271\n",
      "Train Loss: 0.04555501322285987\n",
      "-----------EPOCH-----------    ----->  1272\n",
      "Train Loss: 0.04555290888522459\n",
      "-----------EPOCH-----------    ----->  1273\n",
      "Train Loss: 0.0455508049414901\n",
      "-----------EPOCH-----------    ----->  1274\n",
      "Train Loss: 0.04554870270597909\n",
      "-----------EPOCH-----------    ----->  1275\n",
      "Train Loss: 0.04554659826831453\n",
      "-----------EPOCH-----------    ----->  1276\n",
      "Train Loss: 0.04554450081361117\n",
      "-----------EPOCH-----------    ----->  1277\n",
      "Train Loss: 0.04554240745911135\n",
      "-----------EPOCH-----------    ----->  1278\n",
      "Train Loss: 0.04554031810588121\n",
      "-----------EPOCH-----------    ----->  1279\n",
      "Train Loss: 0.04553822723919269\n",
      "-----------EPOCH-----------    ----->  1280\n",
      "Train Loss: 0.045536135157772606\n",
      "-----------EPOCH-----------    ----->  1281\n",
      "Train Loss: 0.04553404669197095\n",
      "-----------EPOCH-----------    ----->  1282\n",
      "Train Loss: 0.04553196036504341\n",
      "-----------EPOCH-----------    ----->  1283\n",
      "Train Loss: 0.045529877626383705\n",
      "-----------EPOCH-----------    ----->  1284\n",
      "Train Loss: 0.045527795666945044\n",
      "-----------EPOCH-----------    ----->  1285\n",
      "Train Loss: 0.045525715331579175\n",
      "-----------EPOCH-----------    ----->  1286\n",
      "Train Loss: 0.04552363535945816\n",
      "-----------EPOCH-----------    ----->  1287\n",
      "Train Loss: 0.0455215541674119\n",
      "-----------EPOCH-----------    ----->  1288\n",
      "Train Loss: 0.04551947634183055\n",
      "-----------EPOCH-----------    ----->  1289\n",
      "Train Loss: 0.045517402334004906\n",
      "-----------EPOCH-----------    ----->  1290\n",
      "Train Loss: 0.04551532932529829\n",
      "-----------EPOCH-----------    ----->  1291\n",
      "Train Loss: 0.045513256882661994\n",
      "-----------EPOCH-----------    ----->  1292\n",
      "Train Loss: 0.045511188302248165\n",
      "-----------EPOCH-----------    ----->  1293\n",
      "Train Loss: 0.045509122996807226\n",
      "-----------EPOCH-----------    ----->  1294\n",
      "Train Loss: 0.045507057900955133\n",
      "-----------EPOCH-----------    ----->  1295\n",
      "Train Loss: 0.045504995438800204\n",
      "-----------EPOCH-----------    ----->  1296\n",
      "Train Loss: 0.04550293288047576\n",
      "-----------EPOCH-----------    ----->  1297\n",
      "Train Loss: 0.04550087076367195\n",
      "-----------EPOCH-----------    ----->  1298\n",
      "Train Loss: 0.045498809599429584\n",
      "-----------EPOCH-----------    ----->  1299\n",
      "Train Loss: 0.04549675174518131\n",
      "-----------EPOCH-----------    ----->  1300\n",
      "Train Loss: 0.04549469564562605\n",
      "-----------EPOCH-----------    ----->  1301\n",
      "Train Loss: 0.045492641476841816\n",
      "-----------EPOCH-----------    ----->  1302\n",
      "Train Loss: 0.045490589755870135\n",
      "-----------EPOCH-----------    ----->  1303\n",
      "Train Loss: 0.04548853819026031\n",
      "-----------EPOCH-----------    ----->  1304\n",
      "Train Loss: 0.045486486939558264\n",
      "-----------EPOCH-----------    ----->  1305\n",
      "Train Loss: 0.045484436600393405\n",
      "-----------EPOCH-----------    ----->  1306\n",
      "Train Loss: 0.045482385497313635\n",
      "-----------EPOCH-----------    ----->  1307\n",
      "Train Loss: 0.045480333749963166\n",
      "-----------EPOCH-----------    ----->  1308\n",
      "Train Loss: 0.045478280869643985\n",
      "-----------EPOCH-----------    ----->  1309\n",
      "Train Loss: 0.045476230090558546\n",
      "-----------EPOCH-----------    ----->  1310\n",
      "Train Loss: 0.04547417923728693\n",
      "-----------EPOCH-----------    ----->  1311\n",
      "Train Loss: 0.04547213110881156\n",
      "-----------EPOCH-----------    ----->  1312\n",
      "Train Loss: 0.045470087324498844\n",
      "-----------EPOCH-----------    ----->  1313\n",
      "Train Loss: 0.04546804355399569\n",
      "-----------EPOCH-----------    ----->  1314\n",
      "Train Loss: 0.04546600508510322\n",
      "-----------EPOCH-----------    ----->  1315\n",
      "Train Loss: 0.0454639690352107\n",
      "-----------EPOCH-----------    ----->  1316\n",
      "Train Loss: 0.045461935660979835\n",
      "-----------EPOCH-----------    ----->  1317\n",
      "Train Loss: 0.04545990639321607\n",
      "-----------EPOCH-----------    ----->  1318\n",
      "Train Loss: 0.04545787944511556\n",
      "-----------EPOCH-----------    ----->  1319\n",
      "Train Loss: 0.04545585203569827\n",
      "-----------EPOCH-----------    ----->  1320\n",
      "Train Loss: 0.0454538266400262\n",
      "-----------EPOCH-----------    ----->  1321\n",
      "Train Loss: 0.04545180333039116\n",
      "-----------EPOCH-----------    ----->  1322\n",
      "Train Loss: 0.0454497793842138\n",
      "-----------EPOCH-----------    ----->  1323\n",
      "Train Loss: 0.04544775674466114\n",
      "-----------EPOCH-----------    ----->  1324\n",
      "Train Loss: 0.04544573755036612\n",
      "-----------EPOCH-----------    ----->  1325\n",
      "Train Loss: 0.045443723000395\n",
      "-----------EPOCH-----------    ----->  1326\n",
      "Train Loss: 0.0454417111210738\n",
      "-----------EPOCH-----------    ----->  1327\n",
      "Train Loss: 0.045439705050727634\n",
      "-----------EPOCH-----------    ----->  1328\n",
      "Train Loss: 0.04543770191375053\n",
      "-----------EPOCH-----------    ----->  1329\n",
      "Train Loss: 0.045435701920819103\n",
      "-----------EPOCH-----------    ----->  1330\n",
      "Train Loss: 0.045433703830372325\n",
      "-----------EPOCH-----------    ----->  1331\n",
      "Train Loss: 0.04543170896537165\n",
      "-----------EPOCH-----------    ----->  1332\n",
      "Train Loss: 0.04542971661005204\n",
      "-----------EPOCH-----------    ----->  1333\n",
      "Train Loss: 0.0454277257217179\n",
      "-----------EPOCH-----------    ----->  1334\n",
      "Train Loss: 0.04542573427365108\n",
      "-----------EPOCH-----------    ----->  1335\n",
      "Train Loss: 0.04542374503202631\n",
      "-----------EPOCH-----------    ----->  1336\n",
      "Train Loss: 0.04542175636055769\n",
      "-----------EPOCH-----------    ----->  1337\n",
      "Train Loss: 0.04541976770564546\n",
      "-----------EPOCH-----------    ----->  1338\n",
      "Train Loss: 0.04541778246236858\n",
      "-----------EPOCH-----------    ----->  1339\n",
      "Train Loss: 0.04541579638155644\n",
      "-----------EPOCH-----------    ----->  1340\n",
      "Train Loss: 0.04541381471456898\n",
      "-----------EPOCH-----------    ----->  1341\n",
      "Train Loss: 0.045411834003462465\n",
      "-----------EPOCH-----------    ----->  1342\n",
      "Train Loss: 0.04540985239786738\n",
      "-----------EPOCH-----------    ----->  1343\n",
      "Train Loss: 0.0454078725163964\n",
      "-----------EPOCH-----------    ----->  1344\n",
      "Train Loss: 0.04540589216494699\n",
      "-----------EPOCH-----------    ----->  1345\n",
      "Train Loss: 0.04540391516657219\n",
      "-----------EPOCH-----------    ----->  1346\n",
      "Train Loss: 0.0454019437794772\n",
      "-----------EPOCH-----------    ----->  1347\n",
      "Train Loss: 0.04539997454222448\n",
      "-----------EPOCH-----------    ----->  1348\n",
      "Train Loss: 0.04539800520519125\n",
      "-----------EPOCH-----------    ----->  1349\n",
      "Train Loss: 0.04539603735626289\n",
      "-----------EPOCH-----------    ----->  1350\n",
      "Train Loss: 0.04539407232414765\n",
      "-----------EPOCH-----------    ----->  1351\n",
      "Train Loss: 0.04539210923758883\n",
      "-----------EPOCH-----------    ----->  1352\n",
      "Train Loss: 0.04539014643861484\n",
      "-----------EPOCH-----------    ----->  1353\n",
      "Train Loss: 0.045388183527778604\n",
      "-----------EPOCH-----------    ----->  1354\n",
      "Train Loss: 0.04538622151741629\n",
      "-----------EPOCH-----------    ----->  1355\n",
      "Train Loss: 0.045384257124725096\n",
      "-----------EPOCH-----------    ----->  1356\n",
      "Train Loss: 0.04538229344367283\n",
      "-----------EPOCH-----------    ----->  1357\n",
      "Train Loss: 0.04538033170265429\n",
      "-----------EPOCH-----------    ----->  1358\n",
      "Train Loss: 0.04537837460679247\n",
      "-----------EPOCH-----------    ----->  1359\n",
      "Train Loss: 0.04537641691282986\n",
      "-----------EPOCH-----------    ----->  1360\n",
      "Train Loss: 0.04537445977451282\n",
      "-----------EPOCH-----------    ----->  1361\n",
      "Train Loss: 0.04537250436541196\n",
      "-----------EPOCH-----------    ----->  1362\n",
      "Train Loss: 0.04537055241609038\n",
      "-----------EPOCH-----------    ----->  1363\n",
      "Train Loss: 0.04536860545551867\n",
      "-----------EPOCH-----------    ----->  1364\n",
      "Train Loss: 0.04536665921621595\n",
      "-----------EPOCH-----------    ----->  1365\n",
      "Train Loss: 0.04536471351541093\n",
      "-----------EPOCH-----------    ----->  1366\n",
      "Train Loss: 0.04536276795357437\n",
      "-----------EPOCH-----------    ----->  1367\n",
      "Train Loss: 0.04536082816473686\n",
      "-----------EPOCH-----------    ----->  1368\n",
      "Train Loss: 0.04535888899322574\n",
      "-----------EPOCH-----------    ----->  1369\n",
      "Train Loss: 0.0453569531102841\n",
      "-----------EPOCH-----------    ----->  1370\n",
      "Train Loss: 0.045355019451435906\n",
      "-----------EPOCH-----------    ----->  1371\n",
      "Train Loss: 0.04535308811047393\n",
      "-----------EPOCH-----------    ----->  1372\n",
      "Train Loss: 0.04535115912107916\n",
      "-----------EPOCH-----------    ----->  1373\n",
      "Train Loss: 0.04534923127751819\n",
      "-----------EPOCH-----------    ----->  1374\n",
      "Train Loss: 0.045347306438469626\n",
      "-----------EPOCH-----------    ----->  1375\n",
      "Train Loss: 0.04534538498786176\n",
      "-----------EPOCH-----------    ----->  1376\n",
      "Train Loss: 0.04534346551934181\n",
      "-----------EPOCH-----------    ----->  1377\n",
      "Train Loss: 0.04534154794090231\n",
      "-----------EPOCH-----------    ----->  1378\n",
      "Train Loss: 0.045339631076374315\n",
      "-----------EPOCH-----------    ----->  1379\n",
      "Train Loss: 0.04533771336476781\n",
      "-----------EPOCH-----------    ----->  1380\n",
      "Train Loss: 0.04533579730798619\n",
      "-----------EPOCH-----------    ----->  1381\n",
      "Train Loss: 0.04533388299624013\n",
      "-----------EPOCH-----------    ----->  1382\n",
      "Train Loss: 0.04533197305574913\n",
      "-----------EPOCH-----------    ----->  1383\n",
      "Train Loss: 0.04533006513405489\n",
      "-----------EPOCH-----------    ----->  1384\n",
      "Train Loss: 0.045328157069225695\n",
      "-----------EPOCH-----------    ----->  1385\n",
      "Train Loss: 0.045326248066815324\n",
      "-----------EPOCH-----------    ----->  1386\n",
      "Train Loss: 0.04532433699315558\n",
      "-----------EPOCH-----------    ----->  1387\n",
      "Train Loss: 0.04532242258555808\n",
      "-----------EPOCH-----------    ----->  1388\n",
      "Train Loss: 0.04532050973558293\n",
      "-----------EPOCH-----------    ----->  1389\n",
      "Train Loss: 0.04531860235404818\n",
      "-----------EPOCH-----------    ----->  1390\n",
      "Train Loss: 0.045316698899169956\n",
      "-----------EPOCH-----------    ----->  1391\n",
      "Train Loss: 0.04531479709385769\n",
      "-----------EPOCH-----------    ----->  1392\n",
      "Train Loss: 0.04531289841390604\n",
      "-----------EPOCH-----------    ----->  1393\n",
      "Train Loss: 0.045311001749898674\n",
      "-----------EPOCH-----------    ----->  1394\n",
      "Train Loss: 0.045309106358776344\n",
      "-----------EPOCH-----------    ----->  1395\n",
      "Train Loss: 0.04530721214612403\n",
      "-----------EPOCH-----------    ----->  1396\n",
      "Train Loss: 0.045305320511169735\n",
      "-----------EPOCH-----------    ----->  1397\n",
      "Train Loss: 0.045303425340580676\n",
      "-----------EPOCH-----------    ----->  1398\n",
      "Train Loss: 0.045301532475886\n",
      "-----------EPOCH-----------    ----->  1399\n",
      "Train Loss: 0.045299642485506254\n",
      "-----------EPOCH-----------    ----->  1400\n",
      "Train Loss: 0.04529775174785566\n",
      "-----------EPOCH-----------    ----->  1401\n",
      "Train Loss: 0.0452958650831613\n",
      "-----------EPOCH-----------    ----->  1402\n",
      "Train Loss: 0.04529398139432365\n",
      "-----------EPOCH-----------    ----->  1403\n",
      "Train Loss: 0.04529209866461529\n",
      "-----------EPOCH-----------    ----->  1404\n",
      "Train Loss: 0.045290220029993646\n",
      "-----------EPOCH-----------    ----->  1405\n",
      "Train Loss: 0.04528834226039111\n",
      "-----------EPOCH-----------    ----->  1406\n",
      "Train Loss: 0.045286466049085664\n",
      "-----------EPOCH-----------    ----->  1407\n",
      "Train Loss: 0.0452845926131296\n",
      "-----------EPOCH-----------    ----->  1408\n",
      "Train Loss: 0.0452827204949514\n",
      "-----------EPOCH-----------    ----->  1409\n",
      "Train Loss: 0.045280849942173254\n",
      "-----------EPOCH-----------    ----->  1410\n",
      "Train Loss: 0.04527898304476955\n",
      "-----------EPOCH-----------    ----->  1411\n",
      "Train Loss: 0.04527712153500042\n",
      "-----------EPOCH-----------    ----->  1412\n",
      "Train Loss: 0.04527526118422633\n",
      "-----------EPOCH-----------    ----->  1413\n",
      "Train Loss: 0.04527340073529895\n",
      "-----------EPOCH-----------    ----->  1414\n",
      "Train Loss: 0.0452715384285852\n",
      "-----------EPOCH-----------    ----->  1415\n",
      "Train Loss: 0.045269678212653056\n",
      "-----------EPOCH-----------    ----->  1416\n",
      "Train Loss: 0.04526781943518376\n",
      "-----------EPOCH-----------    ----->  1417\n",
      "Train Loss: 0.04526596083987434\n",
      "-----------EPOCH-----------    ----->  1418\n",
      "Train Loss: 0.04526410524680669\n",
      "-----------EPOCH-----------    ----->  1419\n",
      "Train Loss: 0.04526225246129848\n",
      "-----------EPOCH-----------    ----->  1420\n",
      "Train Loss: 0.045260400057052175\n",
      "-----------EPOCH-----------    ----->  1421\n",
      "Train Loss: 0.0452585511450766\n",
      "-----------EPOCH-----------    ----->  1422\n",
      "Train Loss: 0.045256706172177495\n",
      "-----------EPOCH-----------    ----->  1423\n",
      "Train Loss: 0.04525486701715664\n",
      "-----------EPOCH-----------    ----->  1424\n",
      "Train Loss: 0.04525302750076769\n",
      "-----------EPOCH-----------    ----->  1425\n",
      "Train Loss: 0.04525118751286498\n",
      "-----------EPOCH-----------    ----->  1426\n",
      "Train Loss: 0.04524934834894767\n",
      "-----------EPOCH-----------    ----->  1427\n",
      "Train Loss: 0.04524750916451922\n",
      "-----------EPOCH-----------    ----->  1428\n",
      "Train Loss: 0.04524567298560493\n",
      "-----------EPOCH-----------    ----->  1429\n",
      "Train Loss: 0.045243839263340926\n",
      "-----------EPOCH-----------    ----->  1430\n",
      "Train Loss: 0.04524200631007202\n",
      "-----------EPOCH-----------    ----->  1431\n",
      "Train Loss: 0.04524017455259842\n",
      "-----------EPOCH-----------    ----->  1432\n",
      "Train Loss: 0.04523834764435234\n",
      "-----------EPOCH-----------    ----->  1433\n",
      "Train Loss: 0.04523652075533585\n",
      "-----------EPOCH-----------    ----->  1434\n",
      "Train Loss: 0.04523469459329955\n",
      "-----------EPOCH-----------    ----->  1435\n",
      "Train Loss: 0.045232870284289205\n",
      "-----------EPOCH-----------    ----->  1436\n",
      "Train Loss: 0.04523104640609055\n",
      "-----------EPOCH-----------    ----->  1437\n",
      "Train Loss: 0.0452292209759073\n",
      "-----------EPOCH-----------    ----->  1438\n",
      "Train Loss: 0.045227397786270246\n",
      "-----------EPOCH-----------    ----->  1439\n",
      "Train Loss: 0.04522557664912231\n",
      "-----------EPOCH-----------    ----->  1440\n",
      "Train Loss: 0.04522375923414009\n",
      "-----------EPOCH-----------    ----->  1441\n",
      "Train Loss: 0.045221944289046134\n",
      "-----------EPOCH-----------    ----->  1442\n",
      "Train Loss: 0.0452201314317083\n",
      "-----------EPOCH-----------    ----->  1443\n",
      "Train Loss: 0.045218328192813594\n",
      "-----------EPOCH-----------    ----->  1444\n",
      "Train Loss: 0.04521652747825199\n",
      "-----------EPOCH-----------    ----->  1445\n",
      "Train Loss: 0.04521472857843777\n",
      "-----------EPOCH-----------    ----->  1446\n",
      "Train Loss: 0.04521293248093071\n",
      "-----------EPOCH-----------    ----->  1447\n",
      "Train Loss: 0.04521114052401976\n",
      "-----------EPOCH-----------    ----->  1448\n",
      "Train Loss: 0.04520935599169654\n",
      "-----------EPOCH-----------    ----->  1449\n",
      "Train Loss: 0.04520757288984297\n",
      "-----------EPOCH-----------    ----->  1450\n",
      "Train Loss: 0.04520579053130106\n",
      "-----------EPOCH-----------    ----->  1451\n",
      "Train Loss: 0.04520401068619257\n",
      "-----------EPOCH-----------    ----->  1452\n",
      "Train Loss: 0.04520223367642934\n",
      "-----------EPOCH-----------    ----->  1453\n",
      "Train Loss: 0.045200458076546456\n",
      "-----------EPOCH-----------    ----->  1454\n",
      "Train Loss: 0.045198684956315634\n",
      "-----------EPOCH-----------    ----->  1455\n",
      "Train Loss: 0.04519691401909194\n",
      "-----------EPOCH-----------    ----->  1456\n",
      "Train Loss: 0.04519514458855204\n",
      "-----------EPOCH-----------    ----->  1457\n",
      "Train Loss: 0.045193379380230436\n",
      "-----------EPOCH-----------    ----->  1458\n",
      "Train Loss: 0.045191616123791245\n",
      "-----------EPOCH-----------    ----->  1459\n",
      "Train Loss: 0.04518985151675926\n",
      "-----------EPOCH-----------    ----->  1460\n",
      "Train Loss: 0.045188088010212145\n",
      "-----------EPOCH-----------    ----->  1461\n",
      "Train Loss: 0.04518632690525904\n",
      "-----------EPOCH-----------    ----->  1462\n",
      "Train Loss: 0.04518456730172434\n",
      "-----------EPOCH-----------    ----->  1463\n",
      "Train Loss: 0.045182807597120456\n",
      "-----------EPOCH-----------    ----->  1464\n",
      "Train Loss: 0.04518104826291924\n",
      "-----------EPOCH-----------    ----->  1465\n",
      "Train Loss: 0.045179289951975884\n",
      "-----------EPOCH-----------    ----->  1466\n",
      "Train Loss: 0.04517753061120562\n",
      "-----------EPOCH-----------    ----->  1467\n",
      "Train Loss: 0.045175771518415404\n",
      "-----------EPOCH-----------    ----->  1468\n",
      "Train Loss: 0.045174013725048937\n",
      "-----------EPOCH-----------    ----->  1469\n",
      "Train Loss: 0.04517225713071024\n",
      "-----------EPOCH-----------    ----->  1470\n",
      "Train Loss: 0.04517050269398059\n",
      "-----------EPOCH-----------    ----->  1471\n",
      "Train Loss: 0.04516875071629818\n",
      "-----------EPOCH-----------    ----->  1472\n",
      "Train Loss: 0.045166999295980635\n",
      "-----------EPOCH-----------    ----->  1473\n",
      "Train Loss: 0.0451652471688847\n",
      "-----------EPOCH-----------    ----->  1474\n",
      "Train Loss: 0.04516349213486628\n",
      "-----------EPOCH-----------    ----->  1475\n",
      "Train Loss: 0.04516173574918237\n",
      "-----------EPOCH-----------    ----->  1476\n",
      "Train Loss: 0.04515997934987415\n",
      "-----------EPOCH-----------    ----->  1477\n",
      "Train Loss: 0.04515822288645308\n",
      "-----------EPOCH-----------    ----->  1478\n",
      "Train Loss: 0.04515646823742404\n",
      "-----------EPOCH-----------    ----->  1479\n",
      "Train Loss: 0.04515471763607025\n",
      "-----------EPOCH-----------    ----->  1480\n",
      "Train Loss: 0.04515297113294348\n",
      "-----------EPOCH-----------    ----->  1481\n",
      "Train Loss: 0.04515122866379267\n",
      "-----------EPOCH-----------    ----->  1482\n",
      "Train Loss: 0.04514948628067201\n",
      "-----------EPOCH-----------    ----->  1483\n",
      "Train Loss: 0.04514774489526375\n",
      "-----------EPOCH-----------    ----->  1484\n",
      "Train Loss: 0.04514600685714153\n",
      "-----------EPOCH-----------    ----->  1485\n",
      "Train Loss: 0.04514426865720721\n",
      "-----------EPOCH-----------    ----->  1486\n",
      "Train Loss: 0.04514253095315142\n",
      "-----------EPOCH-----------    ----->  1487\n",
      "Train Loss: 0.04514078938436911\n",
      "-----------EPOCH-----------    ----->  1488\n",
      "Train Loss: 0.04513904560457187\n",
      "-----------EPOCH-----------    ----->  1489\n",
      "Train Loss: 0.04513730309584187\n",
      "-----------EPOCH-----------    ----->  1490\n",
      "Train Loss: 0.04513556301077598\n",
      "-----------EPOCH-----------    ----->  1491\n",
      "Train Loss: 0.04513382757102574\n",
      "-----------EPOCH-----------    ----->  1492\n",
      "Train Loss: 0.0451320951054893\n",
      "-----------EPOCH-----------    ----->  1493\n",
      "Train Loss: 0.04513036375089914\n",
      "-----------EPOCH-----------    ----->  1494\n",
      "Train Loss: 0.045128631210291606\n",
      "-----------EPOCH-----------    ----->  1495\n",
      "Train Loss: 0.045126901834508674\n",
      "-----------EPOCH-----------    ----->  1496\n",
      "Train Loss: 0.04512517280315779\n",
      "-----------EPOCH-----------    ----->  1497\n",
      "Train Loss: 0.045123443922202675\n",
      "-----------EPOCH-----------    ----->  1498\n",
      "Train Loss: 0.045121716889003724\n",
      "-----------EPOCH-----------    ----->  1499\n",
      "Train Loss: 0.045119993441460934\n",
      "-----------EPOCH-----------    ----->  1500\n",
      "Train Loss: 0.045118273651907244\n",
      "-----------EPOCH-----------    ----->  1501\n",
      "Train Loss: 0.04511655587012691\n",
      "-----------EPOCH-----------    ----->  1502\n",
      "Train Loss: 0.04511484095066287\n",
      "-----------EPOCH-----------    ----->  1503\n",
      "Train Loss: 0.04511312643568645\n",
      "-----------EPOCH-----------    ----->  1504\n",
      "Train Loss: 0.04511141566149803\n",
      "-----------EPOCH-----------    ----->  1505\n",
      "Train Loss: 0.045109706484444685\n",
      "-----------EPOCH-----------    ----->  1506\n",
      "Train Loss: 0.04510799328756833\n",
      "-----------EPOCH-----------    ----->  1507\n",
      "Train Loss: 0.04510628048709162\n",
      "-----------EPOCH-----------    ----->  1508\n",
      "Train Loss: 0.04510456795176725\n",
      "-----------EPOCH-----------    ----->  1509\n",
      "Train Loss: 0.04510285971919261\n",
      "-----------EPOCH-----------    ----->  1510\n",
      "Train Loss: 0.04510115588951591\n",
      "-----------EPOCH-----------    ----->  1511\n",
      "Train Loss: 0.04509945484613171\n",
      "-----------EPOCH-----------    ----->  1512\n",
      "Train Loss: 0.0450977556112237\n",
      "-----------EPOCH-----------    ----->  1513\n",
      "Train Loss: 0.04509605712216779\n",
      "-----------EPOCH-----------    ----->  1514\n",
      "Train Loss: 0.04509436076434343\n",
      "-----------EPOCH-----------    ----->  1515\n",
      "Train Loss: 0.04509266514643017\n",
      "-----------EPOCH-----------    ----->  1516\n",
      "Train Loss: 0.04509097045751786\n",
      "-----------EPOCH-----------    ----->  1517\n",
      "Train Loss: 0.04508927798800793\n",
      "-----------EPOCH-----------    ----->  1518\n",
      "Train Loss: 0.04508758606302135\n",
      "-----------EPOCH-----------    ----->  1519\n",
      "Train Loss: 0.04508589729945593\n",
      "-----------EPOCH-----------    ----->  1520\n",
      "Train Loss: 0.045084211511867284\n",
      "-----------EPOCH-----------    ----->  1521\n",
      "Train Loss: 0.045082528514033146\n",
      "-----------EPOCH-----------    ----->  1522\n",
      "Train Loss: 0.04508084801458199\n",
      "-----------EPOCH-----------    ----->  1523\n",
      "Train Loss: 0.04507917133644432\n",
      "-----------EPOCH-----------    ----->  1524\n",
      "Train Loss: 0.04507749431305217\n",
      "-----------EPOCH-----------    ----->  1525\n",
      "Train Loss: 0.04507582035690128\n",
      "-----------EPOCH-----------    ----->  1526\n",
      "Train Loss: 0.04507415120748014\n",
      "-----------EPOCH-----------    ----->  1527\n",
      "Train Loss: 0.04507248640739316\n",
      "-----------EPOCH-----------    ----->  1528\n",
      "Train Loss: 0.045070824611294\n",
      "-----------EPOCH-----------    ----->  1529\n",
      "Train Loss: 0.045069160484367564\n",
      "-----------EPOCH-----------    ----->  1530\n",
      "Train Loss: 0.045067498191672176\n",
      "-----------EPOCH-----------    ----->  1531\n",
      "Train Loss: 0.04506583850730673\n",
      "-----------EPOCH-----------    ----->  1532\n",
      "Train Loss: 0.045064181662596896\n",
      "-----------EPOCH-----------    ----->  1533\n",
      "Train Loss: 0.04506252454356068\n",
      "-----------EPOCH-----------    ----->  1534\n",
      "Train Loss: 0.04506086930351927\n",
      "-----------EPOCH-----------    ----->  1535\n",
      "Train Loss: 0.04505921719753884\n",
      "-----------EPOCH-----------    ----->  1536\n",
      "Train Loss: 0.045057564233833794\n",
      "-----------EPOCH-----------    ----->  1537\n",
      "Train Loss: 0.04505591133593037\n",
      "-----------EPOCH-----------    ----->  1538\n",
      "Train Loss: 0.045054256027726745\n",
      "-----------EPOCH-----------    ----->  1539\n",
      "Train Loss: 0.04505260208517283\n",
      "-----------EPOCH-----------    ----->  1540\n",
      "Train Loss: 0.0450509511564212\n",
      "-----------EPOCH-----------    ----->  1541\n",
      "Train Loss: 0.04504930281268456\n",
      "-----------EPOCH-----------    ----->  1542\n",
      "Train Loss: 0.04504765441683103\n",
      "-----------EPOCH-----------    ----->  1543\n",
      "Train Loss: 0.04504600390267898\n",
      "-----------EPOCH-----------    ----->  1544\n",
      "Train Loss: 0.04504435504339475\n",
      "-----------EPOCH-----------    ----->  1545\n",
      "Train Loss: 0.045042711835088636\n",
      "-----------EPOCH-----------    ----->  1546\n",
      "Train Loss: 0.04504107290409743\n",
      "-----------EPOCH-----------    ----->  1547\n",
      "Train Loss: 0.04503943558143061\n",
      "-----------EPOCH-----------    ----->  1548\n",
      "Train Loss: 0.04503779871439513\n",
      "-----------EPOCH-----------    ----->  1549\n",
      "Train Loss: 0.04503616556867716\n",
      "-----------EPOCH-----------    ----->  1550\n",
      "Train Loss: 0.045034533714744085\n",
      "-----------EPOCH-----------    ----->  1551\n",
      "Train Loss: 0.04503290306357925\n",
      "-----------EPOCH-----------    ----->  1552\n",
      "Train Loss: 0.04503127409105255\n",
      "-----------EPOCH-----------    ----->  1553\n",
      "Train Loss: 0.04502964681569455\n",
      "-----------EPOCH-----------    ----->  1554\n",
      "Train Loss: 0.045028019490656\n",
      "-----------EPOCH-----------    ----->  1555\n",
      "Train Loss: 0.04502639167754609\n",
      "-----------EPOCH-----------    ----->  1556\n",
      "Train Loss: 0.045024764270100666\n",
      "-----------EPOCH-----------    ----->  1557\n",
      "Train Loss: 0.045023134006878074\n",
      "-----------EPOCH-----------    ----->  1558\n",
      "Train Loss: 0.04502150230077922\n",
      "-----------EPOCH-----------    ----->  1559\n",
      "Train Loss: 0.04501987629048421\n",
      "-----------EPOCH-----------    ----->  1560\n",
      "Train Loss: 0.04501825471613405\n",
      "-----------EPOCH-----------    ----->  1561\n",
      "Train Loss: 0.04501663649278049\n",
      "-----------EPOCH-----------    ----->  1562\n",
      "Train Loss: 0.0450150207929192\n",
      "-----------EPOCH-----------    ----->  1563\n",
      "Train Loss: 0.04501340716809548\n",
      "-----------EPOCH-----------    ----->  1564\n",
      "Train Loss: 0.045011794844552734\n",
      "-----------EPOCH-----------    ----->  1565\n",
      "Train Loss: 0.045010183462685774\n",
      "-----------EPOCH-----------    ----->  1566\n",
      "Train Loss: 0.04500857059871751\n",
      "-----------EPOCH-----------    ----->  1567\n",
      "Train Loss: 0.0450069605053603\n",
      "-----------EPOCH-----------    ----->  1568\n",
      "Train Loss: 0.045005347833258776\n",
      "-----------EPOCH-----------    ----->  1569\n",
      "Train Loss: 0.045003737441799745\n",
      "-----------EPOCH-----------    ----->  1570\n",
      "Train Loss: 0.04500212883725683\n",
      "-----------EPOCH-----------    ----->  1571\n",
      "Train Loss: 0.045000520120618705\n",
      "-----------EPOCH-----------    ----->  1572\n",
      "Train Loss: 0.0449989123765069\n",
      "-----------EPOCH-----------    ----->  1573\n",
      "Train Loss: 0.044997307202575214\n",
      "-----------EPOCH-----------    ----->  1574\n",
      "Train Loss: 0.04499570307828121\n",
      "-----------EPOCH-----------    ----->  1575\n",
      "Train Loss: 0.04499410104923462\n",
      "-----------EPOCH-----------    ----->  1576\n",
      "Train Loss: 0.044992499035351886\n",
      "-----------EPOCH-----------    ----->  1577\n",
      "Train Loss: 0.04499089858259527\n",
      "-----------EPOCH-----------    ----->  1578\n",
      "Train Loss: 0.04498929928726813\n",
      "-----------EPOCH-----------    ----->  1579\n",
      "Train Loss: 0.044987701913514304\n",
      "-----------EPOCH-----------    ----->  1580\n",
      "Train Loss: 0.04498610641651147\n",
      "-----------EPOCH-----------    ----->  1581\n",
      "Train Loss: 0.0449845111840546\n",
      "-----------EPOCH-----------    ----->  1582\n",
      "Train Loss: 0.04498291707981097\n",
      "-----------EPOCH-----------    ----->  1583\n",
      "Train Loss: 0.04498132402632019\n",
      "-----------EPOCH-----------    ----->  1584\n",
      "Train Loss: 0.044979734482464645\n",
      "-----------EPOCH-----------    ----->  1585\n",
      "Train Loss: 0.04497814586924877\n",
      "-----------EPOCH-----------    ----->  1586\n",
      "Train Loss: 0.04497655834241821\n",
      "-----------EPOCH-----------    ----->  1587\n",
      "Train Loss: 0.04497497194566811\n",
      "-----------EPOCH-----------    ----->  1588\n",
      "Train Loss: 0.044973387123662396\n",
      "-----------EPOCH-----------    ----->  1589\n",
      "Train Loss: 0.04497180162094973\n",
      "-----------EPOCH-----------    ----->  1590\n",
      "Train Loss: 0.04497021881055221\n",
      "-----------EPOCH-----------    ----->  1591\n",
      "Train Loss: 0.044968635975012154\n",
      "-----------EPOCH-----------    ----->  1592\n",
      "Train Loss: 0.04496705586353446\n",
      "-----------EPOCH-----------    ----->  1593\n",
      "Train Loss: 0.04496548048690805\n",
      "-----------EPOCH-----------    ----->  1594\n",
      "Train Loss: 0.04496390662807613\n",
      "-----------EPOCH-----------    ----->  1595\n",
      "Train Loss: 0.044962332227317006\n",
      "-----------EPOCH-----------    ----->  1596\n",
      "Train Loss: 0.0449607588605811\n",
      "-----------EPOCH-----------    ----->  1597\n",
      "Train Loss: 0.04495918608839611\n",
      "-----------EPOCH-----------    ----->  1598\n",
      "Train Loss: 0.04495761419087582\n",
      "-----------EPOCH-----------    ----->  1599\n",
      "Train Loss: 0.04495604439360835\n",
      "-----------EPOCH-----------    ----->  1600\n",
      "Train Loss: 0.04495447494530807\n",
      "-----------EPOCH-----------    ----->  1601\n",
      "Train Loss: 0.044952906567859684\n",
      "-----------EPOCH-----------    ----->  1602\n",
      "Train Loss: 0.044951339218997084\n",
      "-----------EPOCH-----------    ----->  1603\n",
      "Train Loss: 0.04494977149043211\n",
      "-----------EPOCH-----------    ----->  1604\n",
      "Train Loss: 0.044948207865389354\n",
      "-----------EPOCH-----------    ----->  1605\n",
      "Train Loss: 0.044946645939862945\n",
      "-----------EPOCH-----------    ----->  1606\n",
      "Train Loss: 0.044945082688620255\n",
      "-----------EPOCH-----------    ----->  1607\n",
      "Train Loss: 0.04494352105990805\n",
      "-----------EPOCH-----------    ----->  1608\n",
      "Train Loss: 0.04494196328890724\n",
      "-----------EPOCH-----------    ----->  1609\n",
      "Train Loss: 0.04494040704720278\n",
      "-----------EPOCH-----------    ----->  1610\n",
      "Train Loss: 0.04493885323998304\n",
      "-----------EPOCH-----------    ----->  1611\n",
      "Train Loss: 0.04493730228027445\n",
      "-----------EPOCH-----------    ----->  1612\n",
      "Train Loss: 0.04493575568636409\n",
      "-----------EPOCH-----------    ----->  1613\n",
      "Train Loss: 0.044934211881295406\n",
      "-----------EPOCH-----------    ----->  1614\n",
      "Train Loss: 0.0449326698980905\n",
      "-----------EPOCH-----------    ----->  1615\n",
      "Train Loss: 0.044931130957939165\n",
      "-----------EPOCH-----------    ----->  1616\n",
      "Train Loss: 0.04492959404225231\n",
      "-----------EPOCH-----------    ----->  1617\n",
      "Train Loss: 0.04492805960103813\n",
      "-----------EPOCH-----------    ----->  1618\n",
      "Train Loss: 0.04492652592742328\n",
      "-----------EPOCH-----------    ----->  1619\n",
      "Train Loss: 0.04492499201460368\n",
      "-----------EPOCH-----------    ----->  1620\n",
      "Train Loss: 0.044923459380377985\n",
      "-----------EPOCH-----------    ----->  1621\n",
      "Train Loss: 0.044921928630668254\n",
      "-----------EPOCH-----------    ----->  1622\n",
      "Train Loss: 0.04492039639382586\n",
      "-----------EPOCH-----------    ----->  1623\n",
      "Train Loss: 0.0449188651017337\n",
      "-----------EPOCH-----------    ----->  1624\n",
      "Train Loss: 0.044917335325697604\n",
      "-----------EPOCH-----------    ----->  1625\n",
      "Train Loss: 0.044915806517233765\n",
      "-----------EPOCH-----------    ----->  1626\n",
      "Train Loss: 0.044914277361718775\n",
      "-----------EPOCH-----------    ----->  1627\n",
      "Train Loss: 0.04491275072943415\n",
      "-----------EPOCH-----------    ----->  1628\n",
      "Train Loss: 0.04491122657874304\n",
      "-----------EPOCH-----------    ----->  1629\n",
      "Train Loss: 0.044909704370800954\n",
      "-----------EPOCH-----------    ----->  1630\n",
      "Train Loss: 0.044908185199005836\n",
      "-----------EPOCH-----------    ----->  1631\n",
      "Train Loss: 0.04490666792071785\n",
      "-----------EPOCH-----------    ----->  1632\n",
      "Train Loss: 0.044905152423061354\n",
      "-----------EPOCH-----------    ----->  1633\n",
      "Train Loss: 0.04490364025999084\n",
      "-----------EPOCH-----------    ----->  1634\n",
      "Train Loss: 0.044902131601019385\n",
      "-----------EPOCH-----------    ----->  1635\n",
      "Train Loss: 0.04490062477893537\n",
      "-----------EPOCH-----------    ----->  1636\n",
      "Train Loss: 0.04489911991069448\n",
      "-----------EPOCH-----------    ----->  1637\n",
      "Train Loss: 0.044897617058625265\n",
      "-----------EPOCH-----------    ----->  1638\n",
      "Train Loss: 0.044896113949188125\n",
      "-----------EPOCH-----------    ----->  1639\n",
      "Train Loss: 0.0448946107203286\n",
      "-----------EPOCH-----------    ----->  1640\n",
      "Train Loss: 0.04489310857713785\n",
      "-----------EPOCH-----------    ----->  1641\n",
      "Train Loss: 0.04489160908213766\n",
      "-----------EPOCH-----------    ----->  1642\n",
      "Train Loss: 0.04489010869709176\n",
      "-----------EPOCH-----------    ----->  1643\n",
      "Train Loss: 0.04488860862016171\n",
      "-----------EPOCH-----------    ----->  1644\n",
      "Train Loss: 0.04488710703459441\n",
      "-----------EPOCH-----------    ----->  1645\n",
      "Train Loss: 0.04488560870975562\n",
      "-----------EPOCH-----------    ----->  1646\n",
      "Train Loss: 0.04488411236112225\n",
      "-----------EPOCH-----------    ----->  1647\n",
      "Train Loss: 0.04488261675319362\n",
      "-----------EPOCH-----------    ----->  1648\n",
      "Train Loss: 0.04488112295352444\n",
      "-----------EPOCH-----------    ----->  1649\n",
      "Train Loss: 0.04487963200265558\n",
      "-----------EPOCH-----------    ----->  1650\n",
      "Train Loss: 0.04487814450638238\n",
      "-----------EPOCH-----------    ----->  1651\n",
      "Train Loss: 0.044876660314950106\n",
      "-----------EPOCH-----------    ----->  1652\n",
      "Train Loss: 0.044875177174720886\n",
      "-----------EPOCH-----------    ----->  1653\n",
      "Train Loss: 0.0448736963952407\n",
      "-----------EPOCH-----------    ----->  1654\n",
      "Train Loss: 0.0448722210403086\n",
      "-----------EPOCH-----------    ----->  1655\n",
      "Train Loss: 0.044870745902603995\n",
      "-----------EPOCH-----------    ----->  1656\n",
      "Train Loss: 0.044869272422277354\n",
      "-----------EPOCH-----------    ----->  1657\n",
      "Train Loss: 0.04486780305708416\n",
      "-----------EPOCH-----------    ----->  1658\n",
      "Train Loss: 0.04486633573879145\n",
      "-----------EPOCH-----------    ----->  1659\n",
      "Train Loss: 0.04486486892835081\n",
      "-----------EPOCH-----------    ----->  1660\n",
      "Train Loss: 0.04486340243812564\n",
      "-----------EPOCH-----------    ----->  1661\n",
      "Train Loss: 0.044861935979164685\n",
      "-----------EPOCH-----------    ----->  1662\n",
      "Train Loss: 0.044860470385150175\n",
      "-----------EPOCH-----------    ----->  1663\n",
      "Train Loss: 0.04485900338586311\n",
      "-----------EPOCH-----------    ----->  1664\n",
      "Train Loss: 0.04485753708721132\n",
      "-----------EPOCH-----------    ----->  1665\n",
      "Train Loss: 0.04485607499073695\n",
      "-----------EPOCH-----------    ----->  1666\n",
      "Train Loss: 0.04485461469303258\n",
      "-----------EPOCH-----------    ----->  1667\n",
      "Train Loss: 0.04485315579906024\n",
      "-----------EPOCH-----------    ----->  1668\n",
      "Train Loss: 0.04485169770485112\n",
      "-----------EPOCH-----------    ----->  1669\n",
      "Train Loss: 0.044850244568267826\n",
      "-----------EPOCH-----------    ----->  1670\n",
      "Train Loss: 0.04484879290146954\n",
      "-----------EPOCH-----------    ----->  1671\n",
      "Train Loss: 0.04484734203177527\n",
      "-----------EPOCH-----------    ----->  1672\n",
      "Train Loss: 0.0448458923463133\n",
      "-----------EPOCH-----------    ----->  1673\n",
      "Train Loss: 0.04484444349319709\n",
      "-----------EPOCH-----------    ----->  1674\n",
      "Train Loss: 0.044842994666824114\n",
      "-----------EPOCH-----------    ----->  1675\n",
      "Train Loss: 0.0448415457593436\n",
      "-----------EPOCH-----------    ----->  1676\n",
      "Train Loss: 0.04484009806738168\n",
      "-----------EPOCH-----------    ----->  1677\n",
      "Train Loss: 0.044838651113746714\n",
      "-----------EPOCH-----------    ----->  1678\n",
      "Train Loss: 0.044837205485172546\n",
      "-----------EPOCH-----------    ----->  1679\n",
      "Train Loss: 0.044835758903284714\n",
      "-----------EPOCH-----------    ----->  1680\n",
      "Train Loss: 0.04483431234130618\n",
      "-----------EPOCH-----------    ----->  1681\n",
      "Train Loss: 0.04483286661240656\n",
      "-----------EPOCH-----------    ----->  1682\n",
      "Train Loss: 0.0448314185816584\n",
      "-----------EPOCH-----------    ----->  1683\n",
      "Train Loss: 0.044829971078494645\n",
      "-----------EPOCH-----------    ----->  1684\n",
      "Train Loss: 0.04482852560739823\n",
      "-----------EPOCH-----------    ----->  1685\n",
      "Train Loss: 0.04482708194848234\n",
      "-----------EPOCH-----------    ----->  1686\n",
      "Train Loss: 0.04482563947505345\n",
      "-----------EPOCH-----------    ----->  1687\n",
      "Train Loss: 0.044824198150706734\n",
      "-----------EPOCH-----------    ----->  1688\n",
      "Train Loss: 0.04482275899417136\n",
      "-----------EPOCH-----------    ----->  1689\n",
      "Train Loss: 0.04482132308502386\n",
      "-----------EPOCH-----------    ----->  1690\n",
      "Train Loss: 0.04481989059933256\n",
      "-----------EPOCH-----------    ----->  1691\n",
      "Train Loss: 0.04481846174186347\n",
      "-----------EPOCH-----------    ----->  1692\n",
      "Train Loss: 0.04481703568555284\n",
      "-----------EPOCH-----------    ----->  1693\n",
      "Train Loss: 0.044815611123276825\n",
      "-----------EPOCH-----------    ----->  1694\n",
      "Train Loss: 0.04481418666429328\n",
      "-----------EPOCH-----------    ----->  1695\n",
      "Train Loss: 0.04481276386544901\n",
      "-----------EPOCH-----------    ----->  1696\n",
      "Train Loss: 0.04481134233691752\n",
      "-----------EPOCH-----------    ----->  1697\n",
      "Train Loss: 0.044809920801374845\n",
      "-----------EPOCH-----------    ----->  1698\n",
      "Train Loss: 0.04480850038560254\n",
      "-----------EPOCH-----------    ----->  1699\n",
      "Train Loss: 0.04480708054887655\n",
      "-----------EPOCH-----------    ----->  1700\n",
      "Train Loss: 0.044805660971371696\n",
      "-----------EPOCH-----------    ----->  1701\n",
      "Train Loss: 0.04480424300473253\n",
      "-----------EPOCH-----------    ----->  1702\n",
      "Train Loss: 0.044802826922213455\n",
      "-----------EPOCH-----------    ----->  1703\n",
      "Train Loss: 0.04480141227943237\n",
      "-----------EPOCH-----------    ----->  1704\n",
      "Train Loss: 0.044799999133324026\n",
      "-----------EPOCH-----------    ----->  1705\n",
      "Train Loss: 0.04479858770631705\n",
      "-----------EPOCH-----------    ----->  1706\n",
      "Train Loss: 0.044797176280712975\n",
      "-----------EPOCH-----------    ----->  1707\n",
      "Train Loss: 0.0447957656737967\n",
      "-----------EPOCH-----------    ----->  1708\n",
      "Train Loss: 0.04479435778094739\n",
      "-----------EPOCH-----------    ----->  1709\n",
      "Train Loss: 0.04479295154221638\n",
      "-----------EPOCH-----------    ----->  1710\n",
      "Train Loss: 0.04479154690200098\n",
      "-----------EPOCH-----------    ----->  1711\n",
      "Train Loss: 0.044790142337487\n",
      "-----------EPOCH-----------    ----->  1712\n",
      "Train Loss: 0.04478873629291925\n",
      "-----------EPOCH-----------    ----->  1713\n",
      "Train Loss: 0.0447873323722066\n",
      "-----------EPOCH-----------    ----->  1714\n",
      "Train Loss: 0.044785928479045216\n",
      "-----------EPOCH-----------    ----->  1715\n",
      "Train Loss: 0.044784523722608105\n",
      "-----------EPOCH-----------    ----->  1716\n",
      "Train Loss: 0.04478311908470711\n",
      "-----------EPOCH-----------    ----->  1717\n",
      "Train Loss: 0.044781714821202565\n",
      "-----------EPOCH-----------    ----->  1718\n",
      "Train Loss: 0.044780311133718734\n",
      "-----------EPOCH-----------    ----->  1719\n",
      "Train Loss: 0.04477890742390427\n",
      "-----------EPOCH-----------    ----->  1720\n",
      "Train Loss: 0.0447775016610993\n",
      "-----------EPOCH-----------    ----->  1721\n",
      "Train Loss: 0.0447760949535984\n",
      "-----------EPOCH-----------    ----->  1722\n",
      "Train Loss: 0.044774688753212125\n",
      "-----------EPOCH-----------    ----->  1723\n",
      "Train Loss: 0.04477328428765712\n",
      "-----------EPOCH-----------    ----->  1724\n",
      "Train Loss: 0.04477188233672317\n",
      "-----------EPOCH-----------    ----->  1725\n",
      "Train Loss: 0.04477048276231477\n",
      "-----------EPOCH-----------    ----->  1726\n",
      "Train Loss: 0.04476908490214141\n",
      "-----------EPOCH-----------    ----->  1727\n",
      "Train Loss: 0.044767689126033024\n",
      "-----------EPOCH-----------    ----->  1728\n",
      "Train Loss: 0.044766294441516155\n",
      "-----------EPOCH-----------    ----->  1729\n",
      "Train Loss: 0.04476490100542606\n",
      "-----------EPOCH-----------    ----->  1730\n",
      "Train Loss: 0.044763508398616876\n",
      "-----------EPOCH-----------    ----->  1731\n",
      "Train Loss: 0.04476211403956141\n",
      "-----------EPOCH-----------    ----->  1732\n",
      "Train Loss: 0.044760718648638086\n",
      "-----------EPOCH-----------    ----->  1733\n",
      "Train Loss: 0.04475932384876315\n",
      "-----------EPOCH-----------    ----->  1734\n",
      "Train Loss: 0.044757929495138765\n",
      "-----------EPOCH-----------    ----->  1735\n",
      "Train Loss: 0.04475653676468918\n",
      "-----------EPOCH-----------    ----->  1736\n",
      "Train Loss: 0.04475514616126852\n",
      "-----------EPOCH-----------    ----->  1737\n",
      "Train Loss: 0.04475375799901241\n",
      "-----------EPOCH-----------    ----->  1738\n",
      "Train Loss: 0.04475237180105519\n",
      "-----------EPOCH-----------    ----->  1739\n",
      "Train Loss: 0.04475098656930723\n",
      "-----------EPOCH-----------    ----->  1740\n",
      "Train Loss: 0.04474960222851933\n",
      "-----------EPOCH-----------    ----->  1741\n",
      "Train Loss: 0.04474821894126574\n",
      "-----------EPOCH-----------    ----->  1742\n",
      "Train Loss: 0.044746837201761085\n",
      "-----------EPOCH-----------    ----->  1743\n",
      "Train Loss: 0.04474546006691\n",
      "-----------EPOCH-----------    ----->  1744\n",
      "Train Loss: 0.044744083544549604\n",
      "-----------EPOCH-----------    ----->  1745\n",
      "Train Loss: 0.044742707027936195\n",
      "-----------EPOCH-----------    ----->  1746\n",
      "Train Loss: 0.04474133083035181\n",
      "-----------EPOCH-----------    ----->  1747\n",
      "Train Loss: 0.044739956863793624\n",
      "-----------EPOCH-----------    ----->  1748\n",
      "Train Loss: 0.04473858571780873\n",
      "-----------EPOCH-----------    ----->  1749\n",
      "Train Loss: 0.04473721673914328\n",
      "-----------EPOCH-----------    ----->  1750\n",
      "Train Loss: 0.04473584821957358\n",
      "-----------EPOCH-----------    ----->  1751\n",
      "Train Loss: 0.04473448138084362\n",
      "-----------EPOCH-----------    ----->  1752\n",
      "Train Loss: 0.044733116412424494\n",
      "-----------EPOCH-----------    ----->  1753\n",
      "Train Loss: 0.04473175357890799\n",
      "-----------EPOCH-----------    ----->  1754\n",
      "Train Loss: 0.044730389280605916\n",
      "-----------EPOCH-----------    ----->  1755\n",
      "Train Loss: 0.04472902305746203\n",
      "-----------EPOCH-----------    ----->  1756\n",
      "Train Loss: 0.04472765914404719\n",
      "-----------EPOCH-----------    ----->  1757\n",
      "Train Loss: 0.0447262942994351\n",
      "-----------EPOCH-----------    ----->  1758\n",
      "Train Loss: 0.04472493231481859\n",
      "-----------EPOCH-----------    ----->  1759\n",
      "Train Loss: 0.04472357234780393\n",
      "-----------EPOCH-----------    ----->  1760\n",
      "Train Loss: 0.044722213200520305\n",
      "-----------EPOCH-----------    ----->  1761\n",
      "Train Loss: 0.044720856199855726\n",
      "-----------EPOCH-----------    ----->  1762\n",
      "Train Loss: 0.04471950301221717\n",
      "-----------EPOCH-----------    ----->  1763\n",
      "Train Loss: 0.044718151389168674\n",
      "-----------EPOCH-----------    ----->  1764\n",
      "Train Loss: 0.044716801904438996\n",
      "-----------EPOCH-----------    ----->  1765\n",
      "Train Loss: 0.044715455309081255\n",
      "-----------EPOCH-----------    ----->  1766\n",
      "Train Loss: 0.04471411088618943\n",
      "-----------EPOCH-----------    ----->  1767\n",
      "Train Loss: 0.04471276583071669\n",
      "-----------EPOCH-----------    ----->  1768\n",
      "Train Loss: 0.04471142040961424\n",
      "-----------EPOCH-----------    ----->  1769\n",
      "Train Loss: 0.044710075894885855\n",
      "-----------EPOCH-----------    ----->  1770\n",
      "Train Loss: 0.04470873274818258\n",
      "-----------EPOCH-----------    ----->  1771\n",
      "Train Loss: 0.04470739192071924\n",
      "-----------EPOCH-----------    ----->  1772\n",
      "Train Loss: 0.04470605093202233\n",
      "-----------EPOCH-----------    ----->  1773\n",
      "Train Loss: 0.04470471250603702\n",
      "-----------EPOCH-----------    ----->  1774\n",
      "Train Loss: 0.04470337443145687\n",
      "-----------EPOCH-----------    ----->  1775\n",
      "Train Loss: 0.04470203772613297\n",
      "-----------EPOCH-----------    ----->  1776\n",
      "Train Loss: 0.04470070148851445\n",
      "-----------EPOCH-----------    ----->  1777\n",
      "Train Loss: 0.044699365505917486\n",
      "-----------EPOCH-----------    ----->  1778\n",
      "Train Loss: 0.0446980295336216\n",
      "-----------EPOCH-----------    ----->  1779\n",
      "Train Loss: 0.0446966953462923\n",
      "-----------EPOCH-----------    ----->  1780\n",
      "Train Loss: 0.044695361626696475\n",
      "-----------EPOCH-----------    ----->  1781\n",
      "Train Loss: 0.04469402908044363\n",
      "-----------EPOCH-----------    ----->  1782\n",
      "Train Loss: 0.04469269918515011\n",
      "-----------EPOCH-----------    ----->  1783\n",
      "Train Loss: 0.04469137022607365\n",
      "-----------EPOCH-----------    ----->  1784\n",
      "Train Loss: 0.044690043396378526\n",
      "-----------EPOCH-----------    ----->  1785\n",
      "Train Loss: 0.04468871726399186\n",
      "-----------EPOCH-----------    ----->  1786\n",
      "Train Loss: 0.04468739497715358\n",
      "-----------EPOCH-----------    ----->  1787\n",
      "Train Loss: 0.04468607477425898\n",
      "-----------EPOCH-----------    ----->  1788\n",
      "Train Loss: 0.044684756650916396\n",
      "-----------EPOCH-----------    ----->  1789\n",
      "Train Loss: 0.044683442524420414\n",
      "-----------EPOCH-----------    ----->  1790\n",
      "Train Loss: 0.04468212876160145\n",
      "-----------EPOCH-----------    ----->  1791\n",
      "Train Loss: 0.04468081188057301\n",
      "-----------EPOCH-----------    ----->  1792\n",
      "Train Loss: 0.04467949471855264\n",
      "-----------EPOCH-----------    ----->  1793\n",
      "Train Loss: 0.0446781798037767\n",
      "-----------EPOCH-----------    ----->  1794\n",
      "Train Loss: 0.04467686463762107\n",
      "-----------EPOCH-----------    ----->  1795\n",
      "Train Loss: 0.044675550394363196\n",
      "-----------EPOCH-----------    ----->  1796\n",
      "Train Loss: 0.0446742380540634\n",
      "-----------EPOCH-----------    ----->  1797\n",
      "Train Loss: 0.04467293046314974\n",
      "-----------EPOCH-----------    ----->  1798\n",
      "Train Loss: 0.0446716241342658\n",
      "-----------EPOCH-----------    ----->  1799\n",
      "Train Loss: 0.04467032061779384\n",
      "-----------EPOCH-----------    ----->  1800\n",
      "Train Loss: 0.044669018045365695\n",
      "-----------EPOCH-----------    ----->  1801\n",
      "Train Loss: 0.044667715852833564\n",
      "-----------EPOCH-----------    ----->  1802\n",
      "Train Loss: 0.044666414871456936\n",
      "-----------EPOCH-----------    ----->  1803\n",
      "Train Loss: 0.04466511501828383\n",
      "-----------EPOCH-----------    ----->  1804\n",
      "Train Loss: 0.04466381630645986\n",
      "-----------EPOCH-----------    ----->  1805\n",
      "Train Loss: 0.04466252075269942\n",
      "-----------EPOCH-----------    ----->  1806\n",
      "Train Loss: 0.044661226293298474\n",
      "-----------EPOCH-----------    ----->  1807\n",
      "Train Loss: 0.0446599339275806\n",
      "-----------EPOCH-----------    ----->  1808\n",
      "Train Loss: 0.04465864412508829\n",
      "-----------EPOCH-----------    ----->  1809\n",
      "Train Loss: 0.04465735523220675\n",
      "-----------EPOCH-----------    ----->  1810\n",
      "Train Loss: 0.044656068655233166\n",
      "-----------EPOCH-----------    ----->  1811\n",
      "Train Loss: 0.04465478242847406\n",
      "-----------EPOCH-----------    ----->  1812\n",
      "Train Loss: 0.04465349968568597\n",
      "-----------EPOCH-----------    ----->  1813\n",
      "Train Loss: 0.04465221759000795\n",
      "-----------EPOCH-----------    ----->  1814\n",
      "Train Loss: 0.044650936272695736\n",
      "-----------EPOCH-----------    ----->  1815\n",
      "Train Loss: 0.044649657037059545\n",
      "-----------EPOCH-----------    ----->  1816\n",
      "Train Loss: 0.044648378728994194\n",
      "-----------EPOCH-----------    ----->  1817\n",
      "Train Loss: 0.04464710350646729\n",
      "-----------EPOCH-----------    ----->  1818\n",
      "Train Loss: 0.04464582977735825\n",
      "-----------EPOCH-----------    ----->  1819\n",
      "Train Loss: 0.044644557623446456\n",
      "-----------EPOCH-----------    ----->  1820\n",
      "Train Loss: 0.04464328577216166\n",
      "-----------EPOCH-----------    ----->  1821\n",
      "Train Loss: 0.044642013340730764\n",
      "-----------EPOCH-----------    ----->  1822\n",
      "Train Loss: 0.04464074216143735\n",
      "-----------EPOCH-----------    ----->  1823\n",
      "Train Loss: 0.04463947224304942\n",
      "-----------EPOCH-----------    ----->  1824\n",
      "Train Loss: 0.044638203498339996\n",
      "-----------EPOCH-----------    ----->  1825\n",
      "Train Loss: 0.04463693614426897\n",
      "-----------EPOCH-----------    ----->  1826\n",
      "Train Loss: 0.044635669056315476\n",
      "-----------EPOCH-----------    ----->  1827\n",
      "Train Loss: 0.04463440308663928\n",
      "-----------EPOCH-----------    ----->  1828\n",
      "Train Loss: 0.044633137838083065\n",
      "-----------EPOCH-----------    ----->  1829\n",
      "Train Loss: 0.04463187462960148\n",
      "-----------EPOCH-----------    ----->  1830\n",
      "Train Loss: 0.0446306115824486\n",
      "-----------EPOCH-----------    ----->  1831\n",
      "Train Loss: 0.04462934778540062\n",
      "-----------EPOCH-----------    ----->  1832\n",
      "Train Loss: 0.04462808588050602\n",
      "-----------EPOCH-----------    ----->  1833\n",
      "Train Loss: 0.04462682495776052\n",
      "-----------EPOCH-----------    ----->  1834\n",
      "Train Loss: 0.04462556468656043\n",
      "-----------EPOCH-----------    ----->  1835\n",
      "Train Loss: 0.04462430555305135\n",
      "-----------EPOCH-----------    ----->  1836\n",
      "Train Loss: 0.04462304872813556\n",
      "-----------EPOCH-----------    ----->  1837\n",
      "Train Loss: 0.04462179115678484\n",
      "-----------EPOCH-----------    ----->  1838\n",
      "Train Loss: 0.044620534338376386\n",
      "-----------EPOCH-----------    ----->  1839\n",
      "Train Loss: 0.04461927799802896\n",
      "-----------EPOCH-----------    ----->  1840\n",
      "Train Loss: 0.04461802274227185\n",
      "-----------EPOCH-----------    ----->  1841\n",
      "Train Loss: 0.044616771302783374\n",
      "-----------EPOCH-----------    ----->  1842\n",
      "Train Loss: 0.04461552149115647\n",
      "-----------EPOCH-----------    ----->  1843\n",
      "Train Loss: 0.04461426597373056\n",
      "-----------EPOCH-----------    ----->  1844\n",
      "Train Loss: 0.04461301086332078\n",
      "-----------EPOCH-----------    ----->  1845\n",
      "Train Loss: 0.04461175574536825\n",
      "-----------EPOCH-----------    ----->  1846\n",
      "Train Loss: 0.04461050066969593\n",
      "-----------EPOCH-----------    ----->  1847\n",
      "Train Loss: 0.04460924745886991\n",
      "-----------EPOCH-----------    ----->  1848\n",
      "Train Loss: 0.04460799431699194\n",
      "-----------EPOCH-----------    ----->  1849\n",
      "Train Loss: 0.04460674242334551\n",
      "-----------EPOCH-----------    ----->  1850\n",
      "Train Loss: 0.04460549080400649\n",
      "-----------EPOCH-----------    ----->  1851\n",
      "Train Loss: 0.04460424163463528\n",
      "-----------EPOCH-----------    ----->  1852\n",
      "Train Loss: 0.044602993821956594\n",
      "-----------EPOCH-----------    ----->  1853\n",
      "Train Loss: 0.04460174553725763\n",
      "-----------EPOCH-----------    ----->  1854\n",
      "Train Loss: 0.04460049761179298\n",
      "-----------EPOCH-----------    ----->  1855\n",
      "Train Loss: 0.04459924976215795\n",
      "-----------EPOCH-----------    ----->  1856\n",
      "Train Loss: 0.04459800490756746\n",
      "-----------EPOCH-----------    ----->  1857\n",
      "Train Loss: 0.044596760232810555\n",
      "-----------EPOCH-----------    ----->  1858\n",
      "Train Loss: 0.04459551655889491\n",
      "-----------EPOCH-----------    ----->  1859\n",
      "Train Loss: 0.044594273936065514\n",
      "-----------EPOCH-----------    ----->  1860\n",
      "Train Loss: 0.0445930313674369\n",
      "-----------EPOCH-----------    ----->  1861\n",
      "Train Loss: 0.04459178862422093\n",
      "-----------EPOCH-----------    ----->  1862\n",
      "Train Loss: 0.04459054559401029\n",
      "-----------EPOCH-----------    ----->  1863\n",
      "Train Loss: 0.044589301911753594\n",
      "-----------EPOCH-----------    ----->  1864\n",
      "Train Loss: 0.044588058825452935\n",
      "-----------EPOCH-----------    ----->  1865\n",
      "Train Loss: 0.044586817585686514\n",
      "-----------EPOCH-----------    ----->  1866\n",
      "Train Loss: 0.0445855775984403\n",
      "-----------EPOCH-----------    ----->  1867\n",
      "Train Loss: 0.044584338762468416\n",
      "-----------EPOCH-----------    ----->  1868\n",
      "Train Loss: 0.04458309992133879\n",
      "-----------EPOCH-----------    ----->  1869\n",
      "Train Loss: 0.04458186150822947\n",
      "-----------EPOCH-----------    ----->  1870\n",
      "Train Loss: 0.04458062449329874\n",
      "-----------EPOCH-----------    ----->  1871\n",
      "Train Loss: 0.04457938941101654\n",
      "-----------EPOCH-----------    ----->  1872\n",
      "Train Loss: 0.04457815453851104\n",
      "-----------EPOCH-----------    ----->  1873\n",
      "Train Loss: 0.04457692165950555\n",
      "-----------EPOCH-----------    ----->  1874\n",
      "Train Loss: 0.04457568893328808\n",
      "-----------EPOCH-----------    ----->  1875\n",
      "Train Loss: 0.04457445419434711\n",
      "-----------EPOCH-----------    ----->  1876\n",
      "Train Loss: 0.044573221575466955\n",
      "-----------EPOCH-----------    ----->  1877\n",
      "Train Loss: 0.04457199067658849\n",
      "-----------EPOCH-----------    ----->  1878\n",
      "Train Loss: 0.04457075900554926\n",
      "-----------EPOCH-----------    ----->  1879\n",
      "Train Loss: 0.04456952799570589\n",
      "-----------EPOCH-----------    ----->  1880\n",
      "Train Loss: 0.044568299113129525\n",
      "-----------EPOCH-----------    ----->  1881\n",
      "Train Loss: 0.04456707158785391\n",
      "-----------EPOCH-----------    ----->  1882\n",
      "Train Loss: 0.044565844562383015\n",
      "-----------EPOCH-----------    ----->  1883\n",
      "Train Loss: 0.044564618193529006\n",
      "-----------EPOCH-----------    ----->  1884\n",
      "Train Loss: 0.04456339201137352\n",
      "-----------EPOCH-----------    ----->  1885\n",
      "Train Loss: 0.04456216724835318\n",
      "-----------EPOCH-----------    ----->  1886\n",
      "Train Loss: 0.044560943164898656\n",
      "-----------EPOCH-----------    ----->  1887\n",
      "Train Loss: 0.044559720439942566\n",
      "-----------EPOCH-----------    ----->  1888\n",
      "Train Loss: 0.04455849764502459\n",
      "-----------EPOCH-----------    ----->  1889\n",
      "Train Loss: 0.04455727545117698\n",
      "-----------EPOCH-----------    ----->  1890\n",
      "Train Loss: 0.04455605463552579\n",
      "-----------EPOCH-----------    ----->  1891\n",
      "Train Loss: 0.04455483399302292\n",
      "-----------EPOCH-----------    ----->  1892\n",
      "Train Loss: 0.0445536147538825\n",
      "-----------EPOCH-----------    ----->  1893\n",
      "Train Loss: 0.044552396342402864\n",
      "-----------EPOCH-----------    ----->  1894\n",
      "Train Loss: 0.04455117778591669\n",
      "-----------EPOCH-----------    ----->  1895\n",
      "Train Loss: 0.04454996028598128\n",
      "-----------EPOCH-----------    ----->  1896\n",
      "Train Loss: 0.044548743703421254\n",
      "-----------EPOCH-----------    ----->  1897\n",
      "Train Loss: 0.04454752768052033\n",
      "-----------EPOCH-----------    ----->  1898\n",
      "Train Loss: 0.04454631226882942\n",
      "-----------EPOCH-----------    ----->  1899\n",
      "Train Loss: 0.044545098078183396\n",
      "-----------EPOCH-----------    ----->  1900\n",
      "Train Loss: 0.044543883358709735\n",
      "-----------EPOCH-----------    ----->  1901\n",
      "Train Loss: 0.04454267116686013\n",
      "-----------EPOCH-----------    ----->  1902\n",
      "Train Loss: 0.04454146316667072\n",
      "-----------EPOCH-----------    ----->  1903\n",
      "Train Loss: 0.04454025791563001\n",
      "-----------EPOCH-----------    ----->  1904\n",
      "Train Loss: 0.04453905424912669\n",
      "-----------EPOCH-----------    ----->  1905\n",
      "Train Loss: 0.04453785186873163\n",
      "-----------EPOCH-----------    ----->  1906\n",
      "Train Loss: 0.044536649448576895\n",
      "-----------EPOCH-----------    ----->  1907\n",
      "Train Loss: 0.04453544713697648\n",
      "-----------EPOCH-----------    ----->  1908\n",
      "Train Loss: 0.04453424601575056\n",
      "-----------EPOCH-----------    ----->  1909\n",
      "Train Loss: 0.04453304596379996\n",
      "-----------EPOCH-----------    ----->  1910\n",
      "Train Loss: 0.04453184577734085\n",
      "-----------EPOCH-----------    ----->  1911\n",
      "Train Loss: 0.04453064703176789\n",
      "-----------EPOCH-----------    ----->  1912\n",
      "Train Loss: 0.04452944986774635\n",
      "-----------EPOCH-----------    ----->  1913\n",
      "Train Loss: 0.04452825343544475\n",
      "-----------EPOCH-----------    ----->  1914\n",
      "Train Loss: 0.044527057741362466\n",
      "-----------EPOCH-----------    ----->  1915\n",
      "Train Loss: 0.04452586285806332\n",
      "-----------EPOCH-----------    ----->  1916\n",
      "Train Loss: 0.044524668274188384\n",
      "-----------EPOCH-----------    ----->  1917\n",
      "Train Loss: 0.04452347532706146\n",
      "-----------EPOCH-----------    ----->  1918\n",
      "Train Loss: 0.044522281843848474\n",
      "-----------EPOCH-----------    ----->  1919\n",
      "Train Loss: 0.04452109021818242\n",
      "-----------EPOCH-----------    ----->  1920\n",
      "Train Loss: 0.044519897545347055\n",
      "-----------EPOCH-----------    ----->  1921\n",
      "Train Loss: 0.04451870563415542\n",
      "-----------EPOCH-----------    ----->  1922\n",
      "Train Loss: 0.04451750993603892\n",
      "-----------EPOCH-----------    ----->  1923\n",
      "Train Loss: 0.044516313638848934\n",
      "-----------EPOCH-----------    ----->  1924\n",
      "Train Loss: 0.04451511793689214\n",
      "-----------EPOCH-----------    ----->  1925\n",
      "Train Loss: 0.044513923021879793\n",
      "-----------EPOCH-----------    ----->  1926\n",
      "Train Loss: 0.04451272858137404\n",
      "-----------EPOCH-----------    ----->  1927\n",
      "Train Loss: 0.04451153413255923\n",
      "-----------EPOCH-----------    ----->  1928\n",
      "Train Loss: 0.04451034114447457\n",
      "-----------EPOCH-----------    ----->  1929\n",
      "Train Loss: 0.044509148947792565\n",
      "-----------EPOCH-----------    ----->  1930\n",
      "Train Loss: 0.044507956314028554\n",
      "-----------EPOCH-----------    ----->  1931\n",
      "Train Loss: 0.044506764605232806\n",
      "-----------EPOCH-----------    ----->  1932\n",
      "Train Loss: 0.04450557384838897\n",
      "-----------EPOCH-----------    ----->  1933\n",
      "Train Loss: 0.04450438402242308\n",
      "-----------EPOCH-----------    ----->  1934\n",
      "Train Loss: 0.04450319494586314\n",
      "-----------EPOCH-----------    ----->  1935\n",
      "Train Loss: 0.04450200793392062\n",
      "-----------EPOCH-----------    ----->  1936\n",
      "Train Loss: 0.044500820723080904\n",
      "-----------EPOCH-----------    ----->  1937\n",
      "Train Loss: 0.04449963387243696\n",
      "-----------EPOCH-----------    ----->  1938\n",
      "Train Loss: 0.044498448984050115\n",
      "-----------EPOCH-----------    ----->  1939\n",
      "Train Loss: 0.04449726542256603\n",
      "-----------EPOCH-----------    ----->  1940\n",
      "Train Loss: 0.044496082387889394\n",
      "-----------EPOCH-----------    ----->  1941\n",
      "Train Loss: 0.04449490012158657\n",
      "-----------EPOCH-----------    ----->  1942\n",
      "Train Loss: 0.04449371687199249\n",
      "-----------EPOCH-----------    ----->  1943\n",
      "Train Loss: 0.04449253551060113\n",
      "-----------EPOCH-----------    ----->  1944\n",
      "Train Loss: 0.04449135478766601\n",
      "-----------EPOCH-----------    ----->  1945\n",
      "Train Loss: 0.044490175454493804\n",
      "-----------EPOCH-----------    ----->  1946\n",
      "Train Loss: 0.0444889970435449\n",
      "-----------EPOCH-----------    ----->  1947\n",
      "Train Loss: 0.044487818810546594\n",
      "-----------EPOCH-----------    ----->  1948\n",
      "Train Loss: 0.044486640899237276\n",
      "-----------EPOCH-----------    ----->  1949\n",
      "Train Loss: 0.0444854654549959\n",
      "-----------EPOCH-----------    ----->  1950\n",
      "Train Loss: 0.04448429078166746\n",
      "-----------EPOCH-----------    ----->  1951\n",
      "Train Loss: 0.04448311697724774\n",
      "-----------EPOCH-----------    ----->  1952\n",
      "Train Loss: 0.04448194508959764\n",
      "-----------EPOCH-----------    ----->  1953\n",
      "Train Loss: 0.04448077281994496\n",
      "-----------EPOCH-----------    ----->  1954\n",
      "Train Loss: 0.044479599065296034\n",
      "-----------EPOCH-----------    ----->  1955\n",
      "Train Loss: 0.044478425665992784\n",
      "-----------EPOCH-----------    ----->  1956\n",
      "Train Loss: 0.044477253180837006\n",
      "-----------EPOCH-----------    ----->  1957\n",
      "Train Loss: 0.044476080804328744\n",
      "-----------EPOCH-----------    ----->  1958\n",
      "Train Loss: 0.044474910077346635\n",
      "-----------EPOCH-----------    ----->  1959\n",
      "Train Loss: 0.04447374068819415\n",
      "-----------EPOCH-----------    ----->  1960\n",
      "Train Loss: 0.04447257266873563\n",
      "-----------EPOCH-----------    ----->  1961\n",
      "Train Loss: 0.044471405879049616\n",
      "-----------EPOCH-----------    ----->  1962\n",
      "Train Loss: 0.044470240299158525\n",
      "-----------EPOCH-----------    ----->  1963\n",
      "Train Loss: 0.044469075634149736\n",
      "-----------EPOCH-----------    ----->  1964\n",
      "Train Loss: 0.0444679113964292\n",
      "-----------EPOCH-----------    ----->  1965\n",
      "Train Loss: 0.04446674821243332\n",
      "-----------EPOCH-----------    ----->  1966\n",
      "Train Loss: 0.044465586921789584\n",
      "-----------EPOCH-----------    ----->  1967\n",
      "Train Loss: 0.04446442605193079\n",
      "-----------EPOCH-----------    ----->  1968\n",
      "Train Loss: 0.044463265184222826\n",
      "-----------EPOCH-----------    ----->  1969\n",
      "Train Loss: 0.04446210645748405\n",
      "-----------EPOCH-----------    ----->  1970\n",
      "Train Loss: 0.044460947647417016\n",
      "-----------EPOCH-----------    ----->  1971\n",
      "Train Loss: 0.044459789954848936\n",
      "-----------EPOCH-----------    ----->  1972\n",
      "Train Loss: 0.044458632875618846\n",
      "-----------EPOCH-----------    ----->  1973\n",
      "Train Loss: 0.044457476956704926\n",
      "-----------EPOCH-----------    ----->  1974\n",
      "Train Loss: 0.04445632260525914\n",
      "-----------EPOCH-----------    ----->  1975\n",
      "Train Loss: 0.04445516954057264\n",
      "-----------EPOCH-----------    ----->  1976\n",
      "Train Loss: 0.04445401551914874\n",
      "-----------EPOCH-----------    ----->  1977\n",
      "Train Loss: 0.04445286221913072\n",
      "-----------EPOCH-----------    ----->  1978\n",
      "Train Loss: 0.044451707895767474\n",
      "-----------EPOCH-----------    ----->  1979\n",
      "Train Loss: 0.044450553734211806\n",
      "-----------EPOCH-----------    ----->  1980\n",
      "Train Loss: 0.04444940083351187\n",
      "-----------EPOCH-----------    ----->  1981\n",
      "Train Loss: 0.04444824957222269\n",
      "-----------EPOCH-----------    ----->  1982\n",
      "Train Loss: 0.04444709932446839\n",
      "-----------EPOCH-----------    ----->  1983\n",
      "Train Loss: 0.04444595116577587\n",
      "-----------EPOCH-----------    ----->  1984\n",
      "Train Loss: 0.04444480458768611\n",
      "-----------EPOCH-----------    ----->  1985\n",
      "Train Loss: 0.044443658335814984\n",
      "-----------EPOCH-----------    ----->  1986\n",
      "Train Loss: 0.04444251319426486\n",
      "-----------EPOCH-----------    ----->  1987\n",
      "Train Loss: 0.044441367870356616\n",
      "-----------EPOCH-----------    ----->  1988\n",
      "Train Loss: 0.044440224062312954\n",
      "-----------EPOCH-----------    ----->  1989\n",
      "Train Loss: 0.04443908120421764\n",
      "-----------EPOCH-----------    ----->  1990\n",
      "Train Loss: 0.04443793818147438\n",
      "-----------EPOCH-----------    ----->  1991\n",
      "Train Loss: 0.04443679782440523\n",
      "-----------EPOCH-----------    ----->  1992\n",
      "Train Loss: 0.04443565837101998\n",
      "-----------EPOCH-----------    ----->  1993\n",
      "Train Loss: 0.044434519623115974\n",
      "-----------EPOCH-----------    ----->  1994\n",
      "Train Loss: 0.04443338127430992\n",
      "-----------EPOCH-----------    ----->  1995\n",
      "Train Loss: 0.044432244539680726\n",
      "-----------EPOCH-----------    ----->  1996\n",
      "Train Loss: 0.044431107661423025\n",
      "-----------EPOCH-----------    ----->  1997\n",
      "Train Loss: 0.04442997102322884\n",
      "-----------EPOCH-----------    ----->  1998\n",
      "Train Loss: 0.04442883581496744\n",
      "-----------EPOCH-----------    ----->  1999\n",
      "Train Loss: 0.04442770310473348\n",
      "-----------EPOCH-----------    ----->  2000\n",
      "Train Loss: 0.044426572003788224\n",
      "-----------EPOCH-----------    ----->  2001\n",
      "Train Loss: 0.04442544175312334\n",
      "-----------EPOCH-----------    ----->  2002\n",
      "Train Loss: 0.04442431237755422\n",
      "-----------EPOCH-----------    ----->  2003\n",
      "Train Loss: 0.0444231835261301\n",
      "-----------EPOCH-----------    ----->  2004\n",
      "Train Loss: 0.04442205613724719\n",
      "-----------EPOCH-----------    ----->  2005\n",
      "Train Loss: 0.04442093024663727\n",
      "-----------EPOCH-----------    ----->  2006\n",
      "Train Loss: 0.04441980581731731\n",
      "-----------EPOCH-----------    ----->  2007\n",
      "Train Loss: 0.04441868440805924\n",
      "-----------EPOCH-----------    ----->  2008\n",
      "Train Loss: 0.04441756514133536\n",
      "-----------EPOCH-----------    ----->  2009\n",
      "Train Loss: 0.04441644730462996\n",
      "-----------EPOCH-----------    ----->  2010\n",
      "Train Loss: 0.044415330416305\n",
      "-----------EPOCH-----------    ----->  2011\n",
      "Train Loss: 0.044414213714668874\n",
      "-----------EPOCH-----------    ----->  2012\n",
      "Train Loss: 0.044413098172507964\n",
      "-----------EPOCH-----------    ----->  2013\n",
      "Train Loss: 0.04441198220479661\n",
      "-----------EPOCH-----------    ----->  2014\n",
      "Train Loss: 0.04441086719919205\n",
      "-----------EPOCH-----------    ----->  2015\n",
      "Train Loss: 0.04440975496093494\n",
      "-----------EPOCH-----------    ----->  2016\n",
      "Train Loss: 0.04440864160535081\n",
      "-----------EPOCH-----------    ----->  2017\n",
      "Train Loss: 0.044407528937679755\n",
      "-----------EPOCH-----------    ----->  2018\n",
      "Train Loss: 0.044406417499424235\n",
      "-----------EPOCH-----------    ----->  2019\n",
      "Train Loss: 0.04440530669478838\n",
      "-----------EPOCH-----------    ----->  2020\n",
      "Train Loss: 0.04440419621360455\n",
      "-----------EPOCH-----------    ----->  2021\n",
      "Train Loss: 0.044403086591892134\n",
      "-----------EPOCH-----------    ----->  2022\n",
      "Train Loss: 0.04440197925690453\n",
      "-----------EPOCH-----------    ----->  2023\n",
      "Train Loss: 0.04440087246592985\n",
      "-----------EPOCH-----------    ----->  2024\n",
      "Train Loss: 0.04439976600660095\n",
      "-----------EPOCH-----------    ----->  2025\n",
      "Train Loss: 0.04439866031221502\n",
      "-----------EPOCH-----------    ----->  2026\n",
      "Train Loss: 0.044397556194356806\n",
      "-----------EPOCH-----------    ----->  2027\n",
      "Train Loss: 0.04439645376894275\n",
      "-----------EPOCH-----------    ----->  2028\n",
      "Train Loss: 0.04439535256572812\n",
      "-----------EPOCH-----------    ----->  2029\n",
      "Train Loss: 0.044394253360819\n",
      "-----------EPOCH-----------    ----->  2030\n",
      "Train Loss: 0.044393155906362086\n",
      "-----------EPOCH-----------    ----->  2031\n",
      "Train Loss: 0.04439205896159929\n",
      "-----------EPOCH-----------    ----->  2032\n",
      "Train Loss: 0.044390963596858984\n",
      "-----------EPOCH-----------    ----->  2033\n",
      "Train Loss: 0.04438986928904478\n",
      "-----------EPOCH-----------    ----->  2034\n",
      "Train Loss: 0.044388776582272735\n",
      "-----------EPOCH-----------    ----->  2035\n",
      "Train Loss: 0.04438768523478475\n",
      "-----------EPOCH-----------    ----->  2036\n",
      "Train Loss: 0.04438659482670552\n",
      "-----------EPOCH-----------    ----->  2037\n",
      "Train Loss: 0.0443855058673416\n",
      "-----------EPOCH-----------    ----->  2038\n",
      "Train Loss: 0.044384418078953346\n",
      "-----------EPOCH-----------    ----->  2039\n",
      "Train Loss: 0.04438332994948176\n",
      "-----------EPOCH-----------    ----->  2040\n",
      "Train Loss: 0.0443822433357572\n",
      "-----------EPOCH-----------    ----->  2041\n",
      "Train Loss: 0.04438115754090202\n",
      "-----------EPOCH-----------    ----->  2042\n",
      "Train Loss: 0.044380071898629775\n",
      "-----------EPOCH-----------    ----->  2043\n",
      "Train Loss: 0.04437898719202962\n",
      "-----------EPOCH-----------    ----->  2044\n",
      "Train Loss: 0.044377903625345286\n",
      "-----------EPOCH-----------    ----->  2045\n",
      "Train Loss: 0.04437682171736033\n",
      "-----------EPOCH-----------    ----->  2046\n",
      "Train Loss: 0.04437573851804419\n",
      "-----------EPOCH-----------    ----->  2047\n",
      "Train Loss: 0.04437465684687781\n",
      "-----------EPOCH-----------    ----->  2048\n",
      "Train Loss: 0.04437357686456754\n",
      "-----------EPOCH-----------    ----->  2049\n",
      "Train Loss: 0.04437249679131893\n",
      "-----------EPOCH-----------    ----->  2050\n",
      "Train Loss: 0.04437141622069861\n",
      "-----------EPOCH-----------    ----->  2051\n",
      "Train Loss: 0.044370337286073744\n",
      "-----------EPOCH-----------    ----->  2052\n",
      "Train Loss: 0.04436926134104994\n",
      "-----------EPOCH-----------    ----->  2053\n",
      "Train Loss: 0.04436818702233956\n",
      "-----------EPOCH-----------    ----->  2054\n",
      "Train Loss: 0.04436711314273653\n",
      "-----------EPOCH-----------    ----->  2055\n",
      "Train Loss: 0.044366041059620345\n",
      "-----------EPOCH-----------    ----->  2056\n",
      "Train Loss: 0.044364970176849906\n",
      "-----------EPOCH-----------    ----->  2057\n",
      "Train Loss: 0.04436390027291771\n",
      "-----------EPOCH-----------    ----->  2058\n",
      "Train Loss: 0.04436283139516574\n",
      "-----------EPOCH-----------    ----->  2059\n",
      "Train Loss: 0.044361762891941714\n",
      "-----------EPOCH-----------    ----->  2060\n",
      "Train Loss: 0.04436069443862078\n",
      "-----------EPOCH-----------    ----->  2061\n",
      "Train Loss: 0.04435962718517279\n",
      "-----------EPOCH-----------    ----->  2062\n",
      "Train Loss: 0.044358559421449\n",
      "-----------EPOCH-----------    ----->  2063\n",
      "Train Loss: 0.0443574927889085\n",
      "-----------EPOCH-----------    ----->  2064\n",
      "Train Loss: 0.04435642430258316\n",
      "-----------EPOCH-----------    ----->  2065\n",
      "Train Loss: 0.044355356336296996\n",
      "-----------EPOCH-----------    ----->  2066\n",
      "Train Loss: 0.04435428811613638\n",
      "-----------EPOCH-----------    ----->  2067\n",
      "Train Loss: 0.04435321888993252\n",
      "-----------EPOCH-----------    ----->  2068\n",
      "Train Loss: 0.04435215140949549\n",
      "-----------EPOCH-----------    ----->  2069\n",
      "Train Loss: 0.04435108591628743\n",
      "-----------EPOCH-----------    ----->  2070\n",
      "Train Loss: 0.044350020722433624\n",
      "-----------EPOCH-----------    ----->  2071\n",
      "Train Loss: 0.04434895569689605\n",
      "-----------EPOCH-----------    ----->  2072\n",
      "Train Loss: 0.04434789283771128\n",
      "-----------EPOCH-----------    ----->  2073\n",
      "Train Loss: 0.04434683017876374\n",
      "-----------EPOCH-----------    ----->  2074\n",
      "Train Loss: 0.044345767292944024\n",
      "-----------EPOCH-----------    ----->  2075\n",
      "Train Loss: 0.04434470547916363\n",
      "-----------EPOCH-----------    ----->  2076\n",
      "Train Loss: 0.04434364560337311\n",
      "-----------EPOCH-----------    ----->  2077\n",
      "Train Loss: 0.044342586492224584\n",
      "-----------EPOCH-----------    ----->  2078\n",
      "Train Loss: 0.044341527756142377\n",
      "-----------EPOCH-----------    ----->  2079\n",
      "Train Loss: 0.0443404691823\n",
      "-----------EPOCH-----------    ----->  2080\n",
      "Train Loss: 0.044339407845545985\n",
      "-----------EPOCH-----------    ----->  2081\n",
      "Train Loss: 0.04433834568449607\n",
      "-----------EPOCH-----------    ----->  2082\n",
      "Train Loss: 0.04433728412007043\n",
      "-----------EPOCH-----------    ----->  2083\n",
      "Train Loss: 0.04433622350374039\n",
      "-----------EPOCH-----------    ----->  2084\n",
      "Train Loss: 0.044335164452341216\n",
      "-----------EPOCH-----------    ----->  2085\n",
      "Train Loss: 0.044334106977819074\n",
      "-----------EPOCH-----------    ----->  2086\n",
      "Train Loss: 0.044333052286033535\n",
      "-----------EPOCH-----------    ----->  2087\n",
      "Train Loss: 0.04433199706576742\n",
      "-----------EPOCH-----------    ----->  2088\n",
      "Train Loss: 0.04433094329984363\n",
      "-----------EPOCH-----------    ----->  2089\n",
      "Train Loss: 0.04432989046151834\n",
      "-----------EPOCH-----------    ----->  2090\n",
      "Train Loss: 0.04432883861192203\n",
      "-----------EPOCH-----------    ----->  2091\n",
      "Train Loss: 0.0443277868961557\n",
      "-----------EPOCH-----------    ----->  2092\n",
      "Train Loss: 0.04432673503954157\n",
      "-----------EPOCH-----------    ----->  2093\n",
      "Train Loss: 0.044325684257600674\n",
      "-----------EPOCH-----------    ----->  2094\n",
      "Train Loss: 0.04432463403662645\n",
      "-----------EPOCH-----------    ----->  2095\n",
      "Train Loss: 0.04432358615049151\n",
      "-----------EPOCH-----------    ----->  2096\n",
      "Train Loss: 0.04432253854780852\n",
      "-----------EPOCH-----------    ----->  2097\n",
      "Train Loss: 0.044321491153907676\n",
      "-----------EPOCH-----------    ----->  2098\n",
      "Train Loss: 0.044320444224086944\n",
      "-----------EPOCH-----------    ----->  2099\n",
      "Train Loss: 0.04431939912768088\n",
      "-----------EPOCH-----------    ----->  2100\n",
      "Train Loss: 0.044318355426948675\n",
      "-----------EPOCH-----------    ----->  2101\n",
      "Train Loss: 0.04431731170489091\n",
      "-----------EPOCH-----------    ----->  2102\n",
      "Train Loss: 0.04431626808369441\n",
      "-----------EPOCH-----------    ----->  2103\n",
      "Train Loss: 0.044315225690570136\n",
      "-----------EPOCH-----------    ----->  2104\n",
      "Train Loss: 0.04431418500139437\n",
      "-----------EPOCH-----------    ----->  2105\n",
      "Train Loss: 0.044313145861491994\n",
      "-----------EPOCH-----------    ----->  2106\n",
      "Train Loss: 0.04431210721009146\n",
      "-----------EPOCH-----------    ----->  2107\n",
      "Train Loss: 0.04431106744920464\n",
      "-----------EPOCH-----------    ----->  2108\n",
      "Train Loss: 0.04431002799566186\n",
      "-----------EPOCH-----------    ----->  2109\n",
      "Train Loss: 0.044308986562673035\n",
      "-----------EPOCH-----------    ----->  2110\n",
      "Train Loss: 0.04430794509449121\n",
      "-----------EPOCH-----------    ----->  2111\n",
      "Train Loss: 0.04430690519838142\n",
      "-----------EPOCH-----------    ----->  2112\n",
      "Train Loss: 0.04430586494066961\n",
      "-----------EPOCH-----------    ----->  2113\n",
      "Train Loss: 0.04430482627792131\n",
      "-----------EPOCH-----------    ----->  2114\n",
      "Train Loss: 0.04430378789179573\n",
      "-----------EPOCH-----------    ----->  2115\n",
      "Train Loss: 0.044302752009502795\n",
      "-----------EPOCH-----------    ----->  2116\n",
      "Train Loss: 0.04430171715358432\n",
      "-----------EPOCH-----------    ----->  2117\n",
      "Train Loss: 0.04430068468592326\n",
      "-----------EPOCH-----------    ----->  2118\n",
      "Train Loss: 0.04429965199827671\n",
      "-----------EPOCH-----------    ----->  2119\n",
      "Train Loss: 0.04429862017663722\n",
      "-----------EPOCH-----------    ----->  2120\n",
      "Train Loss: 0.04429758951383463\n",
      "-----------EPOCH-----------    ----->  2121\n",
      "Train Loss: 0.0442965601896289\n",
      "-----------EPOCH-----------    ----->  2122\n",
      "Train Loss: 0.04429553097095001\n",
      "-----------EPOCH-----------    ----->  2123\n",
      "Train Loss: 0.04429450128951527\n",
      "-----------EPOCH-----------    ----->  2124\n",
      "Train Loss: 0.04429347197577502\n",
      "-----------EPOCH-----------    ----->  2125\n",
      "Train Loss: 0.044292444936613835\n",
      "-----------EPOCH-----------    ----->  2126\n",
      "Train Loss: 0.044291418913166014\n",
      "-----------EPOCH-----------    ----->  2127\n",
      "Train Loss: 0.04429039465448801\n",
      "-----------EPOCH-----------    ----->  2128\n",
      "Train Loss: 0.04428937125822434\n",
      "-----------EPOCH-----------    ----->  2129\n",
      "Train Loss: 0.04428834850161831\n",
      "-----------EPOCH-----------    ----->  2130\n",
      "Train Loss: 0.04428732577594653\n",
      "-----------EPOCH-----------    ----->  2131\n",
      "Train Loss: 0.044286302129757094\n",
      "-----------EPOCH-----------    ----->  2132\n",
      "Train Loss: 0.044285279491558305\n",
      "-----------EPOCH-----------    ----->  2133\n",
      "Train Loss: 0.04428425648934376\n",
      "-----------EPOCH-----------    ----->  2134\n",
      "Train Loss: 0.04428323396561179\n",
      "-----------EPOCH-----------    ----->  2135\n",
      "Train Loss: 0.04428221320028225\n",
      "-----------EPOCH-----------    ----->  2136\n",
      "Train Loss: 0.04428119236011141\n",
      "-----------EPOCH-----------    ----->  2137\n",
      "Train Loss: 0.04428017229481471\n",
      "-----------EPOCH-----------    ----->  2138\n",
      "Train Loss: 0.04427915133824002\n",
      "-----------EPOCH-----------    ----->  2139\n",
      "Train Loss: 0.04427812992383098\n",
      "-----------EPOCH-----------    ----->  2140\n",
      "Train Loss: 0.044277109654633495\n",
      "-----------EPOCH-----------    ----->  2141\n",
      "Train Loss: 0.04427609096132077\n",
      "-----------EPOCH-----------    ----->  2142\n",
      "Train Loss: 0.04427507321589084\n",
      "-----------EPOCH-----------    ----->  2143\n",
      "Train Loss: 0.044274056808668416\n",
      "-----------EPOCH-----------    ----->  2144\n",
      "Train Loss: 0.04427304224723876\n",
      "-----------EPOCH-----------    ----->  2145\n",
      "Train Loss: 0.044272029467501896\n",
      "-----------EPOCH-----------    ----->  2146\n",
      "Train Loss: 0.04427101575119235\n",
      "-----------EPOCH-----------    ----->  2147\n",
      "Train Loss: 0.044270001787548384\n",
      "-----------EPOCH-----------    ----->  2148\n",
      "Train Loss: 0.04426898842756266\n",
      "-----------EPOCH-----------    ----->  2149\n",
      "Train Loss: 0.044267976170401686\n",
      "-----------EPOCH-----------    ----->  2150\n",
      "Train Loss: 0.04426696456320538\n",
      "-----------EPOCH-----------    ----->  2151\n",
      "Train Loss: 0.04426595301051422\n",
      "-----------EPOCH-----------    ----->  2152\n",
      "Train Loss: 0.044264943187382874\n",
      "-----------EPOCH-----------    ----->  2153\n",
      "Train Loss: 0.04426393124894016\n",
      "-----------EPOCH-----------    ----->  2154\n",
      "Train Loss: 0.04426292133081449\n",
      "-----------EPOCH-----------    ----->  2155\n",
      "Train Loss: 0.044261910937060917\n",
      "-----------EPOCH-----------    ----->  2156\n",
      "Train Loss: 0.04426090259305558\n",
      "-----------EPOCH-----------    ----->  2157\n",
      "Train Loss: 0.04425989443843025\n",
      "-----------EPOCH-----------    ----->  2158\n",
      "Train Loss: 0.044258889112609695\n",
      "-----------EPOCH-----------    ----->  2159\n",
      "Train Loss: 0.044257883947180686\n",
      "-----------EPOCH-----------    ----->  2160\n",
      "Train Loss: 0.04425687933196799\n",
      "-----------EPOCH-----------    ----->  2161\n",
      "Train Loss: 0.044255876427501686\n",
      "-----------EPOCH-----------    ----->  2162\n",
      "Train Loss: 0.04425487547847114\n",
      "-----------EPOCH-----------    ----->  2163\n",
      "Train Loss: 0.044253874728016375\n",
      "-----------EPOCH-----------    ----->  2164\n",
      "Train Loss: 0.0442528734085727\n",
      "-----------EPOCH-----------    ----->  2165\n",
      "Train Loss: 0.04425187249652707\n",
      "-----------EPOCH-----------    ----->  2166\n",
      "Train Loss: 0.04425087344611769\n",
      "-----------EPOCH-----------    ----->  2167\n",
      "Train Loss: 0.04424987532444564\n",
      "-----------EPOCH-----------    ----->  2168\n",
      "Train Loss: 0.044248879233067744\n",
      "-----------EPOCH-----------    ----->  2169\n",
      "Train Loss: 0.04424788528349566\n",
      "-----------EPOCH-----------    ----->  2170\n",
      "Train Loss: 0.04424689126892418\n",
      "-----------EPOCH-----------    ----->  2171\n",
      "Train Loss: 0.04424589997197514\n",
      "-----------EPOCH-----------    ----->  2172\n",
      "Train Loss: 0.0442449100602337\n",
      "-----------EPOCH-----------    ----->  2173\n",
      "Train Loss: 0.04424392095609283\n",
      "-----------EPOCH-----------    ----->  2174\n",
      "Train Loss: 0.044242932386219895\n",
      "-----------EPOCH-----------    ----->  2175\n",
      "Train Loss: 0.04424194541310395\n",
      "-----------EPOCH-----------    ----->  2176\n",
      "Train Loss: 0.044240957817499815\n",
      "-----------EPOCH-----------    ----->  2177\n",
      "Train Loss: 0.044239971665516756\n",
      "-----------EPOCH-----------    ----->  2178\n",
      "Train Loss: 0.044238985401499606\n",
      "-----------EPOCH-----------    ----->  2179\n",
      "Train Loss: 0.044237998941505124\n",
      "-----------EPOCH-----------    ----->  2180\n",
      "Train Loss: 0.04423701241070632\n",
      "-----------EPOCH-----------    ----->  2181\n",
      "Train Loss: 0.0442360269904891\n",
      "-----------EPOCH-----------    ----->  2182\n",
      "Train Loss: 0.044235043075061826\n",
      "-----------EPOCH-----------    ----->  2183\n",
      "Train Loss: 0.04423405922599387\n",
      "-----------EPOCH-----------    ----->  2184\n",
      "Train Loss: 0.044233075846429604\n",
      "-----------EPOCH-----------    ----->  2185\n",
      "Train Loss: 0.044232091928485796\n",
      "-----------EPOCH-----------    ----->  2186\n",
      "Train Loss: 0.044231109378091396\n",
      "-----------EPOCH-----------    ----->  2187\n",
      "Train Loss: 0.04423012801907282\n",
      "-----------EPOCH-----------    ----->  2188\n",
      "Train Loss: 0.04422914720977955\n",
      "-----------EPOCH-----------    ----->  2189\n",
      "Train Loss: 0.04422816744248473\n",
      "-----------EPOCH-----------    ----->  2190\n",
      "Train Loss: 0.04422719086448815\n",
      "-----------EPOCH-----------    ----->  2191\n",
      "Train Loss: 0.04422621550404378\n",
      "-----------EPOCH-----------    ----->  2192\n",
      "Train Loss: 0.0442252413940827\n",
      "-----------EPOCH-----------    ----->  2193\n",
      "Train Loss: 0.04422426758049541\n",
      "-----------EPOCH-----------    ----->  2194\n",
      "Train Loss: 0.044223294015521816\n",
      "-----------EPOCH-----------    ----->  2195\n",
      "Train Loss: 0.044222320081572716\n",
      "-----------EPOCH-----------    ----->  2196\n",
      "Train Loss: 0.04422134838003216\n",
      "-----------EPOCH-----------    ----->  2197\n",
      "Train Loss: 0.044220377126507074\n",
      "-----------EPOCH-----------    ----->  2198\n",
      "Train Loss: 0.044219408116320164\n",
      "-----------EPOCH-----------    ----->  2199\n",
      "Train Loss: 0.044218440845215194\n",
      "-----------EPOCH-----------    ----->  2200\n",
      "Train Loss: 0.04421747430384142\n",
      "-----------EPOCH-----------    ----->  2201\n",
      "Train Loss: 0.044216507917878886\n",
      "-----------EPOCH-----------    ----->  2202\n",
      "Train Loss: 0.04421554324029549\n",
      "-----------EPOCH-----------    ----->  2203\n",
      "Train Loss: 0.04421457874791425\n",
      "-----------EPOCH-----------    ----->  2204\n",
      "Train Loss: 0.04421361501620451\n",
      "-----------EPOCH-----------    ----->  2205\n",
      "Train Loss: 0.04421264852996682\n",
      "-----------EPOCH-----------    ----->  2206\n",
      "Train Loss: 0.0442116840395422\n",
      "-----------EPOCH-----------    ----->  2207\n",
      "Train Loss: 0.044210721037296126\n",
      "-----------EPOCH-----------    ----->  2208\n",
      "Train Loss: 0.04420975838862466\n",
      "-----------EPOCH-----------    ----->  2209\n",
      "Train Loss: 0.04420879615197478\n",
      "-----------EPOCH-----------    ----->  2210\n",
      "Train Loss: 0.04420783469004858\n",
      "-----------EPOCH-----------    ----->  2211\n",
      "Train Loss: 0.04420687356570601\n",
      "-----------EPOCH-----------    ----->  2212\n",
      "Train Loss: 0.044205911670463505\n",
      "-----------EPOCH-----------    ----->  2213\n",
      "Train Loss: 0.04420495048134913\n",
      "-----------EPOCH-----------    ----->  2214\n",
      "Train Loss: 0.04420398936776479\n",
      "-----------EPOCH-----------    ----->  2215\n",
      "Train Loss: 0.04420302925531737\n",
      "-----------EPOCH-----------    ----->  2216\n",
      "Train Loss: 0.044202070310725046\n",
      "-----------EPOCH-----------    ----->  2217\n",
      "Train Loss: 0.04420111177097013\n",
      "-----------EPOCH-----------    ----->  2218\n",
      "Train Loss: 0.04420015357851172\n",
      "-----------EPOCH-----------    ----->  2219\n",
      "Train Loss: 0.044199195196420564\n",
      "-----------EPOCH-----------    ----->  2220\n",
      "Train Loss: 0.04419823730191116\n",
      "-----------EPOCH-----------    ----->  2221\n",
      "Train Loss: 0.04419728036918163\n",
      "-----------EPOCH-----------    ----->  2222\n",
      "Train Loss: 0.04419632425943064\n",
      "-----------EPOCH-----------    ----->  2223\n",
      "Train Loss: 0.04419536864150563\n",
      "-----------EPOCH-----------    ----->  2224\n",
      "Train Loss: 0.04419441324199317\n",
      "-----------EPOCH-----------    ----->  2225\n",
      "Train Loss: 0.04419345888691319\n",
      "-----------EPOCH-----------    ----->  2226\n",
      "Train Loss: 0.0441925062306679\n",
      "-----------EPOCH-----------    ----->  2227\n",
      "Train Loss: 0.04419155489777625\n",
      "-----------EPOCH-----------    ----->  2228\n",
      "Train Loss: 0.0441906055801801\n",
      "-----------EPOCH-----------    ----->  2229\n",
      "Train Loss: 0.0441896566756245\n",
      "-----------EPOCH-----------    ----->  2230\n",
      "Train Loss: 0.04418870894266583\n",
      "-----------EPOCH-----------    ----->  2231\n",
      "Train Loss: 0.04418776242149563\n",
      "-----------EPOCH-----------    ----->  2232\n",
      "Train Loss: 0.0441868173890084\n",
      "-----------EPOCH-----------    ----->  2233\n",
      "Train Loss: 0.04418587330555088\n",
      "-----------EPOCH-----------    ----->  2234\n",
      "Train Loss: 0.044184929145175\n",
      "-----------EPOCH-----------    ----->  2235\n",
      "Train Loss: 0.04418398595190788\n",
      "-----------EPOCH-----------    ----->  2236\n",
      "Train Loss: 0.04418304467324513\n",
      "-----------EPOCH-----------    ----->  2237\n",
      "Train Loss: 0.044182103359349446\n",
      "-----------EPOCH-----------    ----->  2238\n",
      "Train Loss: 0.0441811631850332\n",
      "-----------EPOCH-----------    ----->  2239\n",
      "Train Loss: 0.04418022478065732\n",
      "-----------EPOCH-----------    ----->  2240\n",
      "Train Loss: 0.04417928715260906\n",
      "-----------EPOCH-----------    ----->  2241\n",
      "Train Loss: 0.044178351445346986\n",
      "-----------EPOCH-----------    ----->  2242\n",
      "Train Loss: 0.044177416174968204\n",
      "-----------EPOCH-----------    ----->  2243\n",
      "Train Loss: 0.044176481894182176\n",
      "-----------EPOCH-----------    ----->  2244\n",
      "Train Loss: 0.04417554779746298\n",
      "-----------EPOCH-----------    ----->  2245\n",
      "Train Loss: 0.04417461422308373\n",
      "-----------EPOCH-----------    ----->  2246\n",
      "Train Loss: 0.04417368167390838\n",
      "-----------EPOCH-----------    ----->  2247\n",
      "Train Loss: 0.04417274937805499\n",
      "-----------EPOCH-----------    ----->  2248\n",
      "Train Loss: 0.04417181825086356\n",
      "-----------EPOCH-----------    ----->  2249\n",
      "Train Loss: 0.044170888441166706\n",
      "-----------EPOCH-----------    ----->  2250\n",
      "Train Loss: 0.04416995875700476\n",
      "-----------EPOCH-----------    ----->  2251\n",
      "Train Loss: 0.04416902820285607\n",
      "-----------EPOCH-----------    ----->  2252\n",
      "Train Loss: 0.04416809791952732\n",
      "-----------EPOCH-----------    ----->  2253\n",
      "Train Loss: 0.044167167946223274\n",
      "-----------EPOCH-----------    ----->  2254\n",
      "Train Loss: 0.04416623907560494\n",
      "-----------EPOCH-----------    ----->  2255\n",
      "Train Loss: 0.044165310977809374\n",
      "-----------EPOCH-----------    ----->  2256\n",
      "Train Loss: 0.04416438337318718\n",
      "-----------EPOCH-----------    ----->  2257\n",
      "Train Loss: 0.0441634571299619\n",
      "-----------EPOCH-----------    ----->  2258\n",
      "Train Loss: 0.04416253124303925\n",
      "-----------EPOCH-----------    ----->  2259\n",
      "Train Loss: 0.04416160657052522\n",
      "-----------EPOCH-----------    ----->  2260\n",
      "Train Loss: 0.04416068303698637\n",
      "-----------EPOCH-----------    ----->  2261\n",
      "Train Loss: 0.04415976011477693\n",
      "-----------EPOCH-----------    ----->  2262\n",
      "Train Loss: 0.044158836533526195\n",
      "-----------EPOCH-----------    ----->  2263\n",
      "Train Loss: 0.04415791417001215\n",
      "-----------EPOCH-----------    ----->  2264\n",
      "Train Loss: 0.04415699367337129\n",
      "-----------EPOCH-----------    ----->  2265\n",
      "Train Loss: 0.04415607412214749\n",
      "-----------EPOCH-----------    ----->  2266\n",
      "Train Loss: 0.04415515593584069\n",
      "-----------EPOCH-----------    ----->  2267\n",
      "Train Loss: 0.044154238276737846\n",
      "-----------EPOCH-----------    ----->  2268\n",
      "Train Loss: 0.044153320842396364\n",
      "-----------EPOCH-----------    ----->  2269\n",
      "Train Loss: 0.04415240376749867\n",
      "-----------EPOCH-----------    ----->  2270\n",
      "Train Loss: 0.04415148700527738\n",
      "-----------EPOCH-----------    ----->  2271\n",
      "Train Loss: 0.04415057019018173\n",
      "-----------EPOCH-----------    ----->  2272\n",
      "Train Loss: 0.04414965453183117\n",
      "-----------EPOCH-----------    ----->  2273\n",
      "Train Loss: 0.04414874047968503\n",
      "-----------EPOCH-----------    ----->  2274\n",
      "Train Loss: 0.04414782594828515\n",
      "-----------EPOCH-----------    ----->  2275\n",
      "Train Loss: 0.044146911354310335\n",
      "-----------EPOCH-----------    ----->  2276\n",
      "Train Loss: 0.044145995804002164\n",
      "-----------EPOCH-----------    ----->  2277\n",
      "Train Loss: 0.04414508147075329\n",
      "-----------EPOCH-----------    ----->  2278\n",
      "Train Loss: 0.04414416763604394\n",
      "-----------EPOCH-----------    ----->  2279\n",
      "Train Loss: 0.044143254405672946\n",
      "-----------EPOCH-----------    ----->  2280\n",
      "Train Loss: 0.044142343218911174\n",
      "-----------EPOCH-----------    ----->  2281\n",
      "Train Loss: 0.04414143130576186\n",
      "-----------EPOCH-----------    ----->  2282\n",
      "Train Loss: 0.044140518777939425\n",
      "-----------EPOCH-----------    ----->  2283\n",
      "Train Loss: 0.04413960566807928\n",
      "-----------EPOCH-----------    ----->  2284\n",
      "Train Loss: 0.04413869234269374\n",
      "-----------EPOCH-----------    ----->  2285\n",
      "Train Loss: 0.0441377797726063\n",
      "-----------EPOCH-----------    ----->  2286\n",
      "Train Loss: 0.044136868254013424\n",
      "-----------EPOCH-----------    ----->  2287\n",
      "Train Loss: 0.0441359570744918\n",
      "-----------EPOCH-----------    ----->  2288\n",
      "Train Loss: 0.044135046534333894\n",
      "-----------EPOCH-----------    ----->  2289\n",
      "Train Loss: 0.04413413569250143\n",
      "-----------EPOCH-----------    ----->  2290\n",
      "Train Loss: 0.044133225939313445\n",
      "-----------EPOCH-----------    ----->  2291\n",
      "Train Loss: 0.04413231742484336\n",
      "-----------EPOCH-----------    ----->  2292\n",
      "Train Loss: 0.04413140669443507\n",
      "-----------EPOCH-----------    ----->  2293\n",
      "Train Loss: 0.04413049637408049\n",
      "-----------EPOCH-----------    ----->  2294\n",
      "Train Loss: 0.04412958668097745\n",
      "-----------EPOCH-----------    ----->  2295\n",
      "Train Loss: 0.04412867677054963\n",
      "-----------EPOCH-----------    ----->  2296\n",
      "Train Loss: 0.04412776774966401\n",
      "-----------EPOCH-----------    ----->  2297\n",
      "Train Loss: 0.04412685870122307\n",
      "-----------EPOCH-----------    ----->  2298\n",
      "Train Loss: 0.04412595022082969\n",
      "-----------EPOCH-----------    ----->  2299\n",
      "Train Loss: 0.04412504183889844\n",
      "-----------EPOCH-----------    ----->  2300\n",
      "Train Loss: 0.04412413479551501\n",
      "-----------EPOCH-----------    ----->  2301\n",
      "Train Loss: 0.04412322893126671\n",
      "-----------EPOCH-----------    ----->  2302\n",
      "Train Loss: 0.04412232423365737\n",
      "-----------EPOCH-----------    ----->  2303\n",
      "Train Loss: 0.044121419775231895\n",
      "-----------EPOCH-----------    ----->  2304\n",
      "Train Loss: 0.044120516415966135\n",
      "-----------EPOCH-----------    ----->  2305\n",
      "Train Loss: 0.044119613935701865\n",
      "-----------EPOCH-----------    ----->  2306\n",
      "Train Loss: 0.04411871240710902\n",
      "-----------EPOCH-----------    ----->  2307\n",
      "Train Loss: 0.04411781103449941\n",
      "-----------EPOCH-----------    ----->  2308\n",
      "Train Loss: 0.04411691138218836\n",
      "-----------EPOCH-----------    ----->  2309\n",
      "Train Loss: 0.04411601380338324\n",
      "-----------EPOCH-----------    ----->  2310\n",
      "Train Loss: 0.0441151172503949\n",
      "-----------EPOCH-----------    ----->  2311\n",
      "Train Loss: 0.044114221104718195\n",
      "-----------EPOCH-----------    ----->  2312\n",
      "Train Loss: 0.044113325525998094\n",
      "-----------EPOCH-----------    ----->  2313\n",
      "Train Loss: 0.0441124308771826\n",
      "-----------EPOCH-----------    ----->  2314\n",
      "Train Loss: 0.04411153667816981\n",
      "-----------EPOCH-----------    ----->  2315\n",
      "Train Loss: 0.04411064061871866\n",
      "-----------EPOCH-----------    ----->  2316\n",
      "Train Loss: 0.04410974539286072\n",
      "-----------EPOCH-----------    ----->  2317\n",
      "Train Loss: 0.044108850176772386\n",
      "-----------EPOCH-----------    ----->  2318\n",
      "Train Loss: 0.04410795435155455\n",
      "-----------EPOCH-----------    ----->  2319\n",
      "Train Loss: 0.0441070602924883\n",
      "-----------EPOCH-----------    ----->  2320\n",
      "Train Loss: 0.044106166925706534\n",
      "-----------EPOCH-----------    ----->  2321\n",
      "Train Loss: 0.044105274665519154\n",
      "-----------EPOCH-----------    ----->  2322\n",
      "Train Loss: 0.044104383727952626\n",
      "-----------EPOCH-----------    ----->  2323\n",
      "Train Loss: 0.044103493379884944\n",
      "-----------EPOCH-----------    ----->  2324\n",
      "Train Loss: 0.04410260430311224\n",
      "-----------EPOCH-----------    ----->  2325\n",
      "Train Loss: 0.04410171532967267\n",
      "-----------EPOCH-----------    ----->  2326\n",
      "Train Loss: 0.04410082568997549\n",
      "-----------EPOCH-----------    ----->  2327\n",
      "Train Loss: 0.04409993666484935\n",
      "-----------EPOCH-----------    ----->  2328\n",
      "Train Loss: 0.04409904851130727\n",
      "-----------EPOCH-----------    ----->  2329\n",
      "Train Loss: 0.04409816081400265\n",
      "-----------EPOCH-----------    ----->  2330\n",
      "Train Loss: 0.04409727325021911\n",
      "-----------EPOCH-----------    ----->  2331\n",
      "Train Loss: 0.044096385759093644\n",
      "-----------EPOCH-----------    ----->  2332\n",
      "Train Loss: 0.04409549923688323\n",
      "-----------EPOCH-----------    ----->  2333\n",
      "Train Loss: 0.04409461431577318\n",
      "-----------EPOCH-----------    ----->  2334\n",
      "Train Loss: 0.04409373029526163\n",
      "-----------EPOCH-----------    ----->  2335\n",
      "Train Loss: 0.04409284724115666\n",
      "-----------EPOCH-----------    ----->  2336\n",
      "Train Loss: 0.04409196457278129\n",
      "-----------EPOCH-----------    ----->  2337\n",
      "Train Loss: 0.044091081438254624\n",
      "-----------EPOCH-----------    ----->  2338\n",
      "Train Loss: 0.0440901986514948\n",
      "-----------EPOCH-----------    ----->  2339\n",
      "Train Loss: 0.04408931632286052\n",
      "-----------EPOCH-----------    ----->  2340\n",
      "Train Loss: 0.044088433400867946\n",
      "-----------EPOCH-----------    ----->  2341\n",
      "Train Loss: 0.044087550652613154\n",
      "-----------EPOCH-----------    ----->  2342\n",
      "Train Loss: 0.04408666833995884\n",
      "-----------EPOCH-----------    ----->  2343\n",
      "Train Loss: 0.04408578694777338\n",
      "-----------EPOCH-----------    ----->  2344\n",
      "Train Loss: 0.04408490680257704\n",
      "-----------EPOCH-----------    ----->  2345\n",
      "Train Loss: 0.044084027208455064\n",
      "-----------EPOCH-----------    ----->  2346\n",
      "Train Loss: 0.044083147285432216\n",
      "-----------EPOCH-----------    ----->  2347\n",
      "Train Loss: 0.044082267144239747\n",
      "-----------EPOCH-----------    ----->  2348\n",
      "Train Loss: 0.044081387999857786\n",
      "-----------EPOCH-----------    ----->  2349\n",
      "Train Loss: 0.0440805096291839\n",
      "-----------EPOCH-----------    ----->  2350\n",
      "Train Loss: 0.044079632211121524\n",
      "-----------EPOCH-----------    ----->  2351\n",
      "Train Loss: 0.044078755119365834\n",
      "-----------EPOCH-----------    ----->  2352\n",
      "Train Loss: 0.044077878665257676\n",
      "-----------EPOCH-----------    ----->  2353\n",
      "Train Loss: 0.044077003213386985\n",
      "-----------EPOCH-----------    ----->  2354\n",
      "Train Loss: 0.04407612845635877\n",
      "-----------EPOCH-----------    ----->  2355\n",
      "Train Loss: 0.044075255331861116\n",
      "-----------EPOCH-----------    ----->  2356\n",
      "Train Loss: 0.04407438263729234\n",
      "-----------EPOCH-----------    ----->  2357\n",
      "Train Loss: 0.04407351091004688\n",
      "-----------EPOCH-----------    ----->  2358\n",
      "Train Loss: 0.044072638829442665\n",
      "-----------EPOCH-----------    ----->  2359\n",
      "Train Loss: 0.04407176885848174\n",
      "-----------EPOCH-----------    ----->  2360\n",
      "Train Loss: 0.044070901666379926\n",
      "-----------EPOCH-----------    ----->  2361\n",
      "Train Loss: 0.044070035280334714\n",
      "-----------EPOCH-----------    ----->  2362\n",
      "Train Loss: 0.04406916812478497\n",
      "-----------EPOCH-----------    ----->  2363\n",
      "Train Loss: 0.04406830144561254\n",
      "-----------EPOCH-----------    ----->  2364\n",
      "Train Loss: 0.04406743453769868\n",
      "-----------EPOCH-----------    ----->  2365\n",
      "Train Loss: 0.044066567476529664\n",
      "-----------EPOCH-----------    ----->  2366\n",
      "Train Loss: 0.044065700543962354\n",
      "-----------EPOCH-----------    ----->  2367\n",
      "Train Loss: 0.044064833743336404\n",
      "-----------EPOCH-----------    ----->  2368\n",
      "Train Loss: 0.04406396518911523\n",
      "-----------EPOCH-----------    ----->  2369\n",
      "Train Loss: 0.044063097370641235\n",
      "-----------EPOCH-----------    ----->  2370\n",
      "Train Loss: 0.04406223034279997\n",
      "-----------EPOCH-----------    ----->  2371\n",
      "Train Loss: 0.044061364291490705\n",
      "-----------EPOCH-----------    ----->  2372\n",
      "Train Loss: 0.04406049834058384\n",
      "-----------EPOCH-----------    ----->  2373\n",
      "Train Loss: 0.04405963391772416\n",
      "-----------EPOCH-----------    ----->  2374\n",
      "Train Loss: 0.04405877155030793\n",
      "-----------EPOCH-----------    ----->  2375\n",
      "Train Loss: 0.044057909619495676\n",
      "-----------EPOCH-----------    ----->  2376\n",
      "Train Loss: 0.0440570486082448\n",
      "-----------EPOCH-----------    ----->  2377\n",
      "Train Loss: 0.04405618809353709\n",
      "-----------EPOCH-----------    ----->  2378\n",
      "Train Loss: 0.04405532627010667\n",
      "-----------EPOCH-----------    ----->  2379\n",
      "Train Loss: 0.04405446429251538\n",
      "-----------EPOCH-----------    ----->  2380\n",
      "Train Loss: 0.04405360180574832\n",
      "-----------EPOCH-----------    ----->  2381\n",
      "Train Loss: 0.044052740019322405\n",
      "-----------EPOCH-----------    ----->  2382\n",
      "Train Loss: 0.044051879897768056\n",
      "-----------EPOCH-----------    ----->  2383\n",
      "Train Loss: 0.044051020568166\n",
      "-----------EPOCH-----------    ----->  2384\n",
      "Train Loss: 0.0440501619789102\n",
      "-----------EPOCH-----------    ----->  2385\n",
      "Train Loss: 0.0440493044923578\n",
      "-----------EPOCH-----------    ----->  2386\n",
      "Train Loss: 0.04404844783880235\n",
      "-----------EPOCH-----------    ----->  2387\n",
      "Train Loss: 0.04404759234091761\n",
      "-----------EPOCH-----------    ----->  2388\n",
      "Train Loss: 0.044046737567200414\n",
      "-----------EPOCH-----------    ----->  2389\n",
      "Train Loss: 0.04404588394415638\n",
      "-----------EPOCH-----------    ----->  2390\n",
      "Train Loss: 0.04404503122909076\n",
      "-----------EPOCH-----------    ----->  2391\n",
      "Train Loss: 0.04404417888863474\n",
      "-----------EPOCH-----------    ----->  2392\n",
      "Train Loss: 0.04404332745446243\n",
      "-----------EPOCH-----------    ----->  2393\n",
      "Train Loss: 0.04404247758743159\n",
      "-----------EPOCH-----------    ----->  2394\n",
      "Train Loss: 0.04404162927416611\n",
      "-----------EPOCH-----------    ----->  2395\n",
      "Train Loss: 0.04404078174751512\n",
      "-----------EPOCH-----------    ----->  2396\n",
      "Train Loss: 0.04403993531404607\n",
      "-----------EPOCH-----------    ----->  2397\n",
      "Train Loss: 0.044039088654882194\n",
      "-----------EPOCH-----------    ----->  2398\n",
      "Train Loss: 0.044038240865868175\n",
      "-----------EPOCH-----------    ----->  2399\n",
      "Train Loss: 0.04403739204207555\n",
      "-----------EPOCH-----------    ----->  2400\n",
      "Train Loss: 0.044036543638872425\n",
      "-----------EPOCH-----------    ----->  2401\n",
      "Train Loss: 0.04403569619472671\n",
      "-----------EPOCH-----------    ----->  2402\n",
      "Train Loss: 0.0440348496720836\n",
      "-----------EPOCH-----------    ----->  2403\n",
      "Train Loss: 0.04403400341787309\n",
      "-----------EPOCH-----------    ----->  2404\n",
      "Train Loss: 0.04403315865462622\n",
      "-----------EPOCH-----------    ----->  2405\n",
      "Train Loss: 0.044032315202868835\n",
      "-----------EPOCH-----------    ----->  2406\n",
      "Train Loss: 0.04403147272565073\n",
      "-----------EPOCH-----------    ----->  2407\n",
      "Train Loss: 0.044030630999310726\n",
      "-----------EPOCH-----------    ----->  2408\n",
      "Train Loss: 0.044029790442507086\n",
      "-----------EPOCH-----------    ----->  2409\n",
      "Train Loss: 0.04402894975587616\n",
      "-----------EPOCH-----------    ----->  2410\n",
      "Train Loss: 0.04402810956791118\n",
      "-----------EPOCH-----------    ----->  2411\n",
      "Train Loss: 0.04402727107297398\n",
      "-----------EPOCH-----------    ----->  2412\n",
      "Train Loss: 0.04402643362662766\n",
      "-----------EPOCH-----------    ----->  2413\n",
      "Train Loss: 0.04402559669046035\n",
      "-----------EPOCH-----------    ----->  2414\n",
      "Train Loss: 0.04402476060877026\n",
      "-----------EPOCH-----------    ----->  2415\n",
      "Train Loss: 0.04402392467324597\n",
      "-----------EPOCH-----------    ----->  2416\n",
      "Train Loss: 0.04402308946604177\n",
      "-----------EPOCH-----------    ----->  2417\n",
      "Train Loss: 0.04402225537499942\n",
      "-----------EPOCH-----------    ----->  2418\n",
      "Train Loss: 0.04402142106828805\n",
      "-----------EPOCH-----------    ----->  2419\n",
      "Train Loss: 0.04402058803337952\n",
      "-----------EPOCH-----------    ----->  2420\n",
      "Train Loss: 0.04401975603275647\n",
      "-----------EPOCH-----------    ----->  2421\n",
      "Train Loss: 0.04401892421766076\n",
      "-----------EPOCH-----------    ----->  2422\n",
      "Train Loss: 0.04401809423578541\n",
      "-----------EPOCH-----------    ----->  2423\n",
      "Train Loss: 0.04401726541311332\n",
      "-----------EPOCH-----------    ----->  2424\n",
      "Train Loss: 0.04401643709463506\n",
      "-----------EPOCH-----------    ----->  2425\n",
      "Train Loss: 0.044015609582472325\n",
      "-----------EPOCH-----------    ----->  2426\n",
      "Train Loss: 0.04401478221560461\n",
      "-----------EPOCH-----------    ----->  2427\n",
      "Train Loss: 0.04401395662842522\n",
      "-----------EPOCH-----------    ----->  2428\n",
      "Train Loss: 0.04401313221767846\n",
      "-----------EPOCH-----------    ----->  2429\n",
      "Train Loss: 0.04401230847509135\n",
      "-----------EPOCH-----------    ----->  2430\n",
      "Train Loss: 0.044011486054235646\n",
      "-----------EPOCH-----------    ----->  2431\n",
      "Train Loss: 0.04401066377751301\n",
      "-----------EPOCH-----------    ----->  2432\n",
      "Train Loss: 0.044009842379519236\n",
      "-----------EPOCH-----------    ----->  2433\n",
      "Train Loss: 0.04400902115170176\n",
      "-----------EPOCH-----------    ----->  2434\n",
      "Train Loss: 0.04400820057887682\n",
      "-----------EPOCH-----------    ----->  2435\n",
      "Train Loss: 0.04400737687368678\n",
      "-----------EPOCH-----------    ----->  2436\n",
      "Train Loss: 0.044006552355299884\n",
      "-----------EPOCH-----------    ----->  2437\n",
      "Train Loss: 0.044005727922783525\n",
      "-----------EPOCH-----------    ----->  2438\n",
      "Train Loss: 0.04400490329219325\n",
      "-----------EPOCH-----------    ----->  2439\n",
      "Train Loss: 0.04400407980218172\n",
      "-----------EPOCH-----------    ----->  2440\n",
      "Train Loss: 0.0440032570923424\n",
      "-----------EPOCH-----------    ----->  2441\n",
      "Train Loss: 0.04400243542732107\n",
      "-----------EPOCH-----------    ----->  2442\n",
      "Train Loss: 0.04400161349002308\n",
      "-----------EPOCH-----------    ----->  2443\n",
      "Train Loss: 0.04400079113555126\n",
      "-----------EPOCH-----------    ----->  2444\n",
      "Train Loss: 0.04399996881092006\n",
      "-----------EPOCH-----------    ----->  2445\n",
      "Train Loss: 0.0439991467277434\n",
      "-----------EPOCH-----------    ----->  2446\n",
      "Train Loss: 0.043998324440262505\n",
      "-----------EPOCH-----------    ----->  2447\n",
      "Train Loss: 0.04399750251260272\n",
      "-----------EPOCH-----------    ----->  2448\n",
      "Train Loss: 0.043996679317179474\n",
      "-----------EPOCH-----------    ----->  2449\n",
      "Train Loss: 0.04399585767780927\n",
      "-----------EPOCH-----------    ----->  2450\n",
      "Train Loss: 0.04399503695899742\n",
      "-----------EPOCH-----------    ----->  2451\n",
      "Train Loss: 0.04399421893444936\n",
      "-----------EPOCH-----------    ----->  2452\n",
      "Train Loss: 0.04399340120916595\n",
      "-----------EPOCH-----------    ----->  2453\n",
      "Train Loss: 0.04399258446337624\n",
      "-----------EPOCH-----------    ----->  2454\n",
      "Train Loss: 0.043991767852246885\n",
      "-----------EPOCH-----------    ----->  2455\n",
      "Train Loss: 0.043990952044119826\n",
      "-----------EPOCH-----------    ----->  2456\n",
      "Train Loss: 0.043990136466997586\n",
      "-----------EPOCH-----------    ----->  2457\n",
      "Train Loss: 0.04398932053291373\n",
      "-----------EPOCH-----------    ----->  2458\n",
      "Train Loss: 0.04398850450720988\n",
      "-----------EPOCH-----------    ----->  2459\n",
      "Train Loss: 0.043987688714961344\n",
      "-----------EPOCH-----------    ----->  2460\n",
      "Train Loss: 0.04398687449752373\n",
      "-----------EPOCH-----------    ----->  2461\n",
      "Train Loss: 0.043986060856708635\n",
      "-----------EPOCH-----------    ----->  2462\n",
      "Train Loss: 0.04398524739037398\n",
      "-----------EPOCH-----------    ----->  2463\n",
      "Train Loss: 0.043984434398556586\n",
      "-----------EPOCH-----------    ----->  2464\n",
      "Train Loss: 0.04398362145427772\n",
      "-----------EPOCH-----------    ----->  2465\n",
      "Train Loss: 0.043982809431604604\n",
      "-----------EPOCH-----------    ----->  2466\n",
      "Train Loss: 0.04398199875233966\n",
      "-----------EPOCH-----------    ----->  2467\n",
      "Train Loss: 0.04398118828805139\n",
      "-----------EPOCH-----------    ----->  2468\n",
      "Train Loss: 0.04398037714282625\n",
      "-----------EPOCH-----------    ----->  2469\n",
      "Train Loss: 0.04397956546652882\n",
      "-----------EPOCH-----------    ----->  2470\n",
      "Train Loss: 0.04397875451690162\n",
      "-----------EPOCH-----------    ----->  2471\n",
      "Train Loss: 0.04397794436547015\n",
      "-----------EPOCH-----------    ----->  2472\n",
      "Train Loss: 0.04397713487973342\n",
      "-----------EPOCH-----------    ----->  2473\n",
      "Train Loss: 0.043976325726554605\n",
      "-----------EPOCH-----------    ----->  2474\n",
      "Train Loss: 0.04397551775475117\n",
      "-----------EPOCH-----------    ----->  2475\n",
      "Train Loss: 0.0439747106236158\n",
      "-----------EPOCH-----------    ----->  2476\n",
      "Train Loss: 0.04397390422201071\n",
      "-----------EPOCH-----------    ----->  2477\n",
      "Train Loss: 0.0439730986866233\n",
      "-----------EPOCH-----------    ----->  2478\n",
      "Train Loss: 0.043972293948725975\n",
      "-----------EPOCH-----------    ----->  2479\n",
      "Train Loss: 0.04397148981273447\n",
      "-----------EPOCH-----------    ----->  2480\n",
      "Train Loss: 0.04397068646170427\n",
      "-----------EPOCH-----------    ----->  2481\n",
      "Train Loss: 0.043969882442007995\n",
      "-----------EPOCH-----------    ----->  2482\n",
      "Train Loss: 0.04396907766139314\n",
      "-----------EPOCH-----------    ----->  2483\n",
      "Train Loss: 0.043968273237781894\n",
      "-----------EPOCH-----------    ----->  2484\n",
      "Train Loss: 0.04396746958945725\n",
      "-----------EPOCH-----------    ----->  2485\n",
      "Train Loss: 0.04396666748441331\n",
      "-----------EPOCH-----------    ----->  2486\n",
      "Train Loss: 0.043965866124195535\n",
      "-----------EPOCH-----------    ----->  2487\n",
      "Train Loss: 0.043965065258463776\n",
      "-----------EPOCH-----------    ----->  2488\n",
      "Train Loss: 0.04396426465955707\n",
      "-----------EPOCH-----------    ----->  2489\n",
      "Train Loss: 0.04396346475576665\n",
      "-----------EPOCH-----------    ----->  2490\n",
      "Train Loss: 0.04396266572483237\n",
      "-----------EPOCH-----------    ----->  2491\n",
      "Train Loss: 0.04396186756328275\n",
      "-----------EPOCH-----------    ----->  2492\n",
      "Train Loss: 0.043961069667361796\n",
      "-----------EPOCH-----------    ----->  2493\n",
      "Train Loss: 0.04396027011825761\n",
      "-----------EPOCH-----------    ----->  2494\n",
      "Train Loss: 0.04395947183091662\n",
      "-----------EPOCH-----------    ----->  2495\n",
      "Train Loss: 0.04395867451921643\n",
      "-----------EPOCH-----------    ----->  2496\n",
      "Train Loss: 0.04395787757660981\n",
      "-----------EPOCH-----------    ----->  2497\n",
      "Train Loss: 0.04395708119983067\n",
      "-----------EPOCH-----------    ----->  2498\n",
      "Train Loss: 0.04395628458807305\n",
      "-----------EPOCH-----------    ----->  2499\n",
      "Train Loss: 0.043955488761720916\n",
      "-----------EPOCH-----------    ----->  2500\n",
      "Train Loss: 0.04395469405251355\n",
      "-----------EPOCH-----------    ----->  2501\n",
      "Train Loss: 0.043953900016593245\n",
      "-----------EPOCH-----------    ----->  2502\n",
      "Train Loss: 0.04395310705796162\n",
      "-----------EPOCH-----------    ----->  2503\n",
      "Train Loss: 0.04395231437596785\n",
      "-----------EPOCH-----------    ----->  2504\n",
      "Train Loss: 0.04395152166419607\n",
      "-----------EPOCH-----------    ----->  2505\n",
      "Train Loss: 0.04395072932861899\n",
      "-----------EPOCH-----------    ----->  2506\n",
      "Train Loss: 0.0439499363465548\n",
      "-----------EPOCH-----------    ----->  2507\n",
      "Train Loss: 0.04394914402537046\n",
      "-----------EPOCH-----------    ----->  2508\n",
      "Train Loss: 0.0439483518933381\n",
      "-----------EPOCH-----------    ----->  2509\n",
      "Train Loss: 0.04394756015841273\n",
      "-----------EPOCH-----------    ----->  2510\n",
      "Train Loss: 0.043946769175066534\n",
      "-----------EPOCH-----------    ----->  2511\n",
      "Train Loss: 0.043945978342177644\n",
      "-----------EPOCH-----------    ----->  2512\n",
      "Train Loss: 0.04394518804523247\n",
      "-----------EPOCH-----------    ----->  2513\n",
      "Train Loss: 0.04394439848199134\n",
      "-----------EPOCH-----------    ----->  2514\n",
      "Train Loss: 0.04394360935253308\n",
      "-----------EPOCH-----------    ----->  2515\n",
      "Train Loss: 0.04394282076561742\n",
      "-----------EPOCH-----------    ----->  2516\n",
      "Train Loss: 0.04394203200265813\n",
      "-----------EPOCH-----------    ----->  2517\n",
      "Train Loss: 0.04394124073262165\n",
      "-----------EPOCH-----------    ----->  2518\n",
      "Train Loss: 0.04394044515798786\n",
      "-----------EPOCH-----------    ----->  2519\n",
      "Train Loss: 0.04393964971960638\n",
      "-----------EPOCH-----------    ----->  2520\n",
      "Train Loss: 0.043938855035706624\n",
      "-----------EPOCH-----------    ----->  2521\n",
      "Train Loss: 0.04393806109426541\n",
      "-----------EPOCH-----------    ----->  2522\n",
      "Train Loss: 0.04393726725106598\n",
      "-----------EPOCH-----------    ----->  2523\n",
      "Train Loss: 0.04393647391613303\n",
      "-----------EPOCH-----------    ----->  2524\n",
      "Train Loss: 0.04393568021676426\n",
      "-----------EPOCH-----------    ----->  2525\n",
      "Train Loss: 0.04393488688586189\n",
      "-----------EPOCH-----------    ----->  2526\n",
      "Train Loss: 0.043934094782262005\n",
      "-----------EPOCH-----------    ----->  2527\n",
      "Train Loss: 0.043933302515082887\n",
      "-----------EPOCH-----------    ----->  2528\n",
      "Train Loss: 0.04393251014421016\n",
      "-----------EPOCH-----------    ----->  2529\n",
      "Train Loss: 0.043931717617021505\n",
      "-----------EPOCH-----------    ----->  2530\n",
      "Train Loss: 0.04393092551302243\n",
      "-----------EPOCH-----------    ----->  2531\n",
      "Train Loss: 0.043930134737760244\n",
      "-----------EPOCH-----------    ----->  2532\n",
      "Train Loss: 0.04392934493618574\n",
      "-----------EPOCH-----------    ----->  2533\n",
      "Train Loss: 0.04392855551660872\n",
      "-----------EPOCH-----------    ----->  2534\n",
      "Train Loss: 0.04392776671719641\n",
      "-----------EPOCH-----------    ----->  2535\n",
      "Train Loss: 0.043926977147085454\n",
      "-----------EPOCH-----------    ----->  2536\n",
      "Train Loss: 0.04392618832685282\n",
      "-----------EPOCH-----------    ----->  2537\n",
      "Train Loss: 0.04392539977100262\n",
      "-----------EPOCH-----------    ----->  2538\n",
      "Train Loss: 0.043924611397889064\n",
      "-----------EPOCH-----------    ----->  2539\n",
      "Train Loss: 0.04392382359225284\n",
      "-----------EPOCH-----------    ----->  2540\n",
      "Train Loss: 0.043923035989381326\n",
      "-----------EPOCH-----------    ----->  2541\n",
      "Train Loss: 0.043922249240478224\n",
      "-----------EPOCH-----------    ----->  2542\n",
      "Train Loss: 0.043921463728737196\n",
      "-----------EPOCH-----------    ----->  2543\n",
      "Train Loss: 0.043920678169599194\n",
      "-----------EPOCH-----------    ----->  2544\n",
      "Train Loss: 0.04391989314730861\n",
      "-----------EPOCH-----------    ----->  2545\n",
      "Train Loss: 0.04391910875603964\n",
      "-----------EPOCH-----------    ----->  2546\n",
      "Train Loss: 0.0439183219325889\n",
      "-----------EPOCH-----------    ----->  2547\n",
      "Train Loss: 0.04391753520435708\n",
      "-----------EPOCH-----------    ----->  2548\n",
      "Train Loss: 0.043916748112462\n",
      "-----------EPOCH-----------    ----->  2549\n",
      "Train Loss: 0.04391596158957024\n",
      "-----------EPOCH-----------    ----->  2550\n",
      "Train Loss: 0.04391517566977641\n",
      "-----------EPOCH-----------    ----->  2551\n",
      "Train Loss: 0.04391438953069647\n",
      "-----------EPOCH-----------    ----->  2552\n",
      "Train Loss: 0.0439136043562102\n",
      "-----------EPOCH-----------    ----->  2553\n",
      "Train Loss: 0.04391282016873224\n",
      "-----------EPOCH-----------    ----->  2554\n",
      "Train Loss: 0.043912036185304516\n",
      "-----------EPOCH-----------    ----->  2555\n",
      "Train Loss: 0.04391125341049684\n",
      "-----------EPOCH-----------    ----->  2556\n",
      "Train Loss: 0.043910471378478054\n",
      "-----------EPOCH-----------    ----->  2557\n",
      "Train Loss: 0.04390969022475355\n",
      "-----------EPOCH-----------    ----->  2558\n",
      "Train Loss: 0.04390890896232444\n",
      "-----------EPOCH-----------    ----->  2559\n",
      "Train Loss: 0.04390812849043776\n",
      "-----------EPOCH-----------    ----->  2560\n",
      "Train Loss: 0.04390735000032387\n",
      "-----------EPOCH-----------    ----->  2561\n",
      "Train Loss: 0.043906571501565655\n",
      "-----------EPOCH-----------    ----->  2562\n",
      "Train Loss: 0.04390579426541064\n",
      "-----------EPOCH-----------    ----->  2563\n",
      "Train Loss: 0.04390501703241161\n",
      "-----------EPOCH-----------    ----->  2564\n",
      "Train Loss: 0.043904241887913205\n",
      "-----------EPOCH-----------    ----->  2565\n",
      "Train Loss: 0.04390346862387413\n",
      "-----------EPOCH-----------    ----->  2566\n",
      "Train Loss: 0.04390269689462338\n",
      "-----------EPOCH-----------    ----->  2567\n",
      "Train Loss: 0.043901926154370934\n",
      "-----------EPOCH-----------    ----->  2568\n",
      "Train Loss: 0.04390115580902692\n",
      "-----------EPOCH-----------    ----->  2569\n",
      "Train Loss: 0.043900385816988026\n",
      "-----------EPOCH-----------    ----->  2570\n",
      "Train Loss: 0.04389961730293594\n",
      "-----------EPOCH-----------    ----->  2571\n",
      "Train Loss: 0.04389884997459721\n",
      "-----------EPOCH-----------    ----->  2572\n",
      "Train Loss: 0.04389808351928198\n",
      "-----------EPOCH-----------    ----->  2573\n",
      "Train Loss: 0.04389731810131942\n",
      "-----------EPOCH-----------    ----->  2574\n",
      "Train Loss: 0.043896552724395306\n",
      "-----------EPOCH-----------    ----->  2575\n",
      "Train Loss: 0.04389578853001734\n",
      "-----------EPOCH-----------    ----->  2576\n",
      "Train Loss: 0.04389502483507357\n",
      "-----------EPOCH-----------    ----->  2577\n",
      "Train Loss: 0.043894261769353835\n",
      "-----------EPOCH-----------    ----->  2578\n",
      "Train Loss: 0.04389349861914452\n",
      "-----------EPOCH-----------    ----->  2579\n",
      "Train Loss: 0.0438927363521482\n",
      "-----------EPOCH-----------    ----->  2580\n",
      "Train Loss: 0.043891975592210086\n",
      "-----------EPOCH-----------    ----->  2581\n",
      "Train Loss: 0.04389121529617686\n",
      "-----------EPOCH-----------    ----->  2582\n",
      "Train Loss: 0.04389045612943539\n",
      "-----------EPOCH-----------    ----->  2583\n",
      "Train Loss: 0.04388969738754201\n",
      "-----------EPOCH-----------    ----->  2584\n",
      "Train Loss: 0.04388893898078951\n",
      "-----------EPOCH-----------    ----->  2585\n",
      "Train Loss: 0.043888181059843316\n",
      "-----------EPOCH-----------    ----->  2586\n",
      "Train Loss: 0.043887424292917705\n",
      "-----------EPOCH-----------    ----->  2587\n",
      "Train Loss: 0.04388666826732581\n",
      "-----------EPOCH-----------    ----->  2588\n",
      "Train Loss: 0.043885912882485285\n",
      "-----------EPOCH-----------    ----->  2589\n",
      "Train Loss: 0.043885158099098265\n",
      "-----------EPOCH-----------    ----->  2590\n",
      "Train Loss: 0.043884403261748466\n",
      "-----------EPOCH-----------    ----->  2591\n",
      "Train Loss: 0.04388364839491291\n",
      "-----------EPOCH-----------    ----->  2592\n",
      "Train Loss: 0.043882894250355624\n",
      "-----------EPOCH-----------    ----->  2593\n",
      "Train Loss: 0.043882140196028804\n",
      "-----------EPOCH-----------    ----->  2594\n",
      "Train Loss: 0.043881386722084345\n",
      "-----------EPOCH-----------    ----->  2595\n",
      "Train Loss: 0.04388063367239629\n",
      "-----------EPOCH-----------    ----->  2596\n",
      "Train Loss: 0.043879881141343335\n",
      "-----------EPOCH-----------    ----->  2597\n",
      "Train Loss: 0.04387912951804187\n",
      "-----------EPOCH-----------    ----->  2598\n",
      "Train Loss: 0.04387837829083151\n",
      "-----------EPOCH-----------    ----->  2599\n",
      "Train Loss: 0.04387762824206373\n",
      "-----------EPOCH-----------    ----->  2600\n",
      "Train Loss: 0.04387687817179479\n",
      "-----------EPOCH-----------    ----->  2601\n",
      "Train Loss: 0.04387612905887727\n",
      "-----------EPOCH-----------    ----->  2602\n",
      "Train Loss: 0.043875380578857634\n",
      "-----------EPOCH-----------    ----->  2603\n",
      "Train Loss: 0.04387463178277312\n",
      "-----------EPOCH-----------    ----->  2604\n",
      "Train Loss: 0.0438738835325114\n",
      "-----------EPOCH-----------    ----->  2605\n",
      "Train Loss: 0.04387313642308648\n",
      "-----------EPOCH-----------    ----->  2606\n",
      "Train Loss: 0.04387238921700357\n",
      "-----------EPOCH-----------    ----->  2607\n",
      "Train Loss: 0.04387164230124113\n",
      "-----------EPOCH-----------    ----->  2608\n",
      "Train Loss: 0.0438708960065643\n",
      "-----------EPOCH-----------    ----->  2609\n",
      "Train Loss: 0.04387015043246702\n",
      "-----------EPOCH-----------    ----->  2610\n",
      "Train Loss: 0.043869405622769184\n",
      "-----------EPOCH-----------    ----->  2611\n",
      "Train Loss: 0.04386866189745278\n",
      "-----------EPOCH-----------    ----->  2612\n",
      "Train Loss: 0.043867919146211035\n",
      "-----------EPOCH-----------    ----->  2613\n",
      "Train Loss: 0.04386717637572094\n",
      "-----------EPOCH-----------    ----->  2614\n",
      "Train Loss: 0.043866435225695624\n",
      "-----------EPOCH-----------    ----->  2615\n",
      "Train Loss: 0.04386569525462664\n",
      "-----------EPOCH-----------    ----->  2616\n",
      "Train Loss: 0.04386495494956668\n",
      "-----------EPOCH-----------    ----->  2617\n",
      "Train Loss: 0.04386421584542376\n",
      "-----------EPOCH-----------    ----->  2618\n",
      "Train Loss: 0.04386347678569264\n",
      "-----------EPOCH-----------    ----->  2619\n",
      "Train Loss: 0.04386273837795401\n",
      "-----------EPOCH-----------    ----->  2620\n",
      "Train Loss: 0.043862000079421815\n",
      "-----------EPOCH-----------    ----->  2621\n",
      "Train Loss: 0.043861261756057014\n",
      "-----------EPOCH-----------    ----->  2622\n",
      "Train Loss: 0.04386052305259437\n",
      "-----------EPOCH-----------    ----->  2623\n",
      "Train Loss: 0.043859784784444855\n",
      "-----------EPOCH-----------    ----->  2624\n",
      "Train Loss: 0.04385904614479994\n",
      "-----------EPOCH-----------    ----->  2625\n",
      "Train Loss: 0.0438583070408477\n",
      "-----------EPOCH-----------    ----->  2626\n",
      "Train Loss: 0.043857568557561226\n",
      "-----------EPOCH-----------    ----->  2627\n",
      "Train Loss: 0.043856829954654605\n",
      "-----------EPOCH-----------    ----->  2628\n",
      "Train Loss: 0.043856091004665324\n",
      "-----------EPOCH-----------    ----->  2629\n",
      "Train Loss: 0.043855351709611426\n",
      "-----------EPOCH-----------    ----->  2630\n",
      "Train Loss: 0.043854612091094654\n",
      "-----------EPOCH-----------    ----->  2631\n",
      "Train Loss: 0.04385387311710326\n",
      "-----------EPOCH-----------    ----->  2632\n",
      "Train Loss: 0.04385313456046881\n",
      "-----------EPOCH-----------    ----->  2633\n",
      "Train Loss: 0.043852395551575746\n",
      "-----------EPOCH-----------    ----->  2634\n",
      "Train Loss: 0.043851655999487496\n",
      "-----------EPOCH-----------    ----->  2635\n",
      "Train Loss: 0.043850916677919974\n",
      "-----------EPOCH-----------    ----->  2636\n",
      "Train Loss: 0.043850178247974686\n",
      "-----------EPOCH-----------    ----->  2637\n",
      "Train Loss: 0.043849440894152374\n",
      "-----------EPOCH-----------    ----->  2638\n",
      "Train Loss: 0.043848704455546\n",
      "-----------EPOCH-----------    ----->  2639\n",
      "Train Loss: 0.04384796754862688\n",
      "-----------EPOCH-----------    ----->  2640\n",
      "Train Loss: 0.043847231036429624\n",
      "-----------EPOCH-----------    ----->  2641\n",
      "Train Loss: 0.04384649493980621\n",
      "-----------EPOCH-----------    ----->  2642\n",
      "Train Loss: 0.04384575997408631\n",
      "-----------EPOCH-----------    ----->  2643\n",
      "Train Loss: 0.04384502520817781\n",
      "-----------EPOCH-----------    ----->  2644\n",
      "Train Loss: 0.04384429138968373\n",
      "-----------EPOCH-----------    ----->  2645\n",
      "Train Loss: 0.04384355793668532\n",
      "-----------EPOCH-----------    ----->  2646\n",
      "Train Loss: 0.04384282474812419\n",
      "-----------EPOCH-----------    ----->  2647\n",
      "Train Loss: 0.043842091283174484\n",
      "-----------EPOCH-----------    ----->  2648\n",
      "Train Loss: 0.04384135795746909\n",
      "-----------EPOCH-----------    ----->  2649\n",
      "Train Loss: 0.04384062484977877\n",
      "-----------EPOCH-----------    ----->  2650\n",
      "Train Loss: 0.04383989324973147\n",
      "-----------EPOCH-----------    ----->  2651\n",
      "Train Loss: 0.04383916212957298\n",
      "-----------EPOCH-----------    ----->  2652\n",
      "Train Loss: 0.04383843156396576\n",
      "-----------EPOCH-----------    ----->  2653\n",
      "Train Loss: 0.04383770161960532\n",
      "-----------EPOCH-----------    ----->  2654\n",
      "Train Loss: 0.043836971502606195\n",
      "-----------EPOCH-----------    ----->  2655\n",
      "Train Loss: 0.043836242858377415\n",
      "-----------EPOCH-----------    ----->  2656\n",
      "Train Loss: 0.04383551493879905\n",
      "-----------EPOCH-----------    ----->  2657\n",
      "Train Loss: 0.04383478720554367\n",
      "-----------EPOCH-----------    ----->  2658\n",
      "Train Loss: 0.0438340598216934\n",
      "-----------EPOCH-----------    ----->  2659\n",
      "Train Loss: 0.043833334126608704\n",
      "-----------EPOCH-----------    ----->  2660\n",
      "Train Loss: 0.043832609209694284\n",
      "-----------EPOCH-----------    ----->  2661\n",
      "Train Loss: 0.04383188399228364\n",
      "-----------EPOCH-----------    ----->  2662\n",
      "Train Loss: 0.04383115719127953\n",
      "-----------EPOCH-----------    ----->  2663\n",
      "Train Loss: 0.043830431015987686\n",
      "-----------EPOCH-----------    ----->  2664\n",
      "Train Loss: 0.04382970423208914\n",
      "-----------EPOCH-----------    ----->  2665\n",
      "Train Loss: 0.043828978211471095\n",
      "-----------EPOCH-----------    ----->  2666\n",
      "Train Loss: 0.04382825133883414\n",
      "-----------EPOCH-----------    ----->  2667\n",
      "Train Loss: 0.043827524373270685\n",
      "-----------EPOCH-----------    ----->  2668\n",
      "Train Loss: 0.043826797968235666\n",
      "-----------EPOCH-----------    ----->  2669\n",
      "Train Loss: 0.04382607157798931\n",
      "-----------EPOCH-----------    ----->  2670\n",
      "Train Loss: 0.04382534644938585\n",
      "-----------EPOCH-----------    ----->  2671\n",
      "Train Loss: 0.04382462210948562\n",
      "-----------EPOCH-----------    ----->  2672\n",
      "Train Loss: 0.04382389878752533\n",
      "-----------EPOCH-----------    ----->  2673\n",
      "Train Loss: 0.04382317615213628\n",
      "-----------EPOCH-----------    ----->  2674\n",
      "Train Loss: 0.04382245412593453\n",
      "-----------EPOCH-----------    ----->  2675\n",
      "Train Loss: 0.0438217329598142\n",
      "-----------EPOCH-----------    ----->  2676\n",
      "Train Loss: 0.043821011872380224\n",
      "-----------EPOCH-----------    ----->  2677\n",
      "Train Loss: 0.043820290426634184\n",
      "-----------EPOCH-----------    ----->  2678\n",
      "Train Loss: 0.04381956914748508\n",
      "-----------EPOCH-----------    ----->  2679\n",
      "Train Loss: 0.04381884803735991\n",
      "-----------EPOCH-----------    ----->  2680\n",
      "Train Loss: 0.04381812775086111\n",
      "-----------EPOCH-----------    ----->  2681\n",
      "Train Loss: 0.04381740827491104\n",
      "-----------EPOCH-----------    ----->  2682\n",
      "Train Loss: 0.04381668916993673\n",
      "-----------EPOCH-----------    ----->  2683\n",
      "Train Loss: 0.043815970212281743\n",
      "-----------EPOCH-----------    ----->  2684\n",
      "Train Loss: 0.043815251666006146\n",
      "-----------EPOCH-----------    ----->  2685\n",
      "Train Loss: 0.04381453346618525\n",
      "-----------EPOCH-----------    ----->  2686\n",
      "Train Loss: 0.04381381598340226\n",
      "-----------EPOCH-----------    ----->  2687\n",
      "Train Loss: 0.04381309849490059\n",
      "-----------EPOCH-----------    ----->  2688\n",
      "Train Loss: 0.04381238079848356\n",
      "-----------EPOCH-----------    ----->  2689\n",
      "Train Loss: 0.04381166298010951\n",
      "-----------EPOCH-----------    ----->  2690\n",
      "Train Loss: 0.04381094562789897\n",
      "-----------EPOCH-----------    ----->  2691\n",
      "Train Loss: 0.043810228761548546\n",
      "-----------EPOCH-----------    ----->  2692\n",
      "Train Loss: 0.043809511773652686\n",
      "-----------EPOCH-----------    ----->  2693\n",
      "Train Loss: 0.04380879574930647\n",
      "-----------EPOCH-----------    ----->  2694\n",
      "Train Loss: 0.04380807913091786\n",
      "-----------EPOCH-----------    ----->  2695\n",
      "Train Loss: 0.043807363160543074\n",
      "-----------EPOCH-----------    ----->  2696\n",
      "Train Loss: 0.04380664754821221\n",
      "-----------EPOCH-----------    ----->  2697\n",
      "Train Loss: 0.04380593272327377\n",
      "-----------EPOCH-----------    ----->  2698\n",
      "Train Loss: 0.04380521860964167\n",
      "-----------EPOCH-----------    ----->  2699\n",
      "Train Loss: 0.04380450396002973\n",
      "-----------EPOCH-----------    ----->  2700\n",
      "Train Loss: 0.04380378920691012\n",
      "-----------EPOCH-----------    ----->  2701\n",
      "Train Loss: 0.0438030751132316\n",
      "-----------EPOCH-----------    ----->  2702\n",
      "Train Loss: 0.0438023613702469\n",
      "-----------EPOCH-----------    ----->  2703\n",
      "Train Loss: 0.04380164739269457\n",
      "-----------EPOCH-----------    ----->  2704\n",
      "Train Loss: 0.04380093417278945\n",
      "-----------EPOCH-----------    ----->  2705\n",
      "Train Loss: 0.04380022109205351\n",
      "-----------EPOCH-----------    ----->  2706\n",
      "Train Loss: 0.04379950822199753\n",
      "-----------EPOCH-----------    ----->  2707\n",
      "Train Loss: 0.04379879588124525\n",
      "-----------EPOCH-----------    ----->  2708\n",
      "Train Loss: 0.0437980824043087\n",
      "-----------EPOCH-----------    ----->  2709\n",
      "Train Loss: 0.0437973653887593\n",
      "-----------EPOCH-----------    ----->  2710\n",
      "Train Loss: 0.04379664928223613\n",
      "-----------EPOCH-----------    ----->  2711\n",
      "Train Loss: 0.0437959340278532\n",
      "-----------EPOCH-----------    ----->  2712\n",
      "Train Loss: 0.0437952194442498\n",
      "-----------EPOCH-----------    ----->  2713\n",
      "Train Loss: 0.0437945052870735\n",
      "-----------EPOCH-----------    ----->  2714\n",
      "Train Loss: 0.043793791495470094\n",
      "-----------EPOCH-----------    ----->  2715\n",
      "Train Loss: 0.04379307824550042\n",
      "-----------EPOCH-----------    ----->  2716\n",
      "Train Loss: 0.04379236548578468\n",
      "-----------EPOCH-----------    ----->  2717\n",
      "Train Loss: 0.04379165174070397\n",
      "-----------EPOCH-----------    ----->  2718\n",
      "Train Loss: 0.043790938937749296\n",
      "-----------EPOCH-----------    ----->  2719\n",
      "Train Loss: 0.04379022612931895\n",
      "-----------EPOCH-----------    ----->  2720\n",
      "Train Loss: 0.04378951379028009\n",
      "-----------EPOCH-----------    ----->  2721\n",
      "Train Loss: 0.04378880285594247\n",
      "-----------EPOCH-----------    ----->  2722\n",
      "Train Loss: 0.04378809230896477\n",
      "-----------EPOCH-----------    ----->  2723\n",
      "Train Loss: 0.043787382604948896\n",
      "-----------EPOCH-----------    ----->  2724\n",
      "Train Loss: 0.04378667316692614\n",
      "-----------EPOCH-----------    ----->  2725\n",
      "Train Loss: 0.04378596348923688\n",
      "-----------EPOCH-----------    ----->  2726\n",
      "Train Loss: 0.0437852545900894\n",
      "-----------EPOCH-----------    ----->  2727\n",
      "Train Loss: 0.04378454604146549\n",
      "-----------EPOCH-----------    ----->  2728\n",
      "Train Loss: 0.043783838029210674\n",
      "-----------EPOCH-----------    ----->  2729\n",
      "Train Loss: 0.04378313059178415\n",
      "-----------EPOCH-----------    ----->  2730\n",
      "Train Loss: 0.04378242413286495\n",
      "-----------EPOCH-----------    ----->  2731\n",
      "Train Loss: 0.04378171876245761\n",
      "-----------EPOCH-----------    ----->  2732\n",
      "Train Loss: 0.043781013333252426\n",
      "-----------EPOCH-----------    ----->  2733\n",
      "Train Loss: 0.043780308258188204\n",
      "-----------EPOCH-----------    ----->  2734\n",
      "Train Loss: 0.04377960368794532\n",
      "-----------EPOCH-----------    ----->  2735\n",
      "Train Loss: 0.043778899457863986\n",
      "-----------EPOCH-----------    ----->  2736\n",
      "Train Loss: 0.04377819480502828\n",
      "-----------EPOCH-----------    ----->  2737\n",
      "Train Loss: 0.04377749025010554\n",
      "-----------EPOCH-----------    ----->  2738\n",
      "Train Loss: 0.043776785330609316\n",
      "-----------EPOCH-----------    ----->  2739\n",
      "Train Loss: 0.04377608060497667\n",
      "-----------EPOCH-----------    ----->  2740\n",
      "Train Loss: 0.04377537628246138\n",
      "-----------EPOCH-----------    ----->  2741\n",
      "Train Loss: 0.04377467265624495\n",
      "-----------EPOCH-----------    ----->  2742\n",
      "Train Loss: 0.043773968967771484\n",
      "-----------EPOCH-----------    ----->  2743\n",
      "Train Loss: 0.04377326632386427\n",
      "-----------EPOCH-----------    ----->  2744\n",
      "Train Loss: 0.043772563677292466\n",
      "-----------EPOCH-----------    ----->  2745\n",
      "Train Loss: 0.043771861314966506\n",
      "-----------EPOCH-----------    ----->  2746\n",
      "Train Loss: 0.043771159516406435\n",
      "-----------EPOCH-----------    ----->  2747\n",
      "Train Loss: 0.04377045774430509\n",
      "-----------EPOCH-----------    ----->  2748\n",
      "Train Loss: 0.04376975697670225\n",
      "-----------EPOCH-----------    ----->  2749\n",
      "Train Loss: 0.04376905589417777\n",
      "-----------EPOCH-----------    ----->  2750\n",
      "Train Loss: 0.04376835433094202\n",
      "-----------EPOCH-----------    ----->  2751\n",
      "Train Loss: 0.043767652414254926\n",
      "-----------EPOCH-----------    ----->  2752\n",
      "Train Loss: 0.043766950093240886\n",
      "-----------EPOCH-----------    ----->  2753\n",
      "Train Loss: 0.043766247916789985\n",
      "-----------EPOCH-----------    ----->  2754\n",
      "Train Loss: 0.04376554597177829\n",
      "-----------EPOCH-----------    ----->  2755\n",
      "Train Loss: 0.043764845877850386\n",
      "-----------EPOCH-----------    ----->  2756\n",
      "Train Loss: 0.043764145816521424\n",
      "-----------EPOCH-----------    ----->  2757\n",
      "Train Loss: 0.0437634457652113\n",
      "-----------EPOCH-----------    ----->  2758\n",
      "Train Loss: 0.043762746762063695\n",
      "-----------EPOCH-----------    ----->  2759\n",
      "Train Loss: 0.04376204857292401\n",
      "-----------EPOCH-----------    ----->  2760\n",
      "Train Loss: 0.04376135021234795\n",
      "-----------EPOCH-----------    ----->  2761\n",
      "Train Loss: 0.043760651256876476\n",
      "-----------EPOCH-----------    ----->  2762\n",
      "Train Loss: 0.043759952518890616\n",
      "-----------EPOCH-----------    ----->  2763\n",
      "Train Loss: 0.04375925379302836\n",
      "-----------EPOCH-----------    ----->  2764\n",
      "Train Loss: 0.043758555891072505\n",
      "-----------EPOCH-----------    ----->  2765\n",
      "Train Loss: 0.04375785817917634\n",
      "-----------EPOCH-----------    ----->  2766\n",
      "Train Loss: 0.043757161435368376\n",
      "-----------EPOCH-----------    ----->  2767\n",
      "Train Loss: 0.043756464872394096\n",
      "-----------EPOCH-----------    ----->  2768\n",
      "Train Loss: 0.0437557684843834\n",
      "-----------EPOCH-----------    ----->  2769\n",
      "Train Loss: 0.04375507298557947\n",
      "-----------EPOCH-----------    ----->  2770\n",
      "Train Loss: 0.043754377125551525\n",
      "-----------EPOCH-----------    ----->  2771\n",
      "Train Loss: 0.043753682179217906\n",
      "-----------EPOCH-----------    ----->  2772\n",
      "Train Loss: 0.04375298816427881\n",
      "-----------EPOCH-----------    ----->  2773\n",
      "Train Loss: 0.04375229401466405\n",
      "-----------EPOCH-----------    ----->  2774\n",
      "Train Loss: 0.04375159957670342\n",
      "-----------EPOCH-----------    ----->  2775\n",
      "Train Loss: 0.04375090544482991\n",
      "-----------EPOCH-----------    ----->  2776\n",
      "Train Loss: 0.04375021192819971\n",
      "-----------EPOCH-----------    ----->  2777\n",
      "Train Loss: 0.04374951990558428\n",
      "-----------EPOCH-----------    ----->  2778\n",
      "Train Loss: 0.04374882874071457\n",
      "-----------EPOCH-----------    ----->  2779\n",
      "Train Loss: 0.043748139455468134\n",
      "-----------EPOCH-----------    ----->  2780\n",
      "Train Loss: 0.043747450033681995\n",
      "-----------EPOCH-----------    ----->  2781\n",
      "Train Loss: 0.04374676025639908\n",
      "-----------EPOCH-----------    ----->  2782\n",
      "Train Loss: 0.04374607106078203\n",
      "-----------EPOCH-----------    ----->  2783\n",
      "Train Loss: 0.043745381058917995\n",
      "-----------EPOCH-----------    ----->  2784\n",
      "Train Loss: 0.043744689989867545\n",
      "-----------EPOCH-----------    ----->  2785\n",
      "Train Loss: 0.04374399897275204\n",
      "-----------EPOCH-----------    ----->  2786\n",
      "Train Loss: 0.04374330825314982\n",
      "-----------EPOCH-----------    ----->  2787\n",
      "Train Loss: 0.04374261642590352\n",
      "-----------EPOCH-----------    ----->  2788\n",
      "Train Loss: 0.04374192467652486\n",
      "-----------EPOCH-----------    ----->  2789\n",
      "Train Loss: 0.043741233876984524\n",
      "-----------EPOCH-----------    ----->  2790\n",
      "Train Loss: 0.043740543732323875\n",
      "-----------EPOCH-----------    ----->  2791\n",
      "Train Loss: 0.043739853634294966\n",
      "-----------EPOCH-----------    ----->  2792\n",
      "Train Loss: 0.04373916418235579\n",
      "-----------EPOCH-----------    ----->  2793\n",
      "Train Loss: 0.043738475530626736\n",
      "-----------EPOCH-----------    ----->  2794\n",
      "Train Loss: 0.043737786769240145\n",
      "-----------EPOCH-----------    ----->  2795\n",
      "Train Loss: 0.043737098263653705\n",
      "-----------EPOCH-----------    ----->  2796\n",
      "Train Loss: 0.04373640957876351\n",
      "-----------EPOCH-----------    ----->  2797\n",
      "Train Loss: 0.04373572028483107\n",
      "-----------EPOCH-----------    ----->  2798\n",
      "Train Loss: 0.04373503115007442\n",
      "-----------EPOCH-----------    ----->  2799\n",
      "Train Loss: 0.04373434247292567\n",
      "-----------EPOCH-----------    ----->  2800\n",
      "Train Loss: 0.04373365337536041\n",
      "-----------EPOCH-----------    ----->  2801\n",
      "Train Loss: 0.043732964256176884\n",
      "-----------EPOCH-----------    ----->  2802\n",
      "Train Loss: 0.04373227681757969\n",
      "-----------EPOCH-----------    ----->  2803\n",
      "Train Loss: 0.04373159006657113\n",
      "-----------EPOCH-----------    ----->  2804\n",
      "Train Loss: 0.04373090329542108\n",
      "-----------EPOCH-----------    ----->  2805\n",
      "Train Loss: 0.04373021718740542\n",
      "-----------EPOCH-----------    ----->  2806\n",
      "Train Loss: 0.04372953194687693\n",
      "-----------EPOCH-----------    ----->  2807\n",
      "Train Loss: 0.043728845401084716\n",
      "-----------EPOCH-----------    ----->  2808\n",
      "Train Loss: 0.043728158792427696\n",
      "-----------EPOCH-----------    ----->  2809\n",
      "Train Loss: 0.04372747240190823\n",
      "-----------EPOCH-----------    ----->  2810\n",
      "Train Loss: 0.04372678595396554\n",
      "-----------EPOCH-----------    ----->  2811\n",
      "Train Loss: 0.04372610023886335\n",
      "-----------EPOCH-----------    ----->  2812\n",
      "Train Loss: 0.04372541421446704\n",
      "-----------EPOCH-----------    ----->  2813\n",
      "Train Loss: 0.04372472775884854\n",
      "-----------EPOCH-----------    ----->  2814\n",
      "Train Loss: 0.043724040621535204\n",
      "-----------EPOCH-----------    ----->  2815\n",
      "Train Loss: 0.0437233518456364\n",
      "-----------EPOCH-----------    ----->  2816\n",
      "Train Loss: 0.04372266341882024\n",
      "-----------EPOCH-----------    ----->  2817\n",
      "Train Loss: 0.04372197541025504\n",
      "-----------EPOCH-----------    ----->  2818\n",
      "Train Loss: 0.04372128779639309\n",
      "-----------EPOCH-----------    ----->  2819\n",
      "Train Loss: 0.04372059984900489\n",
      "-----------EPOCH-----------    ----->  2820\n",
      "Train Loss: 0.04371991193393629\n",
      "-----------EPOCH-----------    ----->  2821\n",
      "Train Loss: 0.04371922488965444\n",
      "-----------EPOCH-----------    ----->  2822\n",
      "Train Loss: 0.04371853837676913\n",
      "-----------EPOCH-----------    ----->  2823\n",
      "Train Loss: 0.043717852702889866\n",
      "-----------EPOCH-----------    ----->  2824\n",
      "Train Loss: 0.04371716590185556\n",
      "-----------EPOCH-----------    ----->  2825\n",
      "Train Loss: 0.04371648091658604\n",
      "-----------EPOCH-----------    ----->  2826\n",
      "Train Loss: 0.04371579571083223\n",
      "-----------EPOCH-----------    ----->  2827\n",
      "Train Loss: 0.04371511170203526\n",
      "-----------EPOCH-----------    ----->  2828\n",
      "Train Loss: 0.04371442696329655\n",
      "-----------EPOCH-----------    ----->  2829\n",
      "Train Loss: 0.04371374351475359\n",
      "-----------EPOCH-----------    ----->  2830\n",
      "Train Loss: 0.0437130590455624\n",
      "-----------EPOCH-----------    ----->  2831\n",
      "Train Loss: 0.04371237535632398\n",
      "-----------EPOCH-----------    ----->  2832\n",
      "Train Loss: 0.0437116913725635\n",
      "-----------EPOCH-----------    ----->  2833\n",
      "Train Loss: 0.04371100847299148\n",
      "-----------EPOCH-----------    ----->  2834\n",
      "Train Loss: 0.04371032551319009\n",
      "-----------EPOCH-----------    ----->  2835\n",
      "Train Loss: 0.0437096434678796\n",
      "-----------EPOCH-----------    ----->  2836\n",
      "Train Loss: 0.04370896129964208\n",
      "-----------EPOCH-----------    ----->  2837\n",
      "Train Loss: 0.043708279476149005\n",
      "-----------EPOCH-----------    ----->  2838\n",
      "Train Loss: 0.04370759802931296\n",
      "-----------EPOCH-----------    ----->  2839\n",
      "Train Loss: 0.043706918118847964\n",
      "-----------EPOCH-----------    ----->  2840\n",
      "Train Loss: 0.043706237837443755\n",
      "-----------EPOCH-----------    ----->  2841\n",
      "Train Loss: 0.04370555807980947\n",
      "-----------EPOCH-----------    ----->  2842\n",
      "Train Loss: 0.043704878770024054\n",
      "-----------EPOCH-----------    ----->  2843\n",
      "Train Loss: 0.043704200275265274\n",
      "-----------EPOCH-----------    ----->  2844\n",
      "Train Loss: 0.04370352285935862\n",
      "-----------EPOCH-----------    ----->  2845\n",
      "Train Loss: 0.04370284585550939\n",
      "-----------EPOCH-----------    ----->  2846\n",
      "Train Loss: 0.0437021688433978\n",
      "-----------EPOCH-----------    ----->  2847\n",
      "Train Loss: 0.043701491203684446\n",
      "-----------EPOCH-----------    ----->  2848\n",
      "Train Loss: 0.04370081435147878\n",
      "-----------EPOCH-----------    ----->  2849\n",
      "Train Loss: 0.0437001368462562\n",
      "-----------EPOCH-----------    ----->  2850\n",
      "Train Loss: 0.04369945995545161\n",
      "-----------EPOCH-----------    ----->  2851\n",
      "Train Loss: 0.04369878223630704\n",
      "-----------EPOCH-----------    ----->  2852\n",
      "Train Loss: 0.04369810508912164\n",
      "-----------EPOCH-----------    ----->  2853\n",
      "Train Loss: 0.043697428623545594\n",
      "-----------EPOCH-----------    ----->  2854\n",
      "Train Loss: 0.04369675351022443\n",
      "-----------EPOCH-----------    ----->  2855\n",
      "Train Loss: 0.043696079183167216\n",
      "-----------EPOCH-----------    ----->  2856\n",
      "Train Loss: 0.04369540612079703\n",
      "-----------EPOCH-----------    ----->  2857\n",
      "Train Loss: 0.04369473397686271\n",
      "-----------EPOCH-----------    ----->  2858\n",
      "Train Loss: 0.04369406179418914\n",
      "-----------EPOCH-----------    ----->  2859\n",
      "Train Loss: 0.04369339031105075\n",
      "-----------EPOCH-----------    ----->  2860\n",
      "Train Loss: 0.0436927188525899\n",
      "-----------EPOCH-----------    ----->  2861\n",
      "Train Loss: 0.04369204790470725\n",
      "-----------EPOCH-----------    ----->  2862\n",
      "Train Loss: 0.043691377004244025\n",
      "-----------EPOCH-----------    ----->  2863\n",
      "Train Loss: 0.04369070651364804\n",
      "-----------EPOCH-----------    ----->  2864\n",
      "Train Loss: 0.043690035825848336\n",
      "-----------EPOCH-----------    ----->  2865\n",
      "Train Loss: 0.04368936568218325\n",
      "-----------EPOCH-----------    ----->  2866\n",
      "Train Loss: 0.043688695890255605\n",
      "-----------EPOCH-----------    ----->  2867\n",
      "Train Loss: 0.04368802634843654\n",
      "-----------EPOCH-----------    ----->  2868\n",
      "Train Loss: 0.0436873577803064\n",
      "-----------EPOCH-----------    ----->  2869\n",
      "Train Loss: 0.04368668993707564\n",
      "-----------EPOCH-----------    ----->  2870\n",
      "Train Loss: 0.04368602257175076\n",
      "-----------EPOCH-----------    ----->  2871\n",
      "Train Loss: 0.04368535399939711\n",
      "-----------EPOCH-----------    ----->  2872\n",
      "Train Loss: 0.04368468676085086\n",
      "-----------EPOCH-----------    ----->  2873\n",
      "Train Loss: 0.043684019921971275\n",
      "-----------EPOCH-----------    ----->  2874\n",
      "Train Loss: 0.04368335436168283\n",
      "-----------EPOCH-----------    ----->  2875\n",
      "Train Loss: 0.04368268908265098\n",
      "-----------EPOCH-----------    ----->  2876\n",
      "Train Loss: 0.04368202331416259\n",
      "-----------EPOCH-----------    ----->  2877\n",
      "Train Loss: 0.043681358531968084\n",
      "-----------EPOCH-----------    ----->  2878\n",
      "Train Loss: 0.04368069381797445\n",
      "-----------EPOCH-----------    ----->  2879\n",
      "Train Loss: 0.04368002836486937\n",
      "-----------EPOCH-----------    ----->  2880\n",
      "Train Loss: 0.04367936374327453\n",
      "-----------EPOCH-----------    ----->  2881\n",
      "Train Loss: 0.04367869787604461\n",
      "-----------EPOCH-----------    ----->  2882\n",
      "Train Loss: 0.0436780321511813\n",
      "-----------EPOCH-----------    ----->  2883\n",
      "Train Loss: 0.04367736548904234\n",
      "-----------EPOCH-----------    ----->  2884\n",
      "Train Loss: 0.043676699566358224\n",
      "-----------EPOCH-----------    ----->  2885\n",
      "Train Loss: 0.043676034440040395\n",
      "-----------EPOCH-----------    ----->  2886\n",
      "Train Loss: 0.043675369458647736\n",
      "-----------EPOCH-----------    ----->  2887\n",
      "Train Loss: 0.04367470498711888\n",
      "-----------EPOCH-----------    ----->  2888\n",
      "Train Loss: 0.04367404073275625\n",
      "-----------EPOCH-----------    ----->  2889\n",
      "Train Loss: 0.043673377455399495\n",
      "-----------EPOCH-----------    ----->  2890\n",
      "Train Loss: 0.04367271442673656\n",
      "-----------EPOCH-----------    ----->  2891\n",
      "Train Loss: 0.043672052673869456\n",
      "-----------EPOCH-----------    ----->  2892\n",
      "Train Loss: 0.04367139004438495\n",
      "-----------EPOCH-----------    ----->  2893\n",
      "Train Loss: 0.04367072777100499\n",
      "-----------EPOCH-----------    ----->  2894\n",
      "Train Loss: 0.04367006582788978\n",
      "-----------EPOCH-----------    ----->  2895\n",
      "Train Loss: 0.0436694041721306\n",
      "-----------EPOCH-----------    ----->  2896\n",
      "Train Loss: 0.043668742487960134\n",
      "-----------EPOCH-----------    ----->  2897\n",
      "Train Loss: 0.04366808160246206\n",
      "-----------EPOCH-----------    ----->  2898\n",
      "Train Loss: 0.04366742064663453\n",
      "-----------EPOCH-----------    ----->  2899\n",
      "Train Loss: 0.043666759513993854\n",
      "-----------EPOCH-----------    ----->  2900\n",
      "Train Loss: 0.04366610026335916\n",
      "-----------EPOCH-----------    ----->  2901\n",
      "Train Loss: 0.043665441870770705\n",
      "-----------EPOCH-----------    ----->  2902\n",
      "Train Loss: 0.04366478362397574\n",
      "-----------EPOCH-----------    ----->  2903\n",
      "Train Loss: 0.04366412576556295\n",
      "-----------EPOCH-----------    ----->  2904\n",
      "Train Loss: 0.043663468805785956\n",
      "-----------EPOCH-----------    ----->  2905\n",
      "Train Loss: 0.04366281309457221\n",
      "-----------EPOCH-----------    ----->  2906\n",
      "Train Loss: 0.043662157520323666\n",
      "-----------EPOCH-----------    ----->  2907\n",
      "Train Loss: 0.04366150201816349\n",
      "-----------EPOCH-----------    ----->  2908\n",
      "Train Loss: 0.04366084730153032\n",
      "-----------EPOCH-----------    ----->  2909\n",
      "Train Loss: 0.04366019196130254\n",
      "-----------EPOCH-----------    ----->  2910\n",
      "Train Loss: 0.04365953712764109\n",
      "-----------EPOCH-----------    ----->  2911\n",
      "Train Loss: 0.0436588821292789\n",
      "-----------EPOCH-----------    ----->  2912\n",
      "Train Loss: 0.043658227034611634\n",
      "-----------EPOCH-----------    ----->  2913\n",
      "Train Loss: 0.043657571112208686\n",
      "-----------EPOCH-----------    ----->  2914\n",
      "Train Loss: 0.04365691520615936\n",
      "-----------EPOCH-----------    ----->  2915\n",
      "Train Loss: 0.04365625991089485\n",
      "-----------EPOCH-----------    ----->  2916\n",
      "Train Loss: 0.04365560428332894\n",
      "-----------EPOCH-----------    ----->  2917\n",
      "Train Loss: 0.043654949730648755\n",
      "-----------EPOCH-----------    ----->  2918\n",
      "Train Loss: 0.043654295092721576\n",
      "-----------EPOCH-----------    ----->  2919\n",
      "Train Loss: 0.04365364118764882\n",
      "-----------EPOCH-----------    ----->  2920\n",
      "Train Loss: 0.04365298782854152\n",
      "-----------EPOCH-----------    ----->  2921\n",
      "Train Loss: 0.043652335059469076\n",
      "-----------EPOCH-----------    ----->  2922\n",
      "Train Loss: 0.04365168224708385\n",
      "-----------EPOCH-----------    ----->  2923\n",
      "Train Loss: 0.043651029320376886\n",
      "-----------EPOCH-----------    ----->  2924\n",
      "Train Loss: 0.043650376265494555\n",
      "-----------EPOCH-----------    ----->  2925\n",
      "Train Loss: 0.04364972342124424\n",
      "-----------EPOCH-----------    ----->  2926\n",
      "Train Loss: 0.04364907095115204\n",
      "-----------EPOCH-----------    ----->  2927\n",
      "Train Loss: 0.043648418745480984\n",
      "-----------EPOCH-----------    ----->  2928\n",
      "Train Loss: 0.04364776553114125\n",
      "-----------EPOCH-----------    ----->  2929\n",
      "Train Loss: 0.043647112557267914\n",
      "-----------EPOCH-----------    ----->  2930\n",
      "Train Loss: 0.043646459738240544\n",
      "-----------EPOCH-----------    ----->  2931\n",
      "Train Loss: 0.04364580685054862\n",
      "-----------EPOCH-----------    ----->  2932\n",
      "Train Loss: 0.04364515386305801\n",
      "-----------EPOCH-----------    ----->  2933\n",
      "Train Loss: 0.04364450054869371\n",
      "-----------EPOCH-----------    ----->  2934\n",
      "Train Loss: 0.04364384648339045\n",
      "-----------EPOCH-----------    ----->  2935\n",
      "Train Loss: 0.04364319219245043\n",
      "-----------EPOCH-----------    ----->  2936\n",
      "Train Loss: 0.04364253840456868\n",
      "-----------EPOCH-----------    ----->  2937\n",
      "Train Loss: 0.0436418843025194\n",
      "-----------EPOCH-----------    ----->  2938\n",
      "Train Loss: 0.043641230722038106\n",
      "-----------EPOCH-----------    ----->  2939\n",
      "Train Loss: 0.0436405781630291\n",
      "-----------EPOCH-----------    ----->  2940\n",
      "Train Loss: 0.0436399255688678\n",
      "-----------EPOCH-----------    ----->  2941\n",
      "Train Loss: 0.043639273804657444\n",
      "-----------EPOCH-----------    ----->  2942\n",
      "Train Loss: 0.04363862118618079\n",
      "-----------EPOCH-----------    ----->  2943\n",
      "Train Loss: 0.04363796915830302\n",
      "-----------EPOCH-----------    ----->  2944\n",
      "Train Loss: 0.043637316936800605\n",
      "-----------EPOCH-----------    ----->  2945\n",
      "Train Loss: 0.043636667422620366\n",
      "-----------EPOCH-----------    ----->  2946\n",
      "Train Loss: 0.04363601794823755\n",
      "-----------EPOCH-----------    ----->  2947\n",
      "Train Loss: 0.043635368823462056\n",
      "-----------EPOCH-----------    ----->  2948\n",
      "Train Loss: 0.043634719996837185\n",
      "-----------EPOCH-----------    ----->  2949\n",
      "Train Loss: 0.043634071043394326\n",
      "-----------EPOCH-----------    ----->  2950\n",
      "Train Loss: 0.04363342292909685\n",
      "-----------EPOCH-----------    ----->  2951\n",
      "Train Loss: 0.04363277617706004\n",
      "-----------EPOCH-----------    ----->  2952\n",
      "Train Loss: 0.04363212954674794\n",
      "-----------EPOCH-----------    ----->  2953\n",
      "Train Loss: 0.04363148370082717\n",
      "-----------EPOCH-----------    ----->  2954\n",
      "Train Loss: 0.04363083771458152\n",
      "-----------EPOCH-----------    ----->  2955\n",
      "Train Loss: 0.04363019125489215\n",
      "-----------EPOCH-----------    ----->  2956\n",
      "Train Loss: 0.043629544910781436\n",
      "-----------EPOCH-----------    ----->  2957\n",
      "Train Loss: 0.0436288991987341\n",
      "-----------EPOCH-----------    ----->  2958\n",
      "Train Loss: 0.04362825375448154\n",
      "-----------EPOCH-----------    ----->  2959\n",
      "Train Loss: 0.0436276087147556\n",
      "-----------EPOCH-----------    ----->  2960\n",
      "Train Loss: 0.04362696412720157\n",
      "-----------EPOCH-----------    ----->  2961\n",
      "Train Loss: 0.043626319189548346\n",
      "-----------EPOCH-----------    ----->  2962\n",
      "Train Loss: 0.04362567429123441\n",
      "-----------EPOCH-----------    ----->  2963\n",
      "Train Loss: 0.04362502904259757\n",
      "-----------EPOCH-----------    ----->  2964\n",
      "Train Loss: 0.04362438415585458\n",
      "-----------EPOCH-----------    ----->  2965\n",
      "Train Loss: 0.04362373947591896\n",
      "-----------EPOCH-----------    ----->  2966\n",
      "Train Loss: 0.04362309448722739\n",
      "-----------EPOCH-----------    ----->  2967\n",
      "Train Loss: 0.043622450357710355\n",
      "-----------EPOCH-----------    ----->  2968\n",
      "Train Loss: 0.04362180675534076\n",
      "-----------EPOCH-----------    ----->  2969\n",
      "Train Loss: 0.043621163570275734\n",
      "-----------EPOCH-----------    ----->  2970\n",
      "Train Loss: 0.04362052073785608\n",
      "-----------EPOCH-----------    ----->  2971\n",
      "Train Loss: 0.0436198770359421\n",
      "-----------EPOCH-----------    ----->  2972\n",
      "Train Loss: 0.043619233957744585\n",
      "-----------EPOCH-----------    ----->  2973\n",
      "Train Loss: 0.0436185917712469\n",
      "-----------EPOCH-----------    ----->  2974\n",
      "Train Loss: 0.04361794814660921\n",
      "-----------EPOCH-----------    ----->  2975\n",
      "Train Loss: 0.043617306593124516\n",
      "-----------EPOCH-----------    ----->  2976\n",
      "Train Loss: 0.043616667616863614\n",
      "-----------EPOCH-----------    ----->  2977\n",
      "Train Loss: 0.04361602895302948\n",
      "-----------EPOCH-----------    ----->  2978\n",
      "Train Loss: 0.0436153911502104\n",
      "-----------EPOCH-----------    ----->  2979\n",
      "Train Loss: 0.043614755444704785\n",
      "-----------EPOCH-----------    ----->  2980\n",
      "Train Loss: 0.04361412025893319\n",
      "-----------EPOCH-----------    ----->  2981\n",
      "Train Loss: 0.04361348515026926\n",
      "-----------EPOCH-----------    ----->  2982\n",
      "Train Loss: 0.04361285052335706\n",
      "-----------EPOCH-----------    ----->  2983\n",
      "Train Loss: 0.04361221510835018\n",
      "-----------EPOCH-----------    ----->  2984\n",
      "Train Loss: 0.04361157971106589\n",
      "-----------EPOCH-----------    ----->  2985\n",
      "Train Loss: 0.04361094491021746\n",
      "-----------EPOCH-----------    ----->  2986\n",
      "Train Loss: 0.04361031077655473\n",
      "-----------EPOCH-----------    ----->  2987\n",
      "Train Loss: 0.04360967654463771\n",
      "-----------EPOCH-----------    ----->  2988\n",
      "Train Loss: 0.04360904284090526\n",
      "-----------EPOCH-----------    ----->  2989\n",
      "Train Loss: 0.04360840908765902\n",
      "-----------EPOCH-----------    ----->  2990\n",
      "Train Loss: 0.04360777533877166\n",
      "-----------EPOCH-----------    ----->  2991\n",
      "Train Loss: 0.04360714195000194\n",
      "-----------EPOCH-----------    ----->  2992\n",
      "Train Loss: 0.04360650854128863\n",
      "-----------EPOCH-----------    ----->  2993\n",
      "Train Loss: 0.0436058752486822\n",
      "-----------EPOCH-----------    ----->  2994\n",
      "Train Loss: 0.04360524172971106\n",
      "-----------EPOCH-----------    ----->  2995\n",
      "Train Loss: 0.043604608766182024\n",
      "-----------EPOCH-----------    ----->  2996\n",
      "Train Loss: 0.043603975940876255\n",
      "-----------EPOCH-----------    ----->  2997\n",
      "Train Loss: 0.043603343677816694\n",
      "-----------EPOCH-----------    ----->  2998\n",
      "Train Loss: 0.043602711234099395\n",
      "-----------EPOCH-----------    ----->  2999\n",
      "Train Loss: 0.0436020801494234\n",
      "-----------EPOCH-----------    ----->  3000\n",
      "Train Loss: 0.043601449212227666\n",
      "-----------EPOCH-----------    ----->  3001\n",
      "Train Loss: 0.04360081818542298\n",
      "-----------EPOCH-----------    ----->  3002\n",
      "Train Loss: 0.043600183525489285\n",
      "-----------EPOCH-----------    ----->  3003\n",
      "Train Loss: 0.04359954894515962\n",
      "-----------EPOCH-----------    ----->  3004\n",
      "Train Loss: 0.04359891478198909\n",
      "-----------EPOCH-----------    ----->  3005\n",
      "Train Loss: 0.04359828053620633\n",
      "-----------EPOCH-----------    ----->  3006\n",
      "Train Loss: 0.04359764680727939\n",
      "-----------EPOCH-----------    ----->  3007\n",
      "Train Loss: 0.043597013572057315\n",
      "-----------EPOCH-----------    ----->  3008\n",
      "Train Loss: 0.04359638112431833\n",
      "-----------EPOCH-----------    ----->  3009\n",
      "Train Loss: 0.043595749071966595\n",
      "-----------EPOCH-----------    ----->  3010\n",
      "Train Loss: 0.043595117676102434\n",
      "-----------EPOCH-----------    ----->  3011\n",
      "Train Loss: 0.04359448471860217\n",
      "-----------EPOCH-----------    ----->  3012\n",
      "Train Loss: 0.04359385260247079\n",
      "-----------EPOCH-----------    ----->  3013\n",
      "Train Loss: 0.04359322100956835\n",
      "-----------EPOCH-----------    ----->  3014\n",
      "Train Loss: 0.04359258887248323\n",
      "-----------EPOCH-----------    ----->  3015\n",
      "Train Loss: 0.04359195755414604\n",
      "-----------EPOCH-----------    ----->  3016\n",
      "Train Loss: 0.04359132685749303\n",
      "-----------EPOCH-----------    ----->  3017\n",
      "Train Loss: 0.04359069652237231\n",
      "-----------EPOCH-----------    ----->  3018\n",
      "Train Loss: 0.04359006718953714\n",
      "-----------EPOCH-----------    ----->  3019\n",
      "Train Loss: 0.043589438081057585\n",
      "-----------EPOCH-----------    ----->  3020\n",
      "Train Loss: 0.04358880981472489\n",
      "-----------EPOCH-----------    ----->  3021\n",
      "Train Loss: 0.04358818213195983\n",
      "-----------EPOCH-----------    ----->  3022\n",
      "Train Loss: 0.0435875548707374\n",
      "-----------EPOCH-----------    ----->  3023\n",
      "Train Loss: 0.04358692769847738\n",
      "-----------EPOCH-----------    ----->  3024\n",
      "Train Loss: 0.043586300761812996\n",
      "-----------EPOCH-----------    ----->  3025\n",
      "Train Loss: 0.043585674958904565\n",
      "-----------EPOCH-----------    ----->  3026\n",
      "Train Loss: 0.043585048727274325\n",
      "-----------EPOCH-----------    ----->  3027\n",
      "Train Loss: 0.043584421406299825\n",
      "-----------EPOCH-----------    ----->  3028\n",
      "Train Loss: 0.04358379454028933\n",
      "-----------EPOCH-----------    ----->  3029\n",
      "Train Loss: 0.04358316802041193\n",
      "-----------EPOCH-----------    ----->  3030\n",
      "Train Loss: 0.043582542034987105\n",
      "-----------EPOCH-----------    ----->  3031\n",
      "Train Loss: 0.043581916409816596\n",
      "-----------EPOCH-----------    ----->  3032\n",
      "Train Loss: 0.043581291210515315\n",
      "-----------EPOCH-----------    ----->  3033\n",
      "Train Loss: 0.04358066627634275\n",
      "-----------EPOCH-----------    ----->  3034\n",
      "Train Loss: 0.0435800413569416\n",
      "-----------EPOCH-----------    ----->  3035\n",
      "Train Loss: 0.04357941744700791\n",
      "-----------EPOCH-----------    ----->  3036\n",
      "Train Loss: 0.04357879345637975\n",
      "-----------EPOCH-----------    ----->  3037\n",
      "Train Loss: 0.04357816966316947\n",
      "-----------EPOCH-----------    ----->  3038\n",
      "Train Loss: 0.04357754608882851\n",
      "-----------EPOCH-----------    ----->  3039\n",
      "Train Loss: 0.04357692235875856\n",
      "-----------EPOCH-----------    ----->  3040\n",
      "Train Loss: 0.043576299019639296\n",
      "-----------EPOCH-----------    ----->  3041\n",
      "Train Loss: 0.04357567666656071\n",
      "-----------EPOCH-----------    ----->  3042\n",
      "Train Loss: 0.043575055032022206\n",
      "-----------EPOCH-----------    ----->  3043\n",
      "Train Loss: 0.04357443408431471\n",
      "-----------EPOCH-----------    ----->  3044\n",
      "Train Loss: 0.04357381300867596\n",
      "-----------EPOCH-----------    ----->  3045\n",
      "Train Loss: 0.043573192011946114\n",
      "-----------EPOCH-----------    ----->  3046\n",
      "Train Loss: 0.04357257069213688\n",
      "-----------EPOCH-----------    ----->  3047\n",
      "Train Loss: 0.043571949601702645\n",
      "-----------EPOCH-----------    ----->  3048\n",
      "Train Loss: 0.043571329056283754\n",
      "-----------EPOCH-----------    ----->  3049\n",
      "Train Loss: 0.0435707087664163\n",
      "-----------EPOCH-----------    ----->  3050\n",
      "Train Loss: 0.0435700874704304\n",
      "-----------EPOCH-----------    ----->  3051\n",
      "Train Loss: 0.04356946598711056\n",
      "-----------EPOCH-----------    ----->  3052\n",
      "Train Loss: 0.04356884513418518\n",
      "-----------EPOCH-----------    ----->  3053\n",
      "Train Loss: 0.04356822459996212\n",
      "-----------EPOCH-----------    ----->  3054\n",
      "Train Loss: 0.043567603993876394\n",
      "-----------EPOCH-----------    ----->  3055\n",
      "Train Loss: 0.04356698309055035\n",
      "-----------EPOCH-----------    ----->  3056\n",
      "Train Loss: 0.04356636172810677\n",
      "-----------EPOCH-----------    ----->  3057\n",
      "Train Loss: 0.04356574085766372\n",
      "-----------EPOCH-----------    ----->  3058\n",
      "Train Loss: 0.043565120198079586\n",
      "-----------EPOCH-----------    ----->  3059\n",
      "Train Loss: 0.04356449955719177\n",
      "-----------EPOCH-----------    ----->  3060\n",
      "Train Loss: 0.04356387929708834\n",
      "-----------EPOCH-----------    ----->  3061\n",
      "Train Loss: 0.04356325851041256\n",
      "-----------EPOCH-----------    ----->  3062\n",
      "Train Loss: 0.04356263700284321\n",
      "-----------EPOCH-----------    ----->  3063\n",
      "Train Loss: 0.04356201503259428\n",
      "-----------EPOCH-----------    ----->  3064\n",
      "Train Loss: 0.04356139393063648\n",
      "-----------EPOCH-----------    ----->  3065\n",
      "Train Loss: 0.04356077239057662\n",
      "-----------EPOCH-----------    ----->  3066\n",
      "Train Loss: 0.04356014981268138\n",
      "-----------EPOCH-----------    ----->  3067\n",
      "Train Loss: 0.043559526025756606\n",
      "-----------EPOCH-----------    ----->  3068\n",
      "Train Loss: 0.04355890132241076\n",
      "-----------EPOCH-----------    ----->  3069\n",
      "Train Loss: 0.04355827656157438\n",
      "-----------EPOCH-----------    ----->  3070\n",
      "Train Loss: 0.04355765113471853\n",
      "-----------EPOCH-----------    ----->  3071\n",
      "Train Loss: 0.04355702530886853\n",
      "-----------EPOCH-----------    ----->  3072\n",
      "Train Loss: 0.043556399464031226\n",
      "-----------EPOCH-----------    ----->  3073\n",
      "Train Loss: 0.043555773775075066\n",
      "-----------EPOCH-----------    ----->  3074\n",
      "Train Loss: 0.04355514858950106\n",
      "-----------EPOCH-----------    ----->  3075\n",
      "Train Loss: 0.04355452278464097\n",
      "-----------EPOCH-----------    ----->  3076\n",
      "Train Loss: 0.04355389845010772\n",
      "-----------EPOCH-----------    ----->  3077\n",
      "Train Loss: 0.043553275999224816\n",
      "-----------EPOCH-----------    ----->  3078\n",
      "Train Loss: 0.04355265437399274\n",
      "-----------EPOCH-----------    ----->  3079\n",
      "Train Loss: 0.04355203402220662\n",
      "-----------EPOCH-----------    ----->  3080\n",
      "Train Loss: 0.043551414405512585\n",
      "-----------EPOCH-----------    ----->  3081\n",
      "Train Loss: 0.04355079544596184\n",
      "-----------EPOCH-----------    ----->  3082\n",
      "Train Loss: 0.043550176436973856\n",
      "-----------EPOCH-----------    ----->  3083\n",
      "Train Loss: 0.043549559157447675\n",
      "-----------EPOCH-----------    ----->  3084\n",
      "Train Loss: 0.043548942960163324\n",
      "-----------EPOCH-----------    ----->  3085\n",
      "Train Loss: 0.04354832529003633\n",
      "-----------EPOCH-----------    ----->  3086\n",
      "Train Loss: 0.04354770549472661\n",
      "-----------EPOCH-----------    ----->  3087\n",
      "Train Loss: 0.043547085187956025\n",
      "-----------EPOCH-----------    ----->  3088\n",
      "Train Loss: 0.043546465441794475\n",
      "-----------EPOCH-----------    ----->  3089\n",
      "Train Loss: 0.04354584641126757\n",
      "-----------EPOCH-----------    ----->  3090\n",
      "Train Loss: 0.04354522832527219\n",
      "-----------EPOCH-----------    ----->  3091\n",
      "Train Loss: 0.04354461018765744\n",
      "-----------EPOCH-----------    ----->  3092\n",
      "Train Loss: 0.04354399203594802\n",
      "-----------EPOCH-----------    ----->  3093\n",
      "Train Loss: 0.04354337381008951\n",
      "-----------EPOCH-----------    ----->  3094\n",
      "Train Loss: 0.04354275526620628\n",
      "-----------EPOCH-----------    ----->  3095\n",
      "Train Loss: 0.043542138731085374\n",
      "-----------EPOCH-----------    ----->  3096\n",
      "Train Loss: 0.043541522587269905\n",
      "-----------EPOCH-----------    ----->  3097\n",
      "Train Loss: 0.043540907570949985\n",
      "-----------EPOCH-----------    ----->  3098\n",
      "Train Loss: 0.0435402927271805\n",
      "-----------EPOCH-----------    ----->  3099\n",
      "Train Loss: 0.04353967856908766\n",
      "-----------EPOCH-----------    ----->  3100\n",
      "Train Loss: 0.04353906432195092\n",
      "-----------EPOCH-----------    ----->  3101\n",
      "Train Loss: 0.0435384506442012\n",
      "-----------EPOCH-----------    ----->  3102\n",
      "Train Loss: 0.04353783690279788\n",
      "-----------EPOCH-----------    ----->  3103\n",
      "Train Loss: 0.0435372231502178\n",
      "-----------EPOCH-----------    ----->  3104\n",
      "Train Loss: 0.04353660884111474\n",
      "-----------EPOCH-----------    ----->  3105\n",
      "Train Loss: 0.04353599482031638\n",
      "-----------EPOCH-----------    ----->  3106\n",
      "Train Loss: 0.04353538109988678\n",
      "-----------EPOCH-----------    ----->  3107\n",
      "Train Loss: 0.04353476758320923\n",
      "-----------EPOCH-----------    ----->  3108\n",
      "Train Loss: 0.04353415629975682\n",
      "-----------EPOCH-----------    ----->  3109\n",
      "Train Loss: 0.043533544440655166\n",
      "-----------EPOCH-----------    ----->  3110\n",
      "Train Loss: 0.04353293364584644\n",
      "-----------EPOCH-----------    ----->  3111\n",
      "Train Loss: 0.043532322883539816\n",
      "-----------EPOCH-----------    ----->  3112\n",
      "Train Loss: 0.04353171197761602\n",
      "-----------EPOCH-----------    ----->  3113\n",
      "Train Loss: 0.043531101959561544\n",
      "-----------EPOCH-----------    ----->  3114\n",
      "Train Loss: 0.043530492330060594\n",
      "-----------EPOCH-----------    ----->  3115\n",
      "Train Loss: 0.043529883617249146\n",
      "-----------EPOCH-----------    ----->  3116\n",
      "Train Loss: 0.04352927575673272\n",
      "-----------EPOCH-----------    ----->  3117\n",
      "Train Loss: 0.04352866885097239\n",
      "-----------EPOCH-----------    ----->  3118\n",
      "Train Loss: 0.0435280623775153\n",
      "-----------EPOCH-----------    ----->  3119\n",
      "Train Loss: 0.04352745696118137\n",
      "-----------EPOCH-----------    ----->  3120\n",
      "Train Loss: 0.04352685140410067\n",
      "-----------EPOCH-----------    ----->  3121\n",
      "Train Loss: 0.04352624699883669\n",
      "-----------EPOCH-----------    ----->  3122\n",
      "Train Loss: 0.043525642470072776\n",
      "-----------EPOCH-----------    ----->  3123\n",
      "Train Loss: 0.04352503899032722\n",
      "-----------EPOCH-----------    ----->  3124\n",
      "Train Loss: 0.043524435654009486\n",
      "-----------EPOCH-----------    ----->  3125\n",
      "Train Loss: 0.04352383210362813\n",
      "-----------EPOCH-----------    ----->  3126\n",
      "Train Loss: 0.043523228657884085\n",
      "-----------EPOCH-----------    ----->  3127\n",
      "Train Loss: 0.04352262535833425\n",
      "-----------EPOCH-----------    ----->  3128\n",
      "Train Loss: 0.04352202206618548\n",
      "-----------EPOCH-----------    ----->  3129\n",
      "Train Loss: 0.04352141904262617\n",
      "-----------EPOCH-----------    ----->  3130\n",
      "Train Loss: 0.04352081483251148\n",
      "-----------EPOCH-----------    ----->  3131\n",
      "Train Loss: 0.043520211523201756\n",
      "-----------EPOCH-----------    ----->  3132\n",
      "Train Loss: 0.04351960857263147\n",
      "-----------EPOCH-----------    ----->  3133\n",
      "Train Loss: 0.043519006103646576\n",
      "-----------EPOCH-----------    ----->  3134\n",
      "Train Loss: 0.04351840368448295\n",
      "-----------EPOCH-----------    ----->  3135\n",
      "Train Loss: 0.04351780258629591\n",
      "-----------EPOCH-----------    ----->  3136\n",
      "Train Loss: 0.04351720191832926\n",
      "-----------EPOCH-----------    ----->  3137\n",
      "Train Loss: 0.043516603751156534\n",
      "-----------EPOCH-----------    ----->  3138\n",
      "Train Loss: 0.04351600501954837\n",
      "-----------EPOCH-----------    ----->  3139\n",
      "Train Loss: 0.043515406826457666\n",
      "-----------EPOCH-----------    ----->  3140\n",
      "Train Loss: 0.043514808588196015\n",
      "-----------EPOCH-----------    ----->  3141\n",
      "Train Loss: 0.04351421116691344\n",
      "-----------EPOCH-----------    ----->  3142\n",
      "Train Loss: 0.04351361402793537\n",
      "-----------EPOCH-----------    ----->  3143\n",
      "Train Loss: 0.04351301751896557\n",
      "-----------EPOCH-----------    ----->  3144\n",
      "Train Loss: 0.043512420811151996\n",
      "-----------EPOCH-----------    ----->  3145\n",
      "Train Loss: 0.04351182472097457\n",
      "-----------EPOCH-----------    ----->  3146\n",
      "Train Loss: 0.04351122887925759\n",
      "-----------EPOCH-----------    ----->  3147\n",
      "Train Loss: 0.04351063361818802\n",
      "-----------EPOCH-----------    ----->  3148\n",
      "Train Loss: 0.04351003855326372\n",
      "-----------EPOCH-----------    ----->  3149\n",
      "Train Loss: 0.043509443782384284\n",
      "-----------EPOCH-----------    ----->  3150\n",
      "Train Loss: 0.043508849294708704\n",
      "-----------EPOCH-----------    ----->  3151\n",
      "Train Loss: 0.04350825481931426\n",
      "-----------EPOCH-----------    ----->  3152\n",
      "Train Loss: 0.04350766007533998\n",
      "-----------EPOCH-----------    ----->  3153\n",
      "Train Loss: 0.04350706582852374\n",
      "-----------EPOCH-----------    ----->  3154\n",
      "Train Loss: 0.04350647208668832\n",
      "-----------EPOCH-----------    ----->  3155\n",
      "Train Loss: 0.04350587892658707\n",
      "-----------EPOCH-----------    ----->  3156\n",
      "Train Loss: 0.04350528565630055\n",
      "-----------EPOCH-----------    ----->  3157\n",
      "Train Loss: 0.0435046938083844\n",
      "-----------EPOCH-----------    ----->  3158\n",
      "Train Loss: 0.04350410115478454\n",
      "-----------EPOCH-----------    ----->  3159\n",
      "Train Loss: 0.043503508980813746\n",
      "-----------EPOCH-----------    ----->  3160\n",
      "Train Loss: 0.04350291597581435\n",
      "-----------EPOCH-----------    ----->  3161\n",
      "Train Loss: 0.0435023234457714\n",
      "-----------EPOCH-----------    ----->  3162\n",
      "Train Loss: 0.04350173129325272\n",
      "-----------EPOCH-----------    ----->  3163\n",
      "Train Loss: 0.04350114025677279\n",
      "-----------EPOCH-----------    ----->  3164\n",
      "Train Loss: 0.043500549853296586\n",
      "-----------EPOCH-----------    ----->  3165\n",
      "Train Loss: 0.04349995933358049\n",
      "-----------EPOCH-----------    ----->  3166\n",
      "Train Loss: 0.04349936903367006\n",
      "-----------EPOCH-----------    ----->  3167\n",
      "Train Loss: 0.04349877930568416\n",
      "-----------EPOCH-----------    ----->  3168\n",
      "Train Loss: 0.04349819029279915\n",
      "-----------EPOCH-----------    ----->  3169\n",
      "Train Loss: 0.04349760217285874\n",
      "-----------EPOCH-----------    ----->  3170\n",
      "Train Loss: 0.0434970143339762\n",
      "-----------EPOCH-----------    ----->  3171\n",
      "Train Loss: 0.043496427115446046\n",
      "-----------EPOCH-----------    ----->  3172\n",
      "Train Loss: 0.04349584110115815\n",
      "-----------EPOCH-----------    ----->  3173\n",
      "Train Loss: 0.04349525492657373\n",
      "-----------EPOCH-----------    ----->  3174\n",
      "Train Loss: 0.0434946690370271\n",
      "-----------EPOCH-----------    ----->  3175\n",
      "Train Loss: 0.04349408329994447\n",
      "-----------EPOCH-----------    ----->  3176\n",
      "Train Loss: 0.04349349771403861\n",
      "-----------EPOCH-----------    ----->  3177\n",
      "Train Loss: 0.04349291284111813\n",
      "-----------EPOCH-----------    ----->  3178\n",
      "Train Loss: 0.043492327838332935\n",
      "-----------EPOCH-----------    ----->  3179\n",
      "Train Loss: 0.04349174244150063\n",
      "-----------EPOCH-----------    ----->  3180\n",
      "Train Loss: 0.04349115752856697\n",
      "-----------EPOCH-----------    ----->  3181\n",
      "Train Loss: 0.04349057273427292\n",
      "-----------EPOCH-----------    ----->  3182\n",
      "Train Loss: 0.0434899870892081\n",
      "-----------EPOCH-----------    ----->  3183\n",
      "Train Loss: 0.04348940146120689\n",
      "-----------EPOCH-----------    ----->  3184\n",
      "Train Loss: 0.043488815805482084\n",
      "-----------EPOCH-----------    ----->  3185\n",
      "Train Loss: 0.0434882298078664\n",
      "-----------EPOCH-----------    ----->  3186\n",
      "Train Loss: 0.04348764442186993\n",
      "-----------EPOCH-----------    ----->  3187\n",
      "Train Loss: 0.04348705850386855\n",
      "-----------EPOCH-----------    ----->  3188\n",
      "Train Loss: 0.04348647237603376\n",
      "-----------EPOCH-----------    ----->  3189\n",
      "Train Loss: 0.043485886540751806\n",
      "-----------EPOCH-----------    ----->  3190\n",
      "Train Loss: 0.043485300593138425\n",
      "-----------EPOCH-----------    ----->  3191\n",
      "Train Loss: 0.04348471523828207\n",
      "-----------EPOCH-----------    ----->  3192\n",
      "Train Loss: 0.043484130189155014\n",
      "-----------EPOCH-----------    ----->  3193\n",
      "Train Loss: 0.043483545098522446\n",
      "-----------EPOCH-----------    ----->  3194\n",
      "Train Loss: 0.0434829609592218\n",
      "-----------EPOCH-----------    ----->  3195\n",
      "Train Loss: 0.043482376683767344\n",
      "-----------EPOCH-----------    ----->  3196\n",
      "Train Loss: 0.043481790858919976\n",
      "-----------EPOCH-----------    ----->  3197\n",
      "Train Loss: 0.04348120625320901\n",
      "-----------EPOCH-----------    ----->  3198\n",
      "Train Loss: 0.04348062165388069\n",
      "-----------EPOCH-----------    ----->  3199\n",
      "Train Loss: 0.043480037978338465\n",
      "-----------EPOCH-----------    ----->  3200\n",
      "Train Loss: 0.043479454795108\n",
      "-----------EPOCH-----------    ----->  3201\n",
      "Train Loss: 0.04347887197723481\n",
      "-----------EPOCH-----------    ----->  3202\n",
      "Train Loss: 0.0434782902596951\n",
      "-----------EPOCH-----------    ----->  3203\n",
      "Train Loss: 0.043477708273418375\n",
      "-----------EPOCH-----------    ----->  3204\n",
      "Train Loss: 0.04347712618316045\n",
      "-----------EPOCH-----------    ----->  3205\n",
      "Train Loss: 0.043476543481435884\n",
      "-----------EPOCH-----------    ----->  3206\n",
      "Train Loss: 0.043475960535110644\n",
      "-----------EPOCH-----------    ----->  3207\n",
      "Train Loss: 0.043475377550165145\n",
      "-----------EPOCH-----------    ----->  3208\n",
      "Train Loss: 0.04347479401716372\n",
      "-----------EPOCH-----------    ----->  3209\n",
      "Train Loss: 0.04347421127375678\n",
      "-----------EPOCH-----------    ----->  3210\n",
      "Train Loss: 0.04347362875544169\n",
      "-----------EPOCH-----------    ----->  3211\n",
      "Train Loss: 0.043473047128368976\n",
      "-----------EPOCH-----------    ----->  3212\n",
      "Train Loss: 0.043472466237284256\n",
      "-----------EPOCH-----------    ----->  3213\n",
      "Train Loss: 0.043471886347659465\n",
      "-----------EPOCH-----------    ----->  3214\n",
      "Train Loss: 0.04347130677755215\n",
      "-----------EPOCH-----------    ----->  3215\n",
      "Train Loss: 0.04347072683844466\n",
      "-----------EPOCH-----------    ----->  3216\n",
      "Train Loss: 0.04347014738997271\n",
      "-----------EPOCH-----------    ----->  3217\n",
      "Train Loss: 0.04346956813172039\n",
      "-----------EPOCH-----------    ----->  3218\n",
      "Train Loss: 0.04346898870789091\n",
      "-----------EPOCH-----------    ----->  3219\n",
      "Train Loss: 0.04346840973574664\n",
      "-----------EPOCH-----------    ----->  3220\n",
      "Train Loss: 0.04346783043114434\n",
      "-----------EPOCH-----------    ----->  3221\n",
      "Train Loss: 0.04346725188075055\n",
      "-----------EPOCH-----------    ----->  3222\n",
      "Train Loss: 0.043466672845850096\n",
      "-----------EPOCH-----------    ----->  3223\n",
      "Train Loss: 0.04346609449377763\n",
      "-----------EPOCH-----------    ----->  3224\n",
      "Train Loss: 0.04346551704694074\n",
      "-----------EPOCH-----------    ----->  3225\n",
      "Train Loss: 0.04346494003266834\n",
      "-----------EPOCH-----------    ----->  3226\n",
      "Train Loss: 0.04346436304899798\n",
      "-----------EPOCH-----------    ----->  3227\n",
      "Train Loss: 0.043463786742462686\n",
      "-----------EPOCH-----------    ----->  3228\n",
      "Train Loss: 0.04346321074307334\n",
      "-----------EPOCH-----------    ----->  3229\n",
      "Train Loss: 0.043462634467108574\n",
      "-----------EPOCH-----------    ----->  3230\n",
      "Train Loss: 0.043462059204308366\n",
      "-----------EPOCH-----------    ----->  3231\n",
      "Train Loss: 0.04346148407854617\n",
      "-----------EPOCH-----------    ----->  3232\n",
      "Train Loss: 0.04346091017613329\n",
      "-----------EPOCH-----------    ----->  3233\n",
      "Train Loss: 0.04346033576450972\n",
      "-----------EPOCH-----------    ----->  3234\n",
      "Train Loss: 0.04345976171012179\n",
      "-----------EPOCH-----------    ----->  3235\n",
      "Train Loss: 0.04345918703697361\n",
      "-----------EPOCH-----------    ----->  3236\n",
      "Train Loss: 0.04345861305060203\n",
      "-----------EPOCH-----------    ----->  3237\n",
      "Train Loss: 0.04345803983840854\n",
      "-----------EPOCH-----------    ----->  3238\n",
      "Train Loss: 0.04345746747235222\n",
      "-----------EPOCH-----------    ----->  3239\n",
      "Train Loss: 0.04345689469051966\n",
      "-----------EPOCH-----------    ----->  3240\n",
      "Train Loss: 0.043456323130673505\n",
      "-----------EPOCH-----------    ----->  3241\n",
      "Train Loss: 0.04345575113058081\n",
      "-----------EPOCH-----------    ----->  3242\n",
      "Train Loss: 0.04345517907994937\n",
      "-----------EPOCH-----------    ----->  3243\n",
      "Train Loss: 0.04345460656924732\n",
      "-----------EPOCH-----------    ----->  3244\n",
      "Train Loss: 0.04345403468886726\n",
      "-----------EPOCH-----------    ----->  3245\n",
      "Train Loss: 0.04345346287858422\n",
      "-----------EPOCH-----------    ----->  3246\n",
      "Train Loss: 0.04345289190652286\n",
      "-----------EPOCH-----------    ----->  3247\n",
      "Train Loss: 0.04345232099772528\n",
      "-----------EPOCH-----------    ----->  3248\n",
      "Train Loss: 0.043451751726360406\n",
      "-----------EPOCH-----------    ----->  3249\n",
      "Train Loss: 0.043451181682555774\n",
      "-----------EPOCH-----------    ----->  3250\n",
      "Train Loss: 0.043450611793483356\n",
      "-----------EPOCH-----------    ----->  3251\n",
      "Train Loss: 0.04345004325701262\n",
      "-----------EPOCH-----------    ----->  3252\n",
      "Train Loss: 0.04344947640546108\n",
      "-----------EPOCH-----------    ----->  3253\n",
      "Train Loss: 0.04344891019572258\n",
      "-----------EPOCH-----------    ----->  3254\n",
      "Train Loss: 0.043448343785468836\n",
      "-----------EPOCH-----------    ----->  3255\n",
      "Train Loss: 0.04344777772057281\n",
      "-----------EPOCH-----------    ----->  3256\n",
      "Train Loss: 0.04344721162987811\n",
      "-----------EPOCH-----------    ----->  3257\n",
      "Train Loss: 0.043446645752663424\n",
      "-----------EPOCH-----------    ----->  3258\n",
      "Train Loss: 0.04344607908855162\n",
      "-----------EPOCH-----------    ----->  3259\n",
      "Train Loss: 0.04344551261920163\n",
      "-----------EPOCH-----------    ----->  3260\n",
      "Train Loss: 0.0434449462281696\n",
      "-----------EPOCH-----------    ----->  3261\n",
      "Train Loss: 0.04344437869164346\n",
      "-----------EPOCH-----------    ----->  3262\n",
      "Train Loss: 0.04344381075298371\n",
      "-----------EPOCH-----------    ----->  3263\n",
      "Train Loss: 0.04344324312915143\n",
      "-----------EPOCH-----------    ----->  3264\n",
      "Train Loss: 0.04344267585878925\n",
      "-----------EPOCH-----------    ----->  3265\n",
      "Train Loss: 0.04344210833817382\n",
      "-----------EPOCH-----------    ----->  3266\n",
      "Train Loss: 0.04344154179965886\n",
      "-----------EPOCH-----------    ----->  3267\n",
      "Train Loss: 0.043440975695254395\n",
      "-----------EPOCH-----------    ----->  3268\n",
      "Train Loss: 0.04344041066828064\n",
      "-----------EPOCH-----------    ----->  3269\n",
      "Train Loss: 0.043439846112952485\n",
      "-----------EPOCH-----------    ----->  3270\n",
      "Train Loss: 0.043439281351582926\n",
      "-----------EPOCH-----------    ----->  3271\n",
      "Train Loss: 0.04343871746801315\n",
      "-----------EPOCH-----------    ----->  3272\n",
      "Train Loss: 0.043438153675203886\n",
      "-----------EPOCH-----------    ----->  3273\n",
      "Train Loss: 0.04343758997880373\n",
      "-----------EPOCH-----------    ----->  3274\n",
      "Train Loss: 0.04343702531476024\n",
      "-----------EPOCH-----------    ----->  3275\n",
      "Train Loss: 0.04343645878998238\n",
      "-----------EPOCH-----------    ----->  3276\n",
      "Train Loss: 0.04343589105637341\n",
      "-----------EPOCH-----------    ----->  3277\n",
      "Train Loss: 0.043435322913020914\n",
      "-----------EPOCH-----------    ----->  3278\n",
      "Train Loss: 0.043434754338843244\n",
      "-----------EPOCH-----------    ----->  3279\n",
      "Train Loss: 0.04343418587554549\n",
      "-----------EPOCH-----------    ----->  3280\n",
      "Train Loss: 0.04343361739316813\n",
      "-----------EPOCH-----------    ----->  3281\n",
      "Train Loss: 0.04343305093701411\n",
      "-----------EPOCH-----------    ----->  3282\n",
      "Train Loss: 0.04343248636969208\n",
      "-----------EPOCH-----------    ----->  3283\n",
      "Train Loss: 0.04343192192533192\n",
      "-----------EPOCH-----------    ----->  3284\n",
      "Train Loss: 0.043431357917782784\n",
      "-----------EPOCH-----------    ----->  3285\n",
      "Train Loss: 0.043430794706465825\n",
      "-----------EPOCH-----------    ----->  3286\n",
      "Train Loss: 0.04343023331784523\n",
      "-----------EPOCH-----------    ----->  3287\n",
      "Train Loss: 0.04342967190236555\n",
      "-----------EPOCH-----------    ----->  3288\n",
      "Train Loss: 0.04342911195491302\n",
      "-----------EPOCH-----------    ----->  3289\n",
      "Train Loss: 0.043428551966757205\n",
      "-----------EPOCH-----------    ----->  3290\n",
      "Train Loss: 0.04342799238577176\n",
      "-----------EPOCH-----------    ----->  3291\n",
      "Train Loss: 0.04342743361488984\n",
      "-----------EPOCH-----------    ----->  3292\n",
      "Train Loss: 0.04342687443059903\n",
      "-----------EPOCH-----------    ----->  3293\n",
      "Train Loss: 0.04342631596427067\n",
      "-----------EPOCH-----------    ----->  3294\n",
      "Train Loss: 0.04342575786185254\n",
      "-----------EPOCH-----------    ----->  3295\n",
      "Train Loss: 0.04342520022611972\n",
      "-----------EPOCH-----------    ----->  3296\n",
      "Train Loss: 0.04342464275564922\n",
      "-----------EPOCH-----------    ----->  3297\n",
      "Train Loss: 0.04342408567497014\n",
      "-----------EPOCH-----------    ----->  3298\n",
      "Train Loss: 0.04342352896631583\n",
      "-----------EPOCH-----------    ----->  3299\n",
      "Train Loss: 0.04342297153001289\n",
      "-----------EPOCH-----------    ----->  3300\n",
      "Train Loss: 0.0434224140508838\n",
      "-----------EPOCH-----------    ----->  3301\n",
      "Train Loss: 0.043421856792069016\n",
      "-----------EPOCH-----------    ----->  3302\n",
      "Train Loss: 0.04342129946291449\n",
      "-----------EPOCH-----------    ----->  3303\n",
      "Train Loss: 0.04342074087111604\n",
      "-----------EPOCH-----------    ----->  3304\n",
      "Train Loss: 0.043420183187097616\n",
      "-----------EPOCH-----------    ----->  3305\n",
      "Train Loss: 0.0434196259713791\n",
      "-----------EPOCH-----------    ----->  3306\n",
      "Train Loss: 0.04341907019581477\n",
      "-----------EPOCH-----------    ----->  3307\n",
      "Train Loss: 0.043418514767144145\n",
      "-----------EPOCH-----------    ----->  3308\n",
      "Train Loss: 0.043417960228867285\n",
      "-----------EPOCH-----------    ----->  3309\n",
      "Train Loss: 0.04341740571728956\n",
      "-----------EPOCH-----------    ----->  3310\n",
      "Train Loss: 0.04341685212211042\n",
      "-----------EPOCH-----------    ----->  3311\n",
      "Train Loss: 0.043416298815064217\n",
      "-----------EPOCH-----------    ----->  3312\n",
      "Train Loss: 0.04341574646308857\n",
      "-----------EPOCH-----------    ----->  3313\n",
      "Train Loss: 0.04341519434998129\n",
      "-----------EPOCH-----------    ----->  3314\n",
      "Train Loss: 0.04341464296515222\n",
      "-----------EPOCH-----------    ----->  3315\n",
      "Train Loss: 0.04341409121117452\n",
      "-----------EPOCH-----------    ----->  3316\n",
      "Train Loss: 0.04341353916611362\n",
      "-----------EPOCH-----------    ----->  3317\n",
      "Train Loss: 0.04341298477063347\n",
      "-----------EPOCH-----------    ----->  3318\n",
      "Train Loss: 0.043412430905237644\n",
      "-----------EPOCH-----------    ----->  3319\n",
      "Train Loss: 0.04341187756898669\n",
      "-----------EPOCH-----------    ----->  3320\n",
      "Train Loss: 0.04341132467118636\n",
      "-----------EPOCH-----------    ----->  3321\n",
      "Train Loss: 0.04341077063365482\n",
      "-----------EPOCH-----------    ----->  3322\n",
      "Train Loss: 0.043410217054744724\n",
      "-----------EPOCH-----------    ----->  3323\n",
      "Train Loss: 0.043409663625607636\n",
      "-----------EPOCH-----------    ----->  3324\n",
      "Train Loss: 0.043409109405738236\n",
      "-----------EPOCH-----------    ----->  3325\n",
      "Train Loss: 0.043408556508962505\n",
      "-----------EPOCH-----------    ----->  3326\n",
      "Train Loss: 0.04340800298410141\n",
      "-----------EPOCH-----------    ----->  3327\n",
      "Train Loss: 0.04340744971208\n",
      "-----------EPOCH-----------    ----->  3328\n",
      "Train Loss: 0.043406896388303105\n",
      "-----------EPOCH-----------    ----->  3329\n",
      "Train Loss: 0.04340634407606078\n",
      "-----------EPOCH-----------    ----->  3330\n",
      "Train Loss: 0.04340579234061345\n",
      "-----------EPOCH-----------    ----->  3331\n",
      "Train Loss: 0.043405241044732014\n",
      "-----------EPOCH-----------    ----->  3332\n",
      "Train Loss: 0.04340469174390988\n",
      "-----------EPOCH-----------    ----->  3333\n",
      "Train Loss: 0.04340414260529236\n",
      "-----------EPOCH-----------    ----->  3334\n",
      "Train Loss: 0.043403594933777594\n",
      "-----------EPOCH-----------    ----->  3335\n",
      "Train Loss: 0.04340304707786794\n",
      "-----------EPOCH-----------    ----->  3336\n",
      "Train Loss: 0.043402498689264844\n",
      "-----------EPOCH-----------    ----->  3337\n",
      "Train Loss: 0.04340195055498741\n",
      "-----------EPOCH-----------    ----->  3338\n",
      "Train Loss: 0.043401402642338695\n",
      "-----------EPOCH-----------    ----->  3339\n",
      "Train Loss: 0.0434008542079599\n",
      "-----------EPOCH-----------    ----->  3340\n",
      "Train Loss: 0.0434003052397322\n",
      "-----------EPOCH-----------    ----->  3341\n",
      "Train Loss: 0.04339975562952449\n",
      "-----------EPOCH-----------    ----->  3342\n",
      "Train Loss: 0.043399206494310894\n",
      "-----------EPOCH-----------    ----->  3343\n",
      "Train Loss: 0.04339865641754227\n",
      "-----------EPOCH-----------    ----->  3344\n",
      "Train Loss: 0.04339810676813886\n",
      "-----------EPOCH-----------    ----->  3345\n",
      "Train Loss: 0.0433975569108775\n",
      "-----------EPOCH-----------    ----->  3346\n",
      "Train Loss: 0.04339700746954377\n",
      "-----------EPOCH-----------    ----->  3347\n",
      "Train Loss: 0.04339645797247097\n",
      "-----------EPOCH-----------    ----->  3348\n",
      "Train Loss: 0.04339590840031703\n",
      "-----------EPOCH-----------    ----->  3349\n",
      "Train Loss: 0.043395358621306515\n",
      "-----------EPOCH-----------    ----->  3350\n",
      "Train Loss: 0.04339480808884839\n",
      "-----------EPOCH-----------    ----->  3351\n",
      "Train Loss: 0.043394257687784266\n",
      "-----------EPOCH-----------    ----->  3352\n",
      "Train Loss: 0.04339370667252753\n",
      "-----------EPOCH-----------    ----->  3353\n",
      "Train Loss: 0.04339315579210832\n",
      "-----------EPOCH-----------    ----->  3354\n",
      "Train Loss: 0.0433926047575002\n",
      "-----------EPOCH-----------    ----->  3355\n",
      "Train Loss: 0.043392053843650316\n",
      "-----------EPOCH-----------    ----->  3356\n",
      "Train Loss: 0.04339150296681266\n",
      "-----------EPOCH-----------    ----->  3357\n",
      "Train Loss: 0.04339095264031471\n",
      "-----------EPOCH-----------    ----->  3358\n",
      "Train Loss: 0.04339040238098174\n",
      "-----------EPOCH-----------    ----->  3359\n",
      "Train Loss: 0.043389852079607154\n",
      "-----------EPOCH-----------    ----->  3360\n",
      "Train Loss: 0.043389301867832665\n",
      "-----------EPOCH-----------    ----->  3361\n",
      "Train Loss: 0.0433887520439821\n",
      "-----------EPOCH-----------    ----->  3362\n",
      "Train Loss: 0.04338820234545383\n",
      "-----------EPOCH-----------    ----->  3363\n",
      "Train Loss: 0.0433876528389715\n",
      "-----------EPOCH-----------    ----->  3364\n",
      "Train Loss: 0.04338710443507619\n",
      "-----------EPOCH-----------    ----->  3365\n",
      "Train Loss: 0.0433865561392818\n",
      "-----------EPOCH-----------    ----->  3366\n",
      "Train Loss: 0.04338600814555957\n",
      "-----------EPOCH-----------    ----->  3367\n",
      "Train Loss: 0.04338545991688858\n",
      "-----------EPOCH-----------    ----->  3368\n",
      "Train Loss: 0.04338491178399587\n",
      "-----------EPOCH-----------    ----->  3369\n",
      "Train Loss: 0.04338436356618748\n",
      "-----------EPOCH-----------    ----->  3370\n",
      "Train Loss: 0.04338381570832337\n",
      "-----------EPOCH-----------    ----->  3371\n",
      "Train Loss: 0.04338326869523676\n",
      "-----------EPOCH-----------    ----->  3372\n",
      "Train Loss: 0.04338272185020839\n",
      "-----------EPOCH-----------    ----->  3373\n",
      "Train Loss: 0.04338217631826277\n",
      "-----------EPOCH-----------    ----->  3374\n",
      "Train Loss: 0.043381630958972184\n",
      "-----------EPOCH-----------    ----->  3375\n",
      "Train Loss: 0.04338108666949446\n",
      "-----------EPOCH-----------    ----->  3376\n",
      "Train Loss: 0.043380542322923585\n",
      "-----------EPOCH-----------    ----->  3377\n",
      "Train Loss: 0.04337999786681878\n",
      "-----------EPOCH-----------    ----->  3378\n",
      "Train Loss: 0.04337945398249266\n",
      "-----------EPOCH-----------    ----->  3379\n",
      "Train Loss: 0.04337891110136096\n",
      "-----------EPOCH-----------    ----->  3380\n",
      "Train Loss: 0.04337836854855758\n",
      "-----------EPOCH-----------    ----->  3381\n",
      "Train Loss: 0.04337782662238511\n",
      "-----------EPOCH-----------    ----->  3382\n",
      "Train Loss: 0.04337728518706369\n",
      "-----------EPOCH-----------    ----->  3383\n",
      "Train Loss: 0.04337674317360193\n",
      "-----------EPOCH-----------    ----->  3384\n",
      "Train Loss: 0.043376201465727404\n",
      "-----------EPOCH-----------    ----->  3385\n",
      "Train Loss: 0.043375659467846134\n",
      "-----------EPOCH-----------    ----->  3386\n",
      "Train Loss: 0.043375117908251236\n",
      "-----------EPOCH-----------    ----->  3387\n",
      "Train Loss: 0.04337457660448858\n",
      "-----------EPOCH-----------    ----->  3388\n",
      "Train Loss: 0.04337403607453381\n",
      "-----------EPOCH-----------    ----->  3389\n",
      "Train Loss: 0.04337349572428308\n",
      "-----------EPOCH-----------    ----->  3390\n",
      "Train Loss: 0.043372955279131646\n",
      "-----------EPOCH-----------    ----->  3391\n",
      "Train Loss: 0.04337241507155854\n",
      "-----------EPOCH-----------    ----->  3392\n",
      "Train Loss: 0.04337187557848289\n",
      "-----------EPOCH-----------    ----->  3393\n",
      "Train Loss: 0.04337133650306464\n",
      "-----------EPOCH-----------    ----->  3394\n",
      "Train Loss: 0.043370798535156116\n",
      "-----------EPOCH-----------    ----->  3395\n",
      "Train Loss: 0.04337025971911833\n",
      "-----------EPOCH-----------    ----->  3396\n",
      "Train Loss: 0.04336972128571395\n",
      "-----------EPOCH-----------    ----->  3397\n",
      "Train Loss: 0.04336918302212737\n",
      "-----------EPOCH-----------    ----->  3398\n",
      "Train Loss: 0.04336864369828635\n",
      "-----------EPOCH-----------    ----->  3399\n",
      "Train Loss: 0.043368104748504\n",
      "-----------EPOCH-----------    ----->  3400\n",
      "Train Loss: 0.04336756526511181\n",
      "-----------EPOCH-----------    ----->  3401\n",
      "Train Loss: 0.04336702597124611\n",
      "-----------EPOCH-----------    ----->  3402\n",
      "Train Loss: 0.04336648635779967\n",
      "-----------EPOCH-----------    ----->  3403\n",
      "Train Loss: 0.043365946337458064\n",
      "-----------EPOCH-----------    ----->  3404\n",
      "Train Loss: 0.04336540700431472\n",
      "-----------EPOCH-----------    ----->  3405\n",
      "Train Loss: 0.04336486773729297\n",
      "-----------EPOCH-----------    ----->  3406\n",
      "Train Loss: 0.04336432867064411\n",
      "-----------EPOCH-----------    ----->  3407\n",
      "Train Loss: 0.0433637903960746\n",
      "-----------EPOCH-----------    ----->  3408\n",
      "Train Loss: 0.04336325132613895\n",
      "-----------EPOCH-----------    ----->  3409\n",
      "Train Loss: 0.04336271121494881\n",
      "-----------EPOCH-----------    ----->  3410\n",
      "Train Loss: 0.04336217153189197\n",
      "-----------EPOCH-----------    ----->  3411\n",
      "Train Loss: 0.04336163261790801\n",
      "-----------EPOCH-----------    ----->  3412\n",
      "Train Loss: 0.043361095152967065\n",
      "-----------EPOCH-----------    ----->  3413\n",
      "Train Loss: 0.0433605564567102\n",
      "-----------EPOCH-----------    ----->  3414\n",
      "Train Loss: 0.04336001657515257\n",
      "-----------EPOCH-----------    ----->  3415\n",
      "Train Loss: 0.04335947704628362\n",
      "-----------EPOCH-----------    ----->  3416\n",
      "Train Loss: 0.04335893768146983\n",
      "-----------EPOCH-----------    ----->  3417\n",
      "Train Loss: 0.04335839899964875\n",
      "-----------EPOCH-----------    ----->  3418\n",
      "Train Loss: 0.04335786082581813\n",
      "-----------EPOCH-----------    ----->  3419\n",
      "Train Loss: 0.043357323008595815\n",
      "-----------EPOCH-----------    ----->  3420\n",
      "Train Loss: 0.04335678599246726\n",
      "-----------EPOCH-----------    ----->  3421\n",
      "Train Loss: 0.04335624915953819\n",
      "-----------EPOCH-----------    ----->  3422\n",
      "Train Loss: 0.04335571245546596\n",
      "-----------EPOCH-----------    ----->  3423\n",
      "Train Loss: 0.043355175472965454\n",
      "-----------EPOCH-----------    ----->  3424\n",
      "Train Loss: 0.04335463827697036\n",
      "-----------EPOCH-----------    ----->  3425\n",
      "Train Loss: 0.04335410146134326\n",
      "-----------EPOCH-----------    ----->  3426\n",
      "Train Loss: 0.04335356514653197\n",
      "-----------EPOCH-----------    ----->  3427\n",
      "Train Loss: 0.04335302923753569\n",
      "-----------EPOCH-----------    ----->  3428\n",
      "Train Loss: 0.0433524940847454\n",
      "-----------EPOCH-----------    ----->  3429\n",
      "Train Loss: 0.04335196008819236\n",
      "-----------EPOCH-----------    ----->  3430\n",
      "Train Loss: 0.04335142629068913\n",
      "-----------EPOCH-----------    ----->  3431\n",
      "Train Loss: 0.04335089080444845\n",
      "-----------EPOCH-----------    ----->  3432\n",
      "Train Loss: 0.04335035305394399\n",
      "-----------EPOCH-----------    ----->  3433\n",
      "Train Loss: 0.04334981513917683\n",
      "-----------EPOCH-----------    ----->  3434\n",
      "Train Loss: 0.04334927781511759\n",
      "-----------EPOCH-----------    ----->  3435\n",
      "Train Loss: 0.043348740298386285\n",
      "-----------EPOCH-----------    ----->  3436\n",
      "Train Loss: 0.043348202712088335\n",
      "-----------EPOCH-----------    ----->  3437\n",
      "Train Loss: 0.043347665017097727\n",
      "-----------EPOCH-----------    ----->  3438\n",
      "Train Loss: 0.043347126974960584\n",
      "-----------EPOCH-----------    ----->  3439\n",
      "Train Loss: 0.043346588312072346\n",
      "-----------EPOCH-----------    ----->  3440\n",
      "Train Loss: 0.04334605001288439\n",
      "-----------EPOCH-----------    ----->  3441\n",
      "Train Loss: 0.04334551073473504\n",
      "-----------EPOCH-----------    ----->  3442\n",
      "Train Loss: 0.04334497134148158\n",
      "-----------EPOCH-----------    ----->  3443\n",
      "Train Loss: 0.043344432231033805\n",
      "-----------EPOCH-----------    ----->  3444\n",
      "Train Loss: 0.043343893610421735\n",
      "-----------EPOCH-----------    ----->  3445\n",
      "Train Loss: 0.04334335566794574\n",
      "-----------EPOCH-----------    ----->  3446\n",
      "Train Loss: 0.04334281788832803\n",
      "-----------EPOCH-----------    ----->  3447\n",
      "Train Loss: 0.043342279767649323\n",
      "-----------EPOCH-----------    ----->  3448\n",
      "Train Loss: 0.04334174149540095\n",
      "-----------EPOCH-----------    ----->  3449\n",
      "Train Loss: 0.04334120394558914\n",
      "-----------EPOCH-----------    ----->  3450\n",
      "Train Loss: 0.04334066640707508\n",
      "-----------EPOCH-----------    ----->  3451\n",
      "Train Loss: 0.04334012818342582\n",
      "-----------EPOCH-----------    ----->  3452\n",
      "Train Loss: 0.04333958960580605\n",
      "-----------EPOCH-----------    ----->  3453\n",
      "Train Loss: 0.043339051000074146\n",
      "-----------EPOCH-----------    ----->  3454\n",
      "Train Loss: 0.04333851368811222\n",
      "-----------EPOCH-----------    ----->  3455\n",
      "Train Loss: 0.04333797627649134\n",
      "-----------EPOCH-----------    ----->  3456\n",
      "Train Loss: 0.04333743772363885\n",
      "-----------EPOCH-----------    ----->  3457\n",
      "Train Loss: 0.043336899247197136\n",
      "-----------EPOCH-----------    ----->  3458\n",
      "Train Loss: 0.04333636066107051\n",
      "-----------EPOCH-----------    ----->  3459\n",
      "Train Loss: 0.04333582204739222\n",
      "-----------EPOCH-----------    ----->  3460\n",
      "Train Loss: 0.043335283709392346\n",
      "-----------EPOCH-----------    ----->  3461\n",
      "Train Loss: 0.0433347439998038\n",
      "-----------EPOCH-----------    ----->  3462\n",
      "Train Loss: 0.0433342038918518\n",
      "-----------EPOCH-----------    ----->  3463\n",
      "Train Loss: 0.043333663696934754\n",
      "-----------EPOCH-----------    ----->  3464\n",
      "Train Loss: 0.04333312435873432\n",
      "-----------EPOCH-----------    ----->  3465\n",
      "Train Loss: 0.043332586740415485\n",
      "-----------EPOCH-----------    ----->  3466\n",
      "Train Loss: 0.043332048951372916\n",
      "-----------EPOCH-----------    ----->  3467\n",
      "Train Loss: 0.04333151046233998\n",
      "-----------EPOCH-----------    ----->  3468\n",
      "Train Loss: 0.04333097172372537\n",
      "-----------EPOCH-----------    ----->  3469\n",
      "Train Loss: 0.04333043338322376\n",
      "-----------EPOCH-----------    ----->  3470\n",
      "Train Loss: 0.04332989453545035\n",
      "-----------EPOCH-----------    ----->  3471\n",
      "Train Loss: 0.04332935405954909\n",
      "-----------EPOCH-----------    ----->  3472\n",
      "Train Loss: 0.04332881344228957\n",
      "-----------EPOCH-----------    ----->  3473\n",
      "Train Loss: 0.04332827249614938\n",
      "-----------EPOCH-----------    ----->  3474\n",
      "Train Loss: 0.043327731450927214\n",
      "-----------EPOCH-----------    ----->  3475\n",
      "Train Loss: 0.04332719048208045\n",
      "-----------EPOCH-----------    ----->  3476\n",
      "Train Loss: 0.04332664960802685\n",
      "-----------EPOCH-----------    ----->  3477\n",
      "Train Loss: 0.043326108989762115\n",
      "-----------EPOCH-----------    ----->  3478\n",
      "Train Loss: 0.04332556827268139\n",
      "-----------EPOCH-----------    ----->  3479\n",
      "Train Loss: 0.04332502660562834\n",
      "-----------EPOCH-----------    ----->  3480\n",
      "Train Loss: 0.043324485116737366\n",
      "-----------EPOCH-----------    ----->  3481\n",
      "Train Loss: 0.04332394294309945\n",
      "-----------EPOCH-----------    ----->  3482\n",
      "Train Loss: 0.0433234008152802\n",
      "-----------EPOCH-----------    ----->  3483\n",
      "Train Loss: 0.043322857994172556\n",
      "-----------EPOCH-----------    ----->  3484\n",
      "Train Loss: 0.043322314780235835\n",
      "-----------EPOCH-----------    ----->  3485\n",
      "Train Loss: 0.04332177131618798\n",
      "-----------EPOCH-----------    ----->  3486\n",
      "Train Loss: 0.04332122760251563\n",
      "-----------EPOCH-----------    ----->  3487\n",
      "Train Loss: 0.043320683431448605\n",
      "-----------EPOCH-----------    ----->  3488\n",
      "Train Loss: 0.04332014080722726\n",
      "-----------EPOCH-----------    ----->  3489\n",
      "Train Loss: 0.043319597757576156\n",
      "-----------EPOCH-----------    ----->  3490\n",
      "Train Loss: 0.04331905432879608\n",
      "-----------EPOCH-----------    ----->  3491\n",
      "Train Loss: 0.043318510774566055\n",
      "-----------EPOCH-----------    ----->  3492\n",
      "Train Loss: 0.043317966966978344\n",
      "-----------EPOCH-----------    ----->  3493\n",
      "Train Loss: 0.04331742166817249\n",
      "-----------EPOCH-----------    ----->  3494\n",
      "Train Loss: 0.043316876168078604\n",
      "-----------EPOCH-----------    ----->  3495\n",
      "Train Loss: 0.04331632995256435\n",
      "-----------EPOCH-----------    ----->  3496\n",
      "Train Loss: 0.04331578357009346\n",
      "-----------EPOCH-----------    ----->  3497\n",
      "Train Loss: 0.04331523775241148\n",
      "-----------EPOCH-----------    ----->  3498\n",
      "Train Loss: 0.04331469199931566\n",
      "-----------EPOCH-----------    ----->  3499\n",
      "Train Loss: 0.043314146688951255\n",
      "-----------EPOCH-----------    ----->  3500\n",
      "Train Loss: 0.04331360175433302\n",
      "-----------EPOCH-----------    ----->  3501\n",
      "Train Loss: 0.04331305699440757\n",
      "-----------EPOCH-----------    ----->  3502\n",
      "Train Loss: 0.04331251204929729\n",
      "-----------EPOCH-----------    ----->  3503\n",
      "Train Loss: 0.04331196754526313\n",
      "-----------EPOCH-----------    ----->  3504\n",
      "Train Loss: 0.04331142262344858\n",
      "-----------EPOCH-----------    ----->  3505\n",
      "Train Loss: 0.04331087691301955\n",
      "-----------EPOCH-----------    ----->  3506\n",
      "Train Loss: 0.043310330168574\n",
      "-----------EPOCH-----------    ----->  3507\n",
      "Train Loss: 0.04330978459722381\n",
      "-----------EPOCH-----------    ----->  3508\n",
      "Train Loss: 0.04330923849694721\n",
      "-----------EPOCH-----------    ----->  3509\n",
      "Train Loss: 0.04330869213570481\n",
      "-----------EPOCH-----------    ----->  3510\n",
      "Train Loss: 0.04330814533252297\n",
      "-----------EPOCH-----------    ----->  3511\n",
      "Train Loss: 0.04330759864691675\n",
      "-----------EPOCH-----------    ----->  3512\n",
      "Train Loss: 0.043307052193655146\n",
      "-----------EPOCH-----------    ----->  3513\n",
      "Train Loss: 0.04330650561447741\n",
      "-----------EPOCH-----------    ----->  3514\n",
      "Train Loss: 0.04330595900070757\n",
      "-----------EPOCH-----------    ----->  3515\n",
      "Train Loss: 0.04330541226832336\n",
      "-----------EPOCH-----------    ----->  3516\n",
      "Train Loss: 0.043304864983394586\n",
      "-----------EPOCH-----------    ----->  3517\n",
      "Train Loss: 0.04330431882849191\n",
      "-----------EPOCH-----------    ----->  3518\n",
      "Train Loss: 0.0433037736839788\n",
      "-----------EPOCH-----------    ----->  3519\n",
      "Train Loss: 0.04330322740877386\n",
      "-----------EPOCH-----------    ----->  3520\n",
      "Train Loss: 0.0433026818180903\n",
      "-----------EPOCH-----------    ----->  3521\n",
      "Train Loss: 0.04330213600796314\n",
      "-----------EPOCH-----------    ----->  3522\n",
      "Train Loss: 0.04330159076086351\n",
      "-----------EPOCH-----------    ----->  3523\n",
      "Train Loss: 0.04330104531550566\n",
      "-----------EPOCH-----------    ----->  3524\n",
      "Train Loss: 0.04330049997951055\n",
      "-----------EPOCH-----------    ----->  3525\n",
      "Train Loss: 0.043299954660618145\n",
      "-----------EPOCH-----------    ----->  3526\n",
      "Train Loss: 0.043299409833249376\n",
      "-----------EPOCH-----------    ----->  3527\n",
      "Train Loss: 0.04329886574149686\n",
      "-----------EPOCH-----------    ----->  3528\n",
      "Train Loss: 0.04329832192387541\n",
      "-----------EPOCH-----------    ----->  3529\n",
      "Train Loss: 0.043297778939524606\n",
      "-----------EPOCH-----------    ----->  3530\n",
      "Train Loss: 0.04329723689496537\n",
      "-----------EPOCH-----------    ----->  3531\n",
      "Train Loss: 0.04329669488185311\n",
      "-----------EPOCH-----------    ----->  3532\n",
      "Train Loss: 0.043296153193562954\n",
      "-----------EPOCH-----------    ----->  3533\n",
      "Train Loss: 0.04329560964962338\n",
      "-----------EPOCH-----------    ----->  3534\n",
      "Train Loss: 0.04329506657125144\n",
      "-----------EPOCH-----------    ----->  3535\n",
      "Train Loss: 0.043294524172646044\n",
      "-----------EPOCH-----------    ----->  3536\n",
      "Train Loss: 0.04329398180164975\n",
      "-----------EPOCH-----------    ----->  3537\n",
      "Train Loss: 0.0432934396346051\n",
      "-----------EPOCH-----------    ----->  3538\n",
      "Train Loss: 0.043292897314855465\n",
      "-----------EPOCH-----------    ----->  3539\n",
      "Train Loss: 0.04329235492566299\n",
      "-----------EPOCH-----------    ----->  3540\n",
      "Train Loss: 0.04329181355086083\n",
      "-----------EPOCH-----------    ----->  3541\n",
      "Train Loss: 0.0432912721835309\n",
      "-----------EPOCH-----------    ----->  3542\n",
      "Train Loss: 0.04329073026348383\n",
      "-----------EPOCH-----------    ----->  3543\n",
      "Train Loss: 0.04329018897442846\n",
      "-----------EPOCH-----------    ----->  3544\n",
      "Train Loss: 0.043289648170929534\n",
      "-----------EPOCH-----------    ----->  3545\n",
      "Train Loss: 0.04328910772921691\n",
      "-----------EPOCH-----------    ----->  3546\n",
      "Train Loss: 0.04328856808465579\n",
      "-----------EPOCH-----------    ----->  3547\n",
      "Train Loss: 0.04328802888585732\n",
      "-----------EPOCH-----------    ----->  3548\n",
      "Train Loss: 0.04328748964359313\n",
      "-----------EPOCH-----------    ----->  3549\n",
      "Train Loss: 0.04328695115979465\n",
      "-----------EPOCH-----------    ----->  3550\n",
      "Train Loss: 0.04328641371851854\n",
      "-----------EPOCH-----------    ----->  3551\n",
      "Train Loss: 0.04328587516964228\n",
      "-----------EPOCH-----------    ----->  3552\n",
      "Train Loss: 0.043285335509467504\n",
      "-----------EPOCH-----------    ----->  3553\n",
      "Train Loss: 0.043284795582705676\n",
      "-----------EPOCH-----------    ----->  3554\n",
      "Train Loss: 0.04328425622676055\n",
      "-----------EPOCH-----------    ----->  3555\n",
      "Train Loss: 0.043283719352381705\n",
      "-----------EPOCH-----------    ----->  3556\n",
      "Train Loss: 0.04328318478943924\n",
      "-----------EPOCH-----------    ----->  3557\n",
      "Train Loss: 0.043282650418731874\n",
      "-----------EPOCH-----------    ----->  3558\n",
      "Train Loss: 0.04328211616802915\n",
      "-----------EPOCH-----------    ----->  3559\n",
      "Train Loss: 0.04328158131250965\n",
      "-----------EPOCH-----------    ----->  3560\n",
      "Train Loss: 0.04328104683470004\n",
      "-----------EPOCH-----------    ----->  3561\n",
      "Train Loss: 0.04328051282580582\n",
      "-----------EPOCH-----------    ----->  3562\n",
      "Train Loss: 0.04327997901319013\n",
      "-----------EPOCH-----------    ----->  3563\n",
      "Train Loss: 0.043279445735126446\n",
      "-----------EPOCH-----------    ----->  3564\n",
      "Train Loss: 0.04327891222405408\n",
      "-----------EPOCH-----------    ----->  3565\n",
      "Train Loss: 0.043278380021624256\n",
      "-----------EPOCH-----------    ----->  3566\n",
      "Train Loss: 0.04327784745232463\n",
      "-----------EPOCH-----------    ----->  3567\n",
      "Train Loss: 0.043277314392008694\n",
      "-----------EPOCH-----------    ----->  3568\n",
      "Train Loss: 0.04327678067843694\n",
      "-----------EPOCH-----------    ----->  3569\n",
      "Train Loss: 0.043276246727702\n",
      "-----------EPOCH-----------    ----->  3570\n",
      "Train Loss: 0.04327571139197995\n",
      "-----------EPOCH-----------    ----->  3571\n",
      "Train Loss: 0.04327517651914637\n",
      "-----------EPOCH-----------    ----->  3572\n",
      "Train Loss: 0.043274641795878865\n",
      "-----------EPOCH-----------    ----->  3573\n",
      "Train Loss: 0.04327410767680047\n",
      "-----------EPOCH-----------    ----->  3574\n",
      "Train Loss: 0.04327357386100495\n",
      "-----------EPOCH-----------    ----->  3575\n",
      "Train Loss: 0.04327303902345571\n",
      "-----------EPOCH-----------    ----->  3576\n",
      "Train Loss: 0.043272504503567594\n",
      "-----------EPOCH-----------    ----->  3577\n",
      "Train Loss: 0.04327196948160448\n",
      "-----------EPOCH-----------    ----->  3578\n",
      "Train Loss: 0.04327143489910417\n",
      "-----------EPOCH-----------    ----->  3579\n",
      "Train Loss: 0.04327090123434807\n",
      "-----------EPOCH-----------    ----->  3580\n",
      "Train Loss: 0.04327036769886473\n",
      "-----------EPOCH-----------    ----->  3581\n",
      "Train Loss: 0.043269835186120494\n",
      "-----------EPOCH-----------    ----->  3582\n",
      "Train Loss: 0.043269303031364816\n",
      "-----------EPOCH-----------    ----->  3583\n",
      "Train Loss: 0.04326877134122264\n",
      "-----------EPOCH-----------    ----->  3584\n",
      "Train Loss: 0.04326823869542808\n",
      "-----------EPOCH-----------    ----->  3585\n",
      "Train Loss: 0.04326770610437483\n",
      "-----------EPOCH-----------    ----->  3586\n",
      "Train Loss: 0.043267174484777904\n",
      "-----------EPOCH-----------    ----->  3587\n",
      "Train Loss: 0.04326664325351789\n",
      "-----------EPOCH-----------    ----->  3588\n",
      "Train Loss: 0.043266111855701436\n",
      "-----------EPOCH-----------    ----->  3589\n",
      "Train Loss: 0.043265581027804256\n",
      "-----------EPOCH-----------    ----->  3590\n",
      "Train Loss: 0.04326505135884078\n",
      "-----------EPOCH-----------    ----->  3591\n",
      "Train Loss: 0.043264521609423075\n",
      "-----------EPOCH-----------    ----->  3592\n",
      "Train Loss: 0.04326399124054347\n",
      "-----------EPOCH-----------    ----->  3593\n",
      "Train Loss: 0.04326346103695868\n",
      "-----------EPOCH-----------    ----->  3594\n",
      "Train Loss: 0.04326293010035888\n",
      "-----------EPOCH-----------    ----->  3595\n",
      "Train Loss: 0.043262398893146106\n",
      "-----------EPOCH-----------    ----->  3596\n",
      "Train Loss: 0.043261867177392124\n",
      "-----------EPOCH-----------    ----->  3597\n",
      "Train Loss: 0.04326133472227382\n",
      "-----------EPOCH-----------    ----->  3598\n",
      "Train Loss: 0.043260803003615296\n",
      "-----------EPOCH-----------    ----->  3599\n",
      "Train Loss: 0.04326027328386292\n",
      "-----------EPOCH-----------    ----->  3600\n",
      "Train Loss: 0.04325974374176589\n",
      "-----------EPOCH-----------    ----->  3601\n",
      "Train Loss: 0.04325921512594734\n",
      "-----------EPOCH-----------    ----->  3602\n",
      "Train Loss: 0.04325868688094143\n",
      "-----------EPOCH-----------    ----->  3603\n",
      "Train Loss: 0.043258158504659305\n",
      "-----------EPOCH-----------    ----->  3604\n",
      "Train Loss: 0.04325762999798683\n",
      "-----------EPOCH-----------    ----->  3605\n",
      "Train Loss: 0.043257101424075205\n",
      "-----------EPOCH-----------    ----->  3606\n",
      "Train Loss: 0.04325657335909644\n",
      "-----------EPOCH-----------    ----->  3607\n",
      "Train Loss: 0.04325604504184529\n",
      "-----------EPOCH-----------    ----->  3608\n",
      "Train Loss: 0.043255516966858115\n",
      "-----------EPOCH-----------    ----->  3609\n",
      "Train Loss: 0.04325498776562707\n",
      "-----------EPOCH-----------    ----->  3610\n",
      "Train Loss: 0.04325445805293939\n",
      "-----------EPOCH-----------    ----->  3611\n",
      "Train Loss: 0.0432539287060417\n",
      "-----------EPOCH-----------    ----->  3612\n",
      "Train Loss: 0.043253400759975476\n",
      "-----------EPOCH-----------    ----->  3613\n",
      "Train Loss: 0.04325287247623245\n",
      "-----------EPOCH-----------    ----->  3614\n",
      "Train Loss: 0.04325234208913508\n",
      "-----------EPOCH-----------    ----->  3615\n",
      "Train Loss: 0.043251810925804005\n",
      "-----------EPOCH-----------    ----->  3616\n",
      "Train Loss: 0.04325127904911284\n",
      "-----------EPOCH-----------    ----->  3617\n",
      "Train Loss: 0.043250746070420835\n",
      "-----------EPOCH-----------    ----->  3618\n",
      "Train Loss: 0.04325021332724627\n",
      "-----------EPOCH-----------    ----->  3619\n",
      "Train Loss: 0.0432496817015719\n",
      "-----------EPOCH-----------    ----->  3620\n",
      "Train Loss: 0.043249151096440404\n",
      "-----------EPOCH-----------    ----->  3621\n",
      "Train Loss: 0.0432486199051009\n",
      "-----------EPOCH-----------    ----->  3622\n",
      "Train Loss: 0.043248089136666584\n",
      "-----------EPOCH-----------    ----->  3623\n",
      "Train Loss: 0.043247559135001806\n",
      "-----------EPOCH-----------    ----->  3624\n",
      "Train Loss: 0.04324702932072744\n",
      "-----------EPOCH-----------    ----->  3625\n",
      "Train Loss: 0.043246498937432876\n",
      "-----------EPOCH-----------    ----->  3626\n",
      "Train Loss: 0.04324596914253639\n",
      "-----------EPOCH-----------    ----->  3627\n",
      "Train Loss: 0.043245440158881536\n",
      "-----------EPOCH-----------    ----->  3628\n",
      "Train Loss: 0.043244910945362224\n",
      "-----------EPOCH-----------    ----->  3629\n",
      "Train Loss: 0.043244381928580856\n",
      "-----------EPOCH-----------    ----->  3630\n",
      "Train Loss: 0.043243853657634654\n",
      "-----------EPOCH-----------    ----->  3631\n",
      "Train Loss: 0.043243325805096766\n",
      "-----------EPOCH-----------    ----->  3632\n",
      "Train Loss: 0.04324279953849144\n",
      "-----------EPOCH-----------    ----->  3633\n",
      "Train Loss: 0.04324227394104866\n",
      "-----------EPOCH-----------    ----->  3634\n",
      "Train Loss: 0.043241747721505144\n",
      "-----------EPOCH-----------    ----->  3635\n",
      "Train Loss: 0.04324122202989058\n",
      "-----------EPOCH-----------    ----->  3636\n",
      "Train Loss: 0.04324069598568705\n",
      "-----------EPOCH-----------    ----->  3637\n",
      "Train Loss: 0.04324017027325269\n",
      "-----------EPOCH-----------    ----->  3638\n",
      "Train Loss: 0.043239644910886554\n",
      "-----------EPOCH-----------    ----->  3639\n",
      "Train Loss: 0.04323911925230326\n",
      "-----------EPOCH-----------    ----->  3640\n",
      "Train Loss: 0.043238592305167925\n",
      "-----------EPOCH-----------    ----->  3641\n",
      "Train Loss: 0.043238066410103124\n",
      "-----------EPOCH-----------    ----->  3642\n",
      "Train Loss: 0.04323754113533517\n",
      "-----------EPOCH-----------    ----->  3643\n",
      "Train Loss: 0.04323701727799582\n",
      "-----------EPOCH-----------    ----->  3644\n",
      "Train Loss: 0.043236493181648614\n",
      "-----------EPOCH-----------    ----->  3645\n",
      "Train Loss: 0.043235969012685734\n",
      "-----------EPOCH-----------    ----->  3646\n",
      "Train Loss: 0.04323544557619743\n",
      "-----------EPOCH-----------    ----->  3647\n",
      "Train Loss: 0.04323492283501684\n",
      "-----------EPOCH-----------    ----->  3648\n",
      "Train Loss: 0.04323440197243797\n",
      "-----------EPOCH-----------    ----->  3649\n",
      "Train Loss: 0.043233881353585205\n",
      "-----------EPOCH-----------    ----->  3650\n",
      "Train Loss: 0.04323336037034029\n",
      "-----------EPOCH-----------    ----->  3651\n",
      "Train Loss: 0.043232840583513156\n",
      "-----------EPOCH-----------    ----->  3652\n",
      "Train Loss: 0.04323232148491073\n",
      "-----------EPOCH-----------    ----->  3653\n",
      "Train Loss: 0.043231801885602016\n",
      "-----------EPOCH-----------    ----->  3654\n",
      "Train Loss: 0.043231282350502574\n",
      "-----------EPOCH-----------    ----->  3655\n",
      "Train Loss: 0.04323076304351627\n",
      "-----------EPOCH-----------    ----->  3656\n",
      "Train Loss: 0.04323024311611125\n",
      "-----------EPOCH-----------    ----->  3657\n",
      "Train Loss: 0.04322972307754453\n",
      "-----------EPOCH-----------    ----->  3658\n",
      "Train Loss: 0.04322920349491262\n",
      "-----------EPOCH-----------    ----->  3659\n",
      "Train Loss: 0.04322868400646025\n",
      "-----------EPOCH-----------    ----->  3660\n",
      "Train Loss: 0.043228164791339896\n",
      "-----------EPOCH-----------    ----->  3661\n",
      "Train Loss: 0.043227645845644126\n",
      "-----------EPOCH-----------    ----->  3662\n",
      "Train Loss: 0.04322712684116561\n",
      "-----------EPOCH-----------    ----->  3663\n",
      "Train Loss: 0.043226606871168444\n",
      "-----------EPOCH-----------    ----->  3664\n",
      "Train Loss: 0.04322608751510502\n",
      "-----------EPOCH-----------    ----->  3665\n",
      "Train Loss: 0.04322556853580832\n",
      "-----------EPOCH-----------    ----->  3666\n",
      "Train Loss: 0.04322505022115389\n",
      "-----------EPOCH-----------    ----->  3667\n",
      "Train Loss: 0.04322453224730099\n",
      "-----------EPOCH-----------    ----->  3668\n",
      "Train Loss: 0.043224013434463915\n",
      "-----------EPOCH-----------    ----->  3669\n",
      "Train Loss: 0.04322349310695841\n",
      "-----------EPOCH-----------    ----->  3670\n",
      "Train Loss: 0.04322297383680734\n",
      "-----------EPOCH-----------    ----->  3671\n",
      "Train Loss: 0.043222454856657044\n",
      "-----------EPOCH-----------    ----->  3672\n",
      "Train Loss: 0.04322193615631483\n",
      "-----------EPOCH-----------    ----->  3673\n",
      "Train Loss: 0.043221414636596754\n",
      "-----------EPOCH-----------    ----->  3674\n",
      "Train Loss: 0.04322089317657811\n",
      "-----------EPOCH-----------    ----->  3675\n",
      "Train Loss: 0.04322037284202389\n",
      "-----------EPOCH-----------    ----->  3676\n",
      "Train Loss: 0.04321985400492335\n",
      "-----------EPOCH-----------    ----->  3677\n",
      "Train Loss: 0.04321933587996254\n",
      "-----------EPOCH-----------    ----->  3678\n",
      "Train Loss: 0.04321881916456899\n",
      "-----------EPOCH-----------    ----->  3679\n",
      "Train Loss: 0.043218303356891766\n",
      "-----------EPOCH-----------    ----->  3680\n",
      "Train Loss: 0.043217788266692904\n",
      "-----------EPOCH-----------    ----->  3681\n",
      "Train Loss: 0.04321727297123836\n",
      "-----------EPOCH-----------    ----->  3682\n",
      "Train Loss: 0.04321675823405763\n",
      "-----------EPOCH-----------    ----->  3683\n",
      "Train Loss: 0.04321624341381225\n",
      "-----------EPOCH-----------    ----->  3684\n",
      "Train Loss: 0.04321572895490469\n",
      "-----------EPOCH-----------    ----->  3685\n",
      "Train Loss: 0.04321521450846711\n",
      "-----------EPOCH-----------    ----->  3686\n",
      "Train Loss: 0.043214701006852145\n",
      "-----------EPOCH-----------    ----->  3687\n",
      "Train Loss: 0.04321418908158276\n",
      "-----------EPOCH-----------    ----->  3688\n",
      "Train Loss: 0.04321367755253445\n",
      "-----------EPOCH-----------    ----->  3689\n",
      "Train Loss: 0.04321316577927424\n",
      "-----------EPOCH-----------    ----->  3690\n",
      "Train Loss: 0.04321265417569989\n",
      "-----------EPOCH-----------    ----->  3691\n",
      "Train Loss: 0.043212142297529905\n",
      "-----------EPOCH-----------    ----->  3692\n",
      "Train Loss: 0.04321163070988717\n",
      "-----------EPOCH-----------    ----->  3693\n",
      "Train Loss: 0.04321111893013138\n",
      "-----------EPOCH-----------    ----->  3694\n",
      "Train Loss: 0.04321060723739518\n",
      "-----------EPOCH-----------    ----->  3695\n",
      "Train Loss: 0.043210095922001215\n",
      "-----------EPOCH-----------    ----->  3696\n",
      "Train Loss: 0.04320958493828666\n",
      "-----------EPOCH-----------    ----->  3697\n",
      "Train Loss: 0.04320907556083262\n",
      "-----------EPOCH-----------    ----->  3698\n",
      "Train Loss: 0.043208568702058525\n",
      "-----------EPOCH-----------    ----->  3699\n",
      "Train Loss: 0.04320806093542344\n",
      "-----------EPOCH-----------    ----->  3700\n",
      "Train Loss: 0.04320755268163842\n",
      "-----------EPOCH-----------    ----->  3701\n",
      "Train Loss: 0.04320704512225221\n",
      "-----------EPOCH-----------    ----->  3702\n",
      "Train Loss: 0.04320653786661139\n",
      "-----------EPOCH-----------    ----->  3703\n",
      "Train Loss: 0.04320603118103043\n",
      "-----------EPOCH-----------    ----->  3704\n",
      "Train Loss: 0.04320552555731445\n",
      "-----------EPOCH-----------    ----->  3705\n",
      "Train Loss: 0.043205020772271834\n",
      "-----------EPOCH-----------    ----->  3706\n",
      "Train Loss: 0.0432045164020866\n",
      "-----------EPOCH-----------    ----->  3707\n",
      "Train Loss: 0.04320401263111447\n",
      "-----------EPOCH-----------    ----->  3708\n",
      "Train Loss: 0.04320351012433635\n",
      "-----------EPOCH-----------    ----->  3709\n",
      "Train Loss: 0.04320300740585083\n",
      "-----------EPOCH-----------    ----->  3710\n",
      "Train Loss: 0.0432025044385188\n",
      "-----------EPOCH-----------    ----->  3711\n",
      "Train Loss: 0.043202001780038544\n",
      "-----------EPOCH-----------    ----->  3712\n",
      "Train Loss: 0.043201499406487515\n",
      "-----------EPOCH-----------    ----->  3713\n",
      "Train Loss: 0.04320099671959008\n",
      "-----------EPOCH-----------    ----->  3714\n",
      "Train Loss: 0.0432004918821389\n",
      "-----------EPOCH-----------    ----->  3715\n",
      "Train Loss: 0.04319998660242257\n",
      "-----------EPOCH-----------    ----->  3716\n",
      "Train Loss: 0.04319948123959222\n",
      "-----------EPOCH-----------    ----->  3717\n",
      "Train Loss: 0.04319897616184188\n",
      "-----------EPOCH-----------    ----->  3718\n",
      "Train Loss: 0.04319847052200427\n",
      "-----------EPOCH-----------    ----->  3719\n",
      "Train Loss: 0.043197963692022584\n",
      "-----------EPOCH-----------    ----->  3720\n",
      "Train Loss: 0.043197457274093284\n",
      "-----------EPOCH-----------    ----->  3721\n",
      "Train Loss: 0.04319695044974203\n",
      "-----------EPOCH-----------    ----->  3722\n",
      "Train Loss: 0.04319644202132657\n",
      "-----------EPOCH-----------    ----->  3723\n",
      "Train Loss: 0.043195933014523236\n",
      "-----------EPOCH-----------    ----->  3724\n",
      "Train Loss: 0.04319542372051885\n",
      "-----------EPOCH-----------    ----->  3725\n",
      "Train Loss: 0.043194914242445835\n",
      "-----------EPOCH-----------    ----->  3726\n",
      "Train Loss: 0.0431944043388749\n",
      "-----------EPOCH-----------    ----->  3727\n",
      "Train Loss: 0.043193892055048574\n",
      "-----------EPOCH-----------    ----->  3728\n",
      "Train Loss: 0.04319338021880821\n",
      "-----------EPOCH-----------    ----->  3729\n",
      "Train Loss: 0.04319286823658737\n",
      "-----------EPOCH-----------    ----->  3730\n",
      "Train Loss: 0.04319235634397266\n",
      "-----------EPOCH-----------    ----->  3731\n",
      "Train Loss: 0.04319184510576107\n",
      "-----------EPOCH-----------    ----->  3732\n",
      "Train Loss: 0.04319133428608965\n",
      "-----------EPOCH-----------    ----->  3733\n",
      "Train Loss: 0.04319082403882716\n",
      "-----------EPOCH-----------    ----->  3734\n",
      "Train Loss: 0.04319031372944749\n",
      "-----------EPOCH-----------    ----->  3735\n",
      "Train Loss: 0.043189803530113736\n",
      "-----------EPOCH-----------    ----->  3736\n",
      "Train Loss: 0.043189293817494666\n",
      "-----------EPOCH-----------    ----->  3737\n",
      "Train Loss: 0.04318878403915478\n",
      "-----------EPOCH-----------    ----->  3738\n",
      "Train Loss: 0.04318827484905594\n",
      "-----------EPOCH-----------    ----->  3739\n",
      "Train Loss: 0.04318776571238874\n",
      "-----------EPOCH-----------    ----->  3740\n",
      "Train Loss: 0.043187257248855894\n",
      "-----------EPOCH-----------    ----->  3741\n",
      "Train Loss: 0.04318674775394048\n",
      "-----------EPOCH-----------    ----->  3742\n",
      "Train Loss: 0.04318623827764036\n",
      "-----------EPOCH-----------    ----->  3743\n",
      "Train Loss: 0.04318573247817222\n",
      "-----------EPOCH-----------    ----->  3744\n",
      "Train Loss: 0.04318522655464523\n",
      "-----------EPOCH-----------    ----->  3745\n",
      "Train Loss: 0.04318472001918137\n",
      "-----------EPOCH-----------    ----->  3746\n",
      "Train Loss: 0.04318421498456816\n",
      "-----------EPOCH-----------    ----->  3747\n",
      "Train Loss: 0.043183710546527025\n",
      "-----------EPOCH-----------    ----->  3748\n",
      "Train Loss: 0.04318320594340674\n",
      "-----------EPOCH-----------    ----->  3749\n",
      "Train Loss: 0.04318270110673836\n",
      "-----------EPOCH-----------    ----->  3750\n",
      "Train Loss: 0.043182197403989625\n",
      "-----------EPOCH-----------    ----->  3751\n",
      "Train Loss: 0.0431816943342454\n",
      "-----------EPOCH-----------    ----->  3752\n",
      "Train Loss: 0.04318119122999472\n",
      "-----------EPOCH-----------    ----->  3753\n",
      "Train Loss: 0.04318068892941669\n",
      "-----------EPOCH-----------    ----->  3754\n",
      "Train Loss: 0.043180187487243074\n",
      "-----------EPOCH-----------    ----->  3755\n",
      "Train Loss: 0.04317968593244676\n",
      "-----------EPOCH-----------    ----->  3756\n",
      "Train Loss: 0.043179184901523414\n",
      "-----------EPOCH-----------    ----->  3757\n",
      "Train Loss: 0.043178684420569026\n",
      "-----------EPOCH-----------    ----->  3758\n",
      "Train Loss: 0.0431781837480476\n",
      "-----------EPOCH-----------    ----->  3759\n",
      "Train Loss: 0.04317768307981902\n",
      "-----------EPOCH-----------    ----->  3760\n",
      "Train Loss: 0.0431771821991242\n",
      "-----------EPOCH-----------    ----->  3761\n",
      "Train Loss: 0.0431766809945561\n",
      "-----------EPOCH-----------    ----->  3762\n",
      "Train Loss: 0.04317617997690359\n",
      "-----------EPOCH-----------    ----->  3763\n",
      "Train Loss: 0.043175680056324384\n",
      "-----------EPOCH-----------    ----->  3764\n",
      "Train Loss: 0.04317518018977936\n",
      "-----------EPOCH-----------    ----->  3765\n",
      "Train Loss: 0.043174680001628093\n",
      "-----------EPOCH-----------    ----->  3766\n",
      "Train Loss: 0.04317417987130619\n",
      "-----------EPOCH-----------    ----->  3767\n",
      "Train Loss: 0.0431736795595189\n",
      "-----------EPOCH-----------    ----->  3768\n",
      "Train Loss: 0.0431731795744911\n",
      "-----------EPOCH-----------    ----->  3769\n",
      "Train Loss: 0.043172680750224596\n",
      "-----------EPOCH-----------    ----->  3770\n",
      "Train Loss: 0.043172181879113224\n",
      "-----------EPOCH-----------    ----->  3771\n",
      "Train Loss: 0.043171682816176005\n",
      "-----------EPOCH-----------    ----->  3772\n",
      "Train Loss: 0.043171184864459845\n",
      "-----------EPOCH-----------    ----->  3773\n",
      "Train Loss: 0.043170688414036734\n",
      "-----------EPOCH-----------    ----->  3774\n",
      "Train Loss: 0.043170192130520084\n",
      "-----------EPOCH-----------    ----->  3775\n",
      "Train Loss: 0.04316969557217038\n",
      "-----------EPOCH-----------    ----->  3776\n",
      "Train Loss: 0.04316919891711818\n",
      "-----------EPOCH-----------    ----->  3777\n",
      "Train Loss: 0.04316870311381542\n",
      "-----------EPOCH-----------    ----->  3778\n",
      "Train Loss: 0.043168207351155494\n",
      "-----------EPOCH-----------    ----->  3779\n",
      "Train Loss: 0.0431677123868876\n",
      "-----------EPOCH-----------    ----->  3780\n",
      "Train Loss: 0.04316721752601076\n",
      "-----------EPOCH-----------    ----->  3781\n",
      "Train Loss: 0.04316672304214092\n",
      "-----------EPOCH-----------    ----->  3782\n",
      "Train Loss: 0.043166229391825635\n",
      "-----------EPOCH-----------    ----->  3783\n",
      "Train Loss: 0.04316573621788858\n",
      "-----------EPOCH-----------    ----->  3784\n",
      "Train Loss: 0.04316524284896619\n",
      "-----------EPOCH-----------    ----->  3785\n",
      "Train Loss: 0.0431647502246844\n",
      "-----------EPOCH-----------    ----->  3786\n",
      "Train Loss: 0.04316425839311283\n",
      "-----------EPOCH-----------    ----->  3787\n",
      "Train Loss: 0.0431637666882868\n",
      "-----------EPOCH-----------    ----->  3788\n",
      "Train Loss: 0.043163274529069165\n",
      "-----------EPOCH-----------    ----->  3789\n",
      "Train Loss: 0.04316278183496333\n",
      "-----------EPOCH-----------    ----->  3790\n",
      "Train Loss: 0.0431622888238529\n",
      "-----------EPOCH-----------    ----->  3791\n",
      "Train Loss: 0.043161796404389496\n",
      "-----------EPOCH-----------    ----->  3792\n",
      "Train Loss: 0.0431613042725095\n",
      "-----------EPOCH-----------    ----->  3793\n",
      "Train Loss: 0.04316081216304582\n",
      "-----------EPOCH-----------    ----->  3794\n",
      "Train Loss: 0.04316031987147452\n",
      "-----------EPOCH-----------    ----->  3795\n",
      "Train Loss: 0.04315982817879716\n",
      "-----------EPOCH-----------    ----->  3796\n",
      "Train Loss: 0.0431593359641916\n",
      "-----------EPOCH-----------    ----->  3797\n",
      "Train Loss: 0.04315884343740898\n",
      "-----------EPOCH-----------    ----->  3798\n",
      "Train Loss: 0.04315835069147901\n",
      "-----------EPOCH-----------    ----->  3799\n",
      "Train Loss: 0.043157857950248055\n",
      "-----------EPOCH-----------    ----->  3800\n",
      "Train Loss: 0.04315736470207256\n",
      "-----------EPOCH-----------    ----->  3801\n",
      "Train Loss: 0.04315687140610487\n",
      "-----------EPOCH-----------    ----->  3802\n",
      "Train Loss: 0.04315637817286608\n",
      "-----------EPOCH-----------    ----->  3803\n",
      "Train Loss: 0.04315588529653712\n",
      "-----------EPOCH-----------    ----->  3804\n",
      "Train Loss: 0.04315539237781557\n",
      "-----------EPOCH-----------    ----->  3805\n",
      "Train Loss: 0.04315489956289703\n",
      "-----------EPOCH-----------    ----->  3806\n",
      "Train Loss: 0.04315440639783676\n",
      "-----------EPOCH-----------    ----->  3807\n",
      "Train Loss: 0.04315391314865239\n",
      "-----------EPOCH-----------    ----->  3808\n",
      "Train Loss: 0.04315341948592202\n",
      "-----------EPOCH-----------    ----->  3809\n",
      "Train Loss: 0.043152925600532285\n",
      "-----------EPOCH-----------    ----->  3810\n",
      "Train Loss: 0.04315243172977743\n",
      "-----------EPOCH-----------    ----->  3811\n",
      "Train Loss: 0.043151936437728\n",
      "-----------EPOCH-----------    ----->  3812\n",
      "Train Loss: 0.043151442901566146\n",
      "-----------EPOCH-----------    ----->  3813\n",
      "Train Loss: 0.043150950405425034\n",
      "-----------EPOCH-----------    ----->  3814\n",
      "Train Loss: 0.04315045881807863\n",
      "-----------EPOCH-----------    ----->  3815\n",
      "Train Loss: 0.0431499686598786\n",
      "-----------EPOCH-----------    ----->  3816\n",
      "Train Loss: 0.04314947817856121\n",
      "-----------EPOCH-----------    ----->  3817\n",
      "Train Loss: 0.043148988924427714\n",
      "-----------EPOCH-----------    ----->  3818\n",
      "Train Loss: 0.043148501592743464\n",
      "-----------EPOCH-----------    ----->  3819\n",
      "Train Loss: 0.043148015066953926\n",
      "-----------EPOCH-----------    ----->  3820\n",
      "Train Loss: 0.0431475288350414\n",
      "-----------EPOCH-----------    ----->  3821\n",
      "Train Loss: 0.04314704268926679\n",
      "-----------EPOCH-----------    ----->  3822\n",
      "Train Loss: 0.04314655615375878\n",
      "-----------EPOCH-----------    ----->  3823\n",
      "Train Loss: 0.043146072078294254\n",
      "-----------EPOCH-----------    ----->  3824\n",
      "Train Loss: 0.04314558897230569\n",
      "-----------EPOCH-----------    ----->  3825\n",
      "Train Loss: 0.0431451059883837\n",
      "-----------EPOCH-----------    ----->  3826\n",
      "Train Loss: 0.04314462345439525\n",
      "-----------EPOCH-----------    ----->  3827\n",
      "Train Loss: 0.04314414123054443\n",
      "-----------EPOCH-----------    ----->  3828\n",
      "Train Loss: 0.04314365911749053\n",
      "-----------EPOCH-----------    ----->  3829\n",
      "Train Loss: 0.04314317720784055\n",
      "-----------EPOCH-----------    ----->  3830\n",
      "Train Loss: 0.043142695926768525\n",
      "-----------EPOCH-----------    ----->  3831\n",
      "Train Loss: 0.043142214851069526\n",
      "-----------EPOCH-----------    ----->  3832\n",
      "Train Loss: 0.04314173419741917\n",
      "-----------EPOCH-----------    ----->  3833\n",
      "Train Loss: 0.043141253558157316\n",
      "-----------EPOCH-----------    ----->  3834\n",
      "Train Loss: 0.04314077245125672\n",
      "-----------EPOCH-----------    ----->  3835\n",
      "Train Loss: 0.043140291521648125\n",
      "-----------EPOCH-----------    ----->  3836\n",
      "Train Loss: 0.04313981011154033\n",
      "-----------EPOCH-----------    ----->  3837\n",
      "Train Loss: 0.04313932774489121\n",
      "-----------EPOCH-----------    ----->  3838\n",
      "Train Loss: 0.04313884445584609\n",
      "-----------EPOCH-----------    ----->  3839\n",
      "Train Loss: 0.04313836113114931\n",
      "-----------EPOCH-----------    ----->  3840\n",
      "Train Loss: 0.0431378768562988\n",
      "-----------EPOCH-----------    ----->  3841\n",
      "Train Loss: 0.043137392174937055\n",
      "-----------EPOCH-----------    ----->  3842\n",
      "Train Loss: 0.043136907699176844\n",
      "-----------EPOCH-----------    ----->  3843\n",
      "Train Loss: 0.04313642316207835\n",
      "-----------EPOCH-----------    ----->  3844\n",
      "Train Loss: 0.043135938956951295\n",
      "-----------EPOCH-----------    ----->  3845\n",
      "Train Loss: 0.04313545464813053\n",
      "-----------EPOCH-----------    ----->  3846\n",
      "Train Loss: 0.04313497055321399\n",
      "-----------EPOCH-----------    ----->  3847\n",
      "Train Loss: 0.04313448778131918\n",
      "-----------EPOCH-----------    ----->  3848\n",
      "Train Loss: 0.043134005281558245\n",
      "-----------EPOCH-----------    ----->  3849\n",
      "Train Loss: 0.04313352364636269\n",
      "-----------EPOCH-----------    ----->  3850\n",
      "Train Loss: 0.04313304244567402\n",
      "-----------EPOCH-----------    ----->  3851\n",
      "Train Loss: 0.043132561463373735\n",
      "-----------EPOCH-----------    ----->  3852\n",
      "Train Loss: 0.043132080309621006\n",
      "-----------EPOCH-----------    ----->  3853\n",
      "Train Loss: 0.04313159957966599\n",
      "-----------EPOCH-----------    ----->  3854\n",
      "Train Loss: 0.043131118682957575\n",
      "-----------EPOCH-----------    ----->  3855\n",
      "Train Loss: 0.043130637592827106\n",
      "-----------EPOCH-----------    ----->  3856\n",
      "Train Loss: 0.043130156922971154\n",
      "-----------EPOCH-----------    ----->  3857\n",
      "Train Loss: 0.04312967564543895\n",
      "-----------EPOCH-----------    ----->  3858\n",
      "Train Loss: 0.04312919448145977\n",
      "-----------EPOCH-----------    ----->  3859\n",
      "Train Loss: 0.04312871311793824\n",
      "-----------EPOCH-----------    ----->  3860\n",
      "Train Loss: 0.0431282320225381\n",
      "-----------EPOCH-----------    ----->  3861\n",
      "Train Loss: 0.04312774983635381\n",
      "-----------EPOCH-----------    ----->  3862\n",
      "Train Loss: 0.043127268278791875\n",
      "-----------EPOCH-----------    ----->  3863\n",
      "Train Loss: 0.04312678688117092\n",
      "-----------EPOCH-----------    ----->  3864\n",
      "Train Loss: 0.04312630552777449\n",
      "-----------EPOCH-----------    ----->  3865\n",
      "Train Loss: 0.0431258238577654\n",
      "-----------EPOCH-----------    ----->  3866\n",
      "Train Loss: 0.043125343134139224\n",
      "-----------EPOCH-----------    ----->  3867\n",
      "Train Loss: 0.04312486367300311\n",
      "-----------EPOCH-----------    ----->  3868\n",
      "Train Loss: 0.043124384807870696\n",
      "-----------EPOCH-----------    ----->  3869\n",
      "Train Loss: 0.043123906327428414\n",
      "-----------EPOCH-----------    ----->  3870\n",
      "Train Loss: 0.04312342680129492\n",
      "-----------EPOCH-----------    ----->  3871\n",
      "Train Loss: 0.043122945510038986\n",
      "-----------EPOCH-----------    ----->  3872\n",
      "Train Loss: 0.043122464450087175\n",
      "-----------EPOCH-----------    ----->  3873\n",
      "Train Loss: 0.04312198327929298\n",
      "-----------EPOCH-----------    ----->  3874\n",
      "Train Loss: 0.0431215016329021\n",
      "-----------EPOCH-----------    ----->  3875\n",
      "Train Loss: 0.043121019761997365\n",
      "-----------EPOCH-----------    ----->  3876\n",
      "Train Loss: 0.04312053800027734\n",
      "-----------EPOCH-----------    ----->  3877\n",
      "Train Loss: 0.04312005821437661\n",
      "-----------EPOCH-----------    ----->  3878\n",
      "Train Loss: 0.043119578119995755\n",
      "-----------EPOCH-----------    ----->  3879\n",
      "Train Loss: 0.043119097760144824\n",
      "-----------EPOCH-----------    ----->  3880\n",
      "Train Loss: 0.0431186178634733\n",
      "-----------EPOCH-----------    ----->  3881\n",
      "Train Loss: 0.04311813782807458\n",
      "-----------EPOCH-----------    ----->  3882\n",
      "Train Loss: 0.0431176577518132\n",
      "-----------EPOCH-----------    ----->  3883\n",
      "Train Loss: 0.04311717830399487\n",
      "-----------EPOCH-----------    ----->  3884\n",
      "Train Loss: 0.043116697173705934\n",
      "-----------EPOCH-----------    ----->  3885\n",
      "Train Loss: 0.04311621585603823\n",
      "-----------EPOCH-----------    ----->  3886\n",
      "Train Loss: 0.043115733916142554\n",
      "-----------EPOCH-----------    ----->  3887\n",
      "Train Loss: 0.04311525055438422\n",
      "-----------EPOCH-----------    ----->  3888\n",
      "Train Loss: 0.043114767726752976\n",
      "-----------EPOCH-----------    ----->  3889\n",
      "Train Loss: 0.04311428558231733\n",
      "-----------EPOCH-----------    ----->  3890\n",
      "Train Loss: 0.043113802697232306\n",
      "-----------EPOCH-----------    ----->  3891\n",
      "Train Loss: 0.04311331976042006\n",
      "-----------EPOCH-----------    ----->  3892\n",
      "Train Loss: 0.04311283697765446\n",
      "-----------EPOCH-----------    ----->  3893\n",
      "Train Loss: 0.04311235549729882\n",
      "-----------EPOCH-----------    ----->  3894\n",
      "Train Loss: 0.04311187477474107\n",
      "-----------EPOCH-----------    ----->  3895\n",
      "Train Loss: 0.043111395472715384\n",
      "-----------EPOCH-----------    ----->  3896\n",
      "Train Loss: 0.0431109173107747\n",
      "-----------EPOCH-----------    ----->  3897\n",
      "Train Loss: 0.043110439593116744\n",
      "-----------EPOCH-----------    ----->  3898\n",
      "Train Loss: 0.04310996296219357\n",
      "-----------EPOCH-----------    ----->  3899\n",
      "Train Loss: 0.04310948681960738\n",
      "-----------EPOCH-----------    ----->  3900\n",
      "Train Loss: 0.043109009753598215\n",
      "-----------EPOCH-----------    ----->  3901\n",
      "Train Loss: 0.04310853271922086\n",
      "-----------EPOCH-----------    ----->  3902\n",
      "Train Loss: 0.04310805593550139\n",
      "-----------EPOCH-----------    ----->  3903\n",
      "Train Loss: 0.04310757956956682\n",
      "-----------EPOCH-----------    ----->  3904\n",
      "Train Loss: 0.04310710337537751\n",
      "-----------EPOCH-----------    ----->  3905\n",
      "Train Loss: 0.0431066272005091\n",
      "-----------EPOCH-----------    ----->  3906\n",
      "Train Loss: 0.0431061508757003\n",
      "-----------EPOCH-----------    ----->  3907\n",
      "Train Loss: 0.04310567457021416\n",
      "-----------EPOCH-----------    ----->  3908\n",
      "Train Loss: 0.043105198493546854\n",
      "-----------EPOCH-----------    ----->  3909\n",
      "Train Loss: 0.04310472352933167\n",
      "-----------EPOCH-----------    ----->  3910\n",
      "Train Loss: 0.0431042497772056\n",
      "-----------EPOCH-----------    ----->  3911\n",
      "Train Loss: 0.0431037762798069\n",
      "-----------EPOCH-----------    ----->  3912\n",
      "Train Loss: 0.043103301063537235\n",
      "-----------EPOCH-----------    ----->  3913\n",
      "Train Loss: 0.04310282534633436\n",
      "-----------EPOCH-----------    ----->  3914\n",
      "Train Loss: 0.043102350051606515\n",
      "-----------EPOCH-----------    ----->  3915\n",
      "Train Loss: 0.043101875269279034\n",
      "-----------EPOCH-----------    ----->  3916\n",
      "Train Loss: 0.04310140098423419\n",
      "-----------EPOCH-----------    ----->  3917\n",
      "Train Loss: 0.0431009269663394\n",
      "-----------EPOCH-----------    ----->  3918\n",
      "Train Loss: 0.04310045385948422\n",
      "-----------EPOCH-----------    ----->  3919\n",
      "Train Loss: 0.043099980883182384\n",
      "-----------EPOCH-----------    ----->  3920\n",
      "Train Loss: 0.04309950784999574\n",
      "-----------EPOCH-----------    ----->  3921\n",
      "Train Loss: 0.043099034268505504\n",
      "-----------EPOCH-----------    ----->  3922\n",
      "Train Loss: 0.04309856066149833\n",
      "-----------EPOCH-----------    ----->  3923\n",
      "Train Loss: 0.043098086568388115\n",
      "-----------EPOCH-----------    ----->  3924\n",
      "Train Loss: 0.04309761144167631\n",
      "-----------EPOCH-----------    ----->  3925\n",
      "Train Loss: 0.04309713660208957\n",
      "-----------EPOCH-----------    ----->  3926\n",
      "Train Loss: 0.04309666206677242\n",
      "-----------EPOCH-----------    ----->  3927\n",
      "Train Loss: 0.043096186867821906\n",
      "-----------EPOCH-----------    ----->  3928\n",
      "Train Loss: 0.04309571219951812\n",
      "-----------EPOCH-----------    ----->  3929\n",
      "Train Loss: 0.04309523786652565\n",
      "-----------EPOCH-----------    ----->  3930\n",
      "Train Loss: 0.04309476394006948\n",
      "-----------EPOCH-----------    ----->  3931\n",
      "Train Loss: 0.043094290329224155\n",
      "-----------EPOCH-----------    ----->  3932\n",
      "Train Loss: 0.043093816666063614\n",
      "-----------EPOCH-----------    ----->  3933\n",
      "Train Loss: 0.0430933430336315\n",
      "-----------EPOCH-----------    ----->  3934\n",
      "Train Loss: 0.043092870433667045\n",
      "-----------EPOCH-----------    ----->  3935\n",
      "Train Loss: 0.043092397875711834\n",
      "-----------EPOCH-----------    ----->  3936\n",
      "Train Loss: 0.04309192586481469\n",
      "-----------EPOCH-----------    ----->  3937\n",
      "Train Loss: 0.04309145464652047\n",
      "-----------EPOCH-----------    ----->  3938\n",
      "Train Loss: 0.043090983310854314\n",
      "-----------EPOCH-----------    ----->  3939\n",
      "Train Loss: 0.043090512255596305\n",
      "-----------EPOCH-----------    ----->  3940\n",
      "Train Loss: 0.04309004100911159\n",
      "-----------EPOCH-----------    ----->  3941\n",
      "Train Loss: 0.043089569338171395\n",
      "-----------EPOCH-----------    ----->  3942\n",
      "Train Loss: 0.04308909782580858\n",
      "-----------EPOCH-----------    ----->  3943\n",
      "Train Loss: 0.04308862635857773\n",
      "-----------EPOCH-----------    ----->  3944\n",
      "Train Loss: 0.0430881549277438\n",
      "-----------EPOCH-----------    ----->  3945\n",
      "Train Loss: 0.04308768409807816\n",
      "-----------EPOCH-----------    ----->  3946\n",
      "Train Loss: 0.043087213589103994\n",
      "-----------EPOCH-----------    ----->  3947\n",
      "Train Loss: 0.04308674229028139\n",
      "-----------EPOCH-----------    ----->  3948\n",
      "Train Loss: 0.04308626954165808\n",
      "-----------EPOCH-----------    ----->  3949\n",
      "Train Loss: 0.043085796875604876\n",
      "-----------EPOCH-----------    ----->  3950\n",
      "Train Loss: 0.043085324304078174\n",
      "-----------EPOCH-----------    ----->  3951\n",
      "Train Loss: 0.043084851193471774\n",
      "-----------EPOCH-----------    ----->  3952\n",
      "Train Loss: 0.043084374436958575\n",
      "-----------EPOCH-----------    ----->  3953\n",
      "Train Loss: 0.04308389823997649\n",
      "-----------EPOCH-----------    ----->  3954\n",
      "Train Loss: 0.043083422415518824\n",
      "-----------EPOCH-----------    ----->  3955\n",
      "Train Loss: 0.04308294787273731\n",
      "-----------EPOCH-----------    ----->  3956\n",
      "Train Loss: 0.043082474433092766\n",
      "-----------EPOCH-----------    ----->  3957\n",
      "Train Loss: 0.04308200118436694\n",
      "-----------EPOCH-----------    ----->  3958\n",
      "Train Loss: 0.04308152898967568\n",
      "-----------EPOCH-----------    ----->  3959\n",
      "Train Loss: 0.04308105688680544\n",
      "-----------EPOCH-----------    ----->  3960\n",
      "Train Loss: 0.04308058619330798\n",
      "-----------EPOCH-----------    ----->  3961\n",
      "Train Loss: 0.043080116570884994\n",
      "-----------EPOCH-----------    ----->  3962\n",
      "Train Loss: 0.04307964784695913\n",
      "-----------EPOCH-----------    ----->  3963\n",
      "Train Loss: 0.04307917822777446\n",
      "-----------EPOCH-----------    ----->  3964\n",
      "Train Loss: 0.04307870865823224\n",
      "-----------EPOCH-----------    ----->  3965\n",
      "Train Loss: 0.04307823933906266\n",
      "-----------EPOCH-----------    ----->  3966\n",
      "Train Loss: 0.04307777016269375\n",
      "-----------EPOCH-----------    ----->  3967\n",
      "Train Loss: 0.04307730239895864\n",
      "-----------EPOCH-----------    ----->  3968\n",
      "Train Loss: 0.04307683502991135\n",
      "-----------EPOCH-----------    ----->  3969\n",
      "Train Loss: 0.043076369359900876\n",
      "-----------EPOCH-----------    ----->  3970\n",
      "Train Loss: 0.04307590478334116\n",
      "-----------EPOCH-----------    ----->  3971\n",
      "Train Loss: 0.04307544067958131\n",
      "-----------EPOCH-----------    ----->  3972\n",
      "Train Loss: 0.043074976883809374\n",
      "-----------EPOCH-----------    ----->  3973\n",
      "Train Loss: 0.043074513898391426\n",
      "-----------EPOCH-----------    ----->  3974\n",
      "Train Loss: 0.04307405097335188\n",
      "-----------EPOCH-----------    ----->  3975\n",
      "Train Loss: 0.043073588338743155\n",
      "-----------EPOCH-----------    ----->  3976\n",
      "Train Loss: 0.04307312712942737\n",
      "-----------EPOCH-----------    ----->  3977\n",
      "Train Loss: 0.04307266671659022\n",
      "-----------EPOCH-----------    ----->  3978\n",
      "Train Loss: 0.0430722058652172\n",
      "-----------EPOCH-----------    ----->  3979\n",
      "Train Loss: 0.04307174543891302\n",
      "-----------EPOCH-----------    ----->  3980\n",
      "Train Loss: 0.04307128638732179\n",
      "-----------EPOCH-----------    ----->  3981\n",
      "Train Loss: 0.04307082765126831\n",
      "-----------EPOCH-----------    ----->  3982\n",
      "Train Loss: 0.04307036793284368\n",
      "-----------EPOCH-----------    ----->  3983\n",
      "Train Loss: 0.0430699087476525\n",
      "-----------EPOCH-----------    ----->  3984\n",
      "Train Loss: 0.04306944997219436\n",
      "-----------EPOCH-----------    ----->  3985\n",
      "Train Loss: 0.043068991354473306\n",
      "-----------EPOCH-----------    ----->  3986\n",
      "Train Loss: 0.04306853255368778\n",
      "-----------EPOCH-----------    ----->  3987\n",
      "Train Loss: 0.04306807468510909\n",
      "-----------EPOCH-----------    ----->  3988\n",
      "Train Loss: 0.04306761703268525\n",
      "-----------EPOCH-----------    ----->  3989\n",
      "Train Loss: 0.04306715937043208\n",
      "-----------EPOCH-----------    ----->  3990\n",
      "Train Loss: 0.043066702355664024\n",
      "-----------EPOCH-----------    ----->  3991\n",
      "Train Loss: 0.04306624496843177\n",
      "-----------EPOCH-----------    ----->  3992\n",
      "Train Loss: 0.04306578782697529\n",
      "-----------EPOCH-----------    ----->  3993\n",
      "Train Loss: 0.043065330853487925\n",
      "-----------EPOCH-----------    ----->  3994\n",
      "Train Loss: 0.04306487405238583\n",
      "-----------EPOCH-----------    ----->  3995\n",
      "Train Loss: 0.043064417586778134\n",
      "-----------EPOCH-----------    ----->  3996\n",
      "Train Loss: 0.04306396094020439\n",
      "-----------EPOCH-----------    ----->  3997\n",
      "Train Loss: 0.04306350437726842\n",
      "-----------EPOCH-----------    ----->  3998\n",
      "Train Loss: 0.043063046683328575\n",
      "-----------EPOCH-----------    ----->  3999\n",
      "Train Loss: 0.043062586081250284\n",
      "-----------EPOCH-----------    ----->  4000\n",
      "Train Loss: 0.043062125743933345\n",
      "-----------EPOCH-----------    ----->  4001\n",
      "Train Loss: 0.04306166571437147\n",
      "-----------EPOCH-----------    ----->  4002\n",
      "Train Loss: 0.043061206055040546\n",
      "-----------EPOCH-----------    ----->  4003\n",
      "Train Loss: 0.04306074681597641\n",
      "-----------EPOCH-----------    ----->  4004\n",
      "Train Loss: 0.043060287453089194\n",
      "-----------EPOCH-----------    ----->  4005\n",
      "Train Loss: 0.04305982764112264\n",
      "-----------EPOCH-----------    ----->  4006\n",
      "Train Loss: 0.043059368138143754\n",
      "-----------EPOCH-----------    ----->  4007\n",
      "Train Loss: 0.04305890870174184\n",
      "-----------EPOCH-----------    ----->  4008\n",
      "Train Loss: 0.04305844958296786\n",
      "-----------EPOCH-----------    ----->  4009\n",
      "Train Loss: 0.0430579919380375\n",
      "-----------EPOCH-----------    ----->  4010\n",
      "Train Loss: 0.04305753457073656\n",
      "-----------EPOCH-----------    ----->  4011\n",
      "Train Loss: 0.04305707638089625\n",
      "-----------EPOCH-----------    ----->  4012\n",
      "Train Loss: 0.04305661844319079\n",
      "-----------EPOCH-----------    ----->  4013\n",
      "Train Loss: 0.04305616098758326\n",
      "-----------EPOCH-----------    ----->  4014\n",
      "Train Loss: 0.04305570337416446\n",
      "-----------EPOCH-----------    ----->  4015\n",
      "Train Loss: 0.04305524585443216\n",
      "-----------EPOCH-----------    ----->  4016\n",
      "Train Loss: 0.043054788553059845\n",
      "-----------EPOCH-----------    ----->  4017\n",
      "Train Loss: 0.04305432998120905\n",
      "-----------EPOCH-----------    ----->  4018\n",
      "Train Loss: 0.04305387047038265\n",
      "-----------EPOCH-----------    ----->  4019\n",
      "Train Loss: 0.04305341081243196\n",
      "-----------EPOCH-----------    ----->  4020\n",
      "Train Loss: 0.043052951323799125\n",
      "-----------EPOCH-----------    ----->  4021\n",
      "Train Loss: 0.04305249169588116\n",
      "-----------EPOCH-----------    ----->  4022\n",
      "Train Loss: 0.04305203260840904\n",
      "-----------EPOCH-----------    ----->  4023\n",
      "Train Loss: 0.043051573991435325\n",
      "-----------EPOCH-----------    ----->  4024\n",
      "Train Loss: 0.04305111540116456\n",
      "-----------EPOCH-----------    ----->  4025\n",
      "Train Loss: 0.043050657349928634\n",
      "-----------EPOCH-----------    ----->  4026\n",
      "Train Loss: 0.043050201327664094\n",
      "-----------EPOCH-----------    ----->  4027\n",
      "Train Loss: 0.04304974563269273\n",
      "-----------EPOCH-----------    ----->  4028\n",
      "Train Loss: 0.0430492895310236\n",
      "-----------EPOCH-----------    ----->  4029\n",
      "Train Loss: 0.04304883342742879\n",
      "-----------EPOCH-----------    ----->  4030\n",
      "Train Loss: 0.043048377272714454\n",
      "-----------EPOCH-----------    ----->  4031\n",
      "Train Loss: 0.04304792007608645\n",
      "-----------EPOCH-----------    ----->  4032\n",
      "Train Loss: 0.043047462849705266\n",
      "-----------EPOCH-----------    ----->  4033\n",
      "Train Loss: 0.043047005908777615\n",
      "-----------EPOCH-----------    ----->  4034\n",
      "Train Loss: 0.04304654896047206\n",
      "-----------EPOCH-----------    ----->  4035\n",
      "Train Loss: 0.04304609259202324\n",
      "-----------EPOCH-----------    ----->  4036\n",
      "Train Loss: 0.04304563712895337\n",
      "-----------EPOCH-----------    ----->  4037\n",
      "Train Loss: 0.043045181934066\n",
      "-----------EPOCH-----------    ----->  4038\n",
      "Train Loss: 0.04304472654465036\n",
      "-----------EPOCH-----------    ----->  4039\n",
      "Train Loss: 0.04304427146711426\n",
      "-----------EPOCH-----------    ----->  4040\n",
      "Train Loss: 0.04304381637883861\n",
      "-----------EPOCH-----------    ----->  4041\n",
      "Train Loss: 0.043043361321878276\n",
      "-----------EPOCH-----------    ----->  4042\n",
      "Train Loss: 0.043042906626060015\n",
      "-----------EPOCH-----------    ----->  4043\n",
      "Train Loss: 0.04304245215365691\n",
      "-----------EPOCH-----------    ----->  4044\n",
      "Train Loss: 0.04304199782695423\n",
      "-----------EPOCH-----------    ----->  4045\n",
      "Train Loss: 0.04304154343582342\n",
      "-----------EPOCH-----------    ----->  4046\n",
      "Train Loss: 0.04304108853986023\n",
      "-----------EPOCH-----------    ----->  4047\n",
      "Train Loss: 0.04304063452521774\n",
      "-----------EPOCH-----------    ----->  4048\n",
      "Train Loss: 0.043040181496362656\n",
      "-----------EPOCH-----------    ----->  4049\n",
      "Train Loss: 0.043039730292024576\n",
      "-----------EPOCH-----------    ----->  4050\n",
      "Train Loss: 0.04303927973280522\n",
      "-----------EPOCH-----------    ----->  4051\n",
      "Train Loss: 0.043038829734902626\n",
      "-----------EPOCH-----------    ----->  4052\n",
      "Train Loss: 0.04303837994672209\n",
      "-----------EPOCH-----------    ----->  4053\n",
      "Train Loss: 0.043037930253531594\n",
      "-----------EPOCH-----------    ----->  4054\n",
      "Train Loss: 0.04303748024526067\n",
      "-----------EPOCH-----------    ----->  4055\n",
      "Train Loss: 0.04303702988313883\n",
      "-----------EPOCH-----------    ----->  4056\n",
      "Train Loss: 0.04303657990381524\n",
      "-----------EPOCH-----------    ----->  4057\n",
      "Train Loss: 0.043036130915600074\n",
      "-----------EPOCH-----------    ----->  4058\n",
      "Train Loss: 0.04303568215607079\n",
      "-----------EPOCH-----------    ----->  4059\n",
      "Train Loss: 0.043035233086376065\n",
      "-----------EPOCH-----------    ----->  4060\n",
      "Train Loss: 0.043034784169889234\n",
      "-----------EPOCH-----------    ----->  4061\n",
      "Train Loss: 0.043034334765586345\n",
      "-----------EPOCH-----------    ----->  4062\n",
      "Train Loss: 0.04303388487680276\n",
      "-----------EPOCH-----------    ----->  4063\n",
      "Train Loss: 0.04303343451579631\n",
      "-----------EPOCH-----------    ----->  4064\n",
      "Train Loss: 0.04303298254327993\n",
      "-----------EPOCH-----------    ----->  4065\n",
      "Train Loss: 0.04303253050786329\n",
      "-----------EPOCH-----------    ----->  4066\n",
      "Train Loss: 0.04303207840557618\n",
      "-----------EPOCH-----------    ----->  4067\n",
      "Train Loss: 0.043031626822709404\n",
      "-----------EPOCH-----------    ----->  4068\n",
      "Train Loss: 0.0430311762329159\n",
      "-----------EPOCH-----------    ----->  4069\n",
      "Train Loss: 0.043030724929496306\n",
      "-----------EPOCH-----------    ----->  4070\n",
      "Train Loss: 0.043030273818313924\n",
      "-----------EPOCH-----------    ----->  4071\n",
      "Train Loss: 0.0430298232477768\n",
      "-----------EPOCH-----------    ----->  4072\n",
      "Train Loss: 0.0430293732281189\n",
      "-----------EPOCH-----------    ----->  4073\n",
      "Train Loss: 0.043028923229562976\n",
      "-----------EPOCH-----------    ----->  4074\n",
      "Train Loss: 0.043028473387283155\n",
      "-----------EPOCH-----------    ----->  4075\n",
      "Train Loss: 0.04302802278323594\n",
      "-----------EPOCH-----------    ----->  4076\n",
      "Train Loss: 0.04302757264230126\n",
      "-----------EPOCH-----------    ----->  4077\n",
      "Train Loss: 0.04302712208685777\n",
      "-----------EPOCH-----------    ----->  4078\n",
      "Train Loss: 0.04302667167456711\n",
      "-----------EPOCH-----------    ----->  4079\n",
      "Train Loss: 0.04302622335711848\n",
      "-----------EPOCH-----------    ----->  4080\n",
      "Train Loss: 0.04302577466962259\n",
      "-----------EPOCH-----------    ----->  4081\n",
      "Train Loss: 0.04302532565519591\n",
      "-----------EPOCH-----------    ----->  4082\n",
      "Train Loss: 0.043024876348137064\n",
      "-----------EPOCH-----------    ----->  4083\n",
      "Train Loss: 0.04302442757673161\n",
      "-----------EPOCH-----------    ----->  4084\n",
      "Train Loss: 0.04302397969930882\n",
      "-----------EPOCH-----------    ----->  4085\n",
      "Train Loss: 0.04302353203848693\n",
      "-----------EPOCH-----------    ----->  4086\n",
      "Train Loss: 0.043023085546547817\n",
      "-----------EPOCH-----------    ----->  4087\n",
      "Train Loss: 0.0430226390065044\n",
      "-----------EPOCH-----------    ----->  4088\n",
      "Train Loss: 0.04302219275777728\n",
      "-----------EPOCH-----------    ----->  4089\n",
      "Train Loss: 0.04302174669940669\n",
      "-----------EPOCH-----------    ----->  4090\n",
      "Train Loss: 0.04302130066942665\n",
      "-----------EPOCH-----------    ----->  4091\n",
      "Train Loss: 0.04302085559777676\n",
      "-----------EPOCH-----------    ----->  4092\n",
      "Train Loss: 0.04302041151182384\n",
      "-----------EPOCH-----------    ----->  4093\n",
      "Train Loss: 0.04301996716844285\n",
      "-----------EPOCH-----------    ----->  4094\n",
      "Train Loss: 0.043019522870880206\n",
      "-----------EPOCH-----------    ----->  4095\n",
      "Train Loss: 0.04301907938015683\n",
      "-----------EPOCH-----------    ----->  4096\n",
      "Train Loss: 0.04301863636037526\n",
      "-----------EPOCH-----------    ----->  4097\n",
      "Train Loss: 0.043018193832250876\n",
      "-----------EPOCH-----------    ----->  4098\n",
      "Train Loss: 0.043017752111381743\n",
      "-----------EPOCH-----------    ----->  4099\n",
      "Train Loss: 0.043017310927840176\n",
      "-----------EPOCH-----------    ----->  4100\n",
      "Train Loss: 0.04301686977089795\n",
      "-----------EPOCH-----------    ----->  4101\n",
      "Train Loss: 0.04301642924732032\n",
      "-----------EPOCH-----------    ----->  4102\n",
      "Train Loss: 0.04301599064345871\n",
      "-----------EPOCH-----------    ----->  4103\n",
      "Train Loss: 0.04301555339573572\n",
      "-----------EPOCH-----------    ----->  4104\n",
      "Train Loss: 0.04301511678443584\n",
      "-----------EPOCH-----------    ----->  4105\n",
      "Train Loss: 0.04301468082278584\n",
      "-----------EPOCH-----------    ----->  4106\n",
      "Train Loss: 0.04301424524895684\n",
      "-----------EPOCH-----------    ----->  4107\n",
      "Train Loss: 0.04301380976362368\n",
      "-----------EPOCH-----------    ----->  4108\n",
      "Train Loss: 0.043013373924563315\n",
      "-----------EPOCH-----------    ----->  4109\n",
      "Train Loss: 0.0430129377533116\n",
      "-----------EPOCH-----------    ----->  4110\n",
      "Train Loss: 0.043012499173735605\n",
      "-----------EPOCH-----------    ----->  4111\n",
      "Train Loss: 0.043012061250147664\n",
      "-----------EPOCH-----------    ----->  4112\n",
      "Train Loss: 0.043011622969604126\n",
      "-----------EPOCH-----------    ----->  4113\n",
      "Train Loss: 0.043011185097086437\n",
      "-----------EPOCH-----------    ----->  4114\n",
      "Train Loss: 0.04301074748051897\n",
      "-----------EPOCH-----------    ----->  4115\n",
      "Train Loss: 0.04301031009699562\n",
      "-----------EPOCH-----------    ----->  4116\n",
      "Train Loss: 0.043009872632796355\n",
      "-----------EPOCH-----------    ----->  4117\n",
      "Train Loss: 0.04300943599988076\n",
      "-----------EPOCH-----------    ----->  4118\n",
      "Train Loss: 0.04300900010603687\n",
      "-----------EPOCH-----------    ----->  4119\n",
      "Train Loss: 0.043008564558729714\n",
      "-----------EPOCH-----------    ----->  4120\n",
      "Train Loss: 0.0430081289340682\n",
      "-----------EPOCH-----------    ----->  4121\n",
      "Train Loss: 0.04300769371712155\n",
      "-----------EPOCH-----------    ----->  4122\n",
      "Train Loss: 0.04300725954007048\n",
      "-----------EPOCH-----------    ----->  4123\n",
      "Train Loss: 0.04300682485617573\n",
      "-----------EPOCH-----------    ----->  4124\n",
      "Train Loss: 0.043006390503348674\n",
      "-----------EPOCH-----------    ----->  4125\n",
      "Train Loss: 0.04300595627847511\n",
      "-----------EPOCH-----------    ----->  4126\n",
      "Train Loss: 0.04300552157181965\n",
      "-----------EPOCH-----------    ----->  4127\n",
      "Train Loss: 0.04300508666795032\n",
      "-----------EPOCH-----------    ----->  4128\n",
      "Train Loss: 0.043004652046069736\n",
      "-----------EPOCH-----------    ----->  4129\n",
      "Train Loss: 0.043004217124136504\n",
      "-----------EPOCH-----------    ----->  4130\n",
      "Train Loss: 0.04300378326053823\n",
      "-----------EPOCH-----------    ----->  4131\n",
      "Train Loss: 0.04300334959959786\n",
      "-----------EPOCH-----------    ----->  4132\n",
      "Train Loss: 0.04300291684593044\n",
      "-----------EPOCH-----------    ----->  4133\n",
      "Train Loss: 0.04300248430960559\n",
      "-----------EPOCH-----------    ----->  4134\n",
      "Train Loss: 0.04300205160111876\n",
      "-----------EPOCH-----------    ----->  4135\n",
      "Train Loss: 0.04300162011000709\n",
      "-----------EPOCH-----------    ----->  4136\n",
      "Train Loss: 0.04300118848681264\n",
      "-----------EPOCH-----------    ----->  4137\n",
      "Train Loss: 0.04300075766978399\n",
      "-----------EPOCH-----------    ----->  4138\n",
      "Train Loss: 0.04300032741432665\n",
      "-----------EPOCH-----------    ----->  4139\n",
      "Train Loss: 0.04299989796481619\n",
      "-----------EPOCH-----------    ----->  4140\n",
      "Train Loss: 0.042999470386207835\n",
      "-----------EPOCH-----------    ----->  4141\n",
      "Train Loss: 0.042999042933123476\n",
      "-----------EPOCH-----------    ----->  4142\n",
      "Train Loss: 0.04299861678317384\n",
      "-----------EPOCH-----------    ----->  4143\n",
      "Train Loss: 0.04299819098118817\n",
      "-----------EPOCH-----------    ----->  4144\n",
      "Train Loss: 0.042997764251778856\n",
      "-----------EPOCH-----------    ----->  4145\n",
      "Train Loss: 0.042997338980724935\n",
      "-----------EPOCH-----------    ----->  4146\n",
      "Train Loss: 0.0429969130836832\n",
      "-----------EPOCH-----------    ----->  4147\n",
      "Train Loss: 0.04299648687545509\n",
      "-----------EPOCH-----------    ----->  4148\n",
      "Train Loss: 0.042996060600202016\n",
      "-----------EPOCH-----------    ----->  4149\n",
      "Train Loss: 0.0429956334806241\n",
      "-----------EPOCH-----------    ----->  4150\n",
      "Train Loss: 0.04299520706398855\n",
      "-----------EPOCH-----------    ----->  4151\n",
      "Train Loss: 0.04299478028516879\n",
      "-----------EPOCH-----------    ----->  4152\n",
      "Train Loss: 0.042994354791254\n",
      "-----------EPOCH-----------    ----->  4153\n",
      "Train Loss: 0.0429939304873051\n",
      "-----------EPOCH-----------    ----->  4154\n",
      "Train Loss: 0.042993505019649575\n",
      "-----------EPOCH-----------    ----->  4155\n",
      "Train Loss: 0.042993079987030766\n",
      "-----------EPOCH-----------    ----->  4156\n",
      "Train Loss: 0.04299265506643476\n",
      "-----------EPOCH-----------    ----->  4157\n",
      "Train Loss: 0.04299223085047622\n",
      "-----------EPOCH-----------    ----->  4158\n",
      "Train Loss: 0.04299180667787568\n",
      "-----------EPOCH-----------    ----->  4159\n",
      "Train Loss: 0.04299138272718341\n",
      "-----------EPOCH-----------    ----->  4160\n",
      "Train Loss: 0.04299095945271762\n",
      "-----------EPOCH-----------    ----->  4161\n",
      "Train Loss: 0.04299053556577848\n",
      "-----------EPOCH-----------    ----->  4162\n",
      "Train Loss: 0.042990112622356726\n",
      "-----------EPOCH-----------    ----->  4163\n",
      "Train Loss: 0.04298968987547964\n",
      "-----------EPOCH-----------    ----->  4164\n",
      "Train Loss: 0.042989267084825984\n",
      "-----------EPOCH-----------    ----->  4165\n",
      "Train Loss: 0.04298884164719356\n",
      "-----------EPOCH-----------    ----->  4166\n",
      "Train Loss: 0.04298841665098748\n",
      "-----------EPOCH-----------    ----->  4167\n",
      "Train Loss: 0.042987992275895406\n",
      "-----------EPOCH-----------    ----->  4168\n",
      "Train Loss: 0.04298756787401346\n",
      "-----------EPOCH-----------    ----->  4169\n",
      "Train Loss: 0.04298714485398277\n",
      "-----------EPOCH-----------    ----->  4170\n",
      "Train Loss: 0.04298672163500296\n",
      "-----------EPOCH-----------    ----->  4171\n",
      "Train Loss: 0.04298629893265264\n",
      "-----------EPOCH-----------    ----->  4172\n",
      "Train Loss: 0.042985875962079687\n",
      "-----------EPOCH-----------    ----->  4173\n",
      "Train Loss: 0.042985452956494606\n",
      "-----------EPOCH-----------    ----->  4174\n",
      "Train Loss: 0.04298503062729888\n",
      "-----------EPOCH-----------    ----->  4175\n",
      "Train Loss: 0.04298460778605342\n",
      "-----------EPOCH-----------    ----->  4176\n",
      "Train Loss: 0.04298418545290326\n",
      "-----------EPOCH-----------    ----->  4177\n",
      "Train Loss: 0.042983762069966784\n",
      "-----------EPOCH-----------    ----->  4178\n",
      "Train Loss: 0.042983336703290353\n",
      "-----------EPOCH-----------    ----->  4179\n",
      "Train Loss: 0.0429829111132327\n",
      "-----------EPOCH-----------    ----->  4180\n",
      "Train Loss: 0.042982485375711754\n",
      "-----------EPOCH-----------    ----->  4181\n",
      "Train Loss: 0.04298205949042794\n",
      "-----------EPOCH-----------    ----->  4182\n",
      "Train Loss: 0.0429816339565616\n",
      "-----------EPOCH-----------    ----->  4183\n",
      "Train Loss: 0.042981208814172035\n",
      "-----------EPOCH-----------    ----->  4184\n",
      "Train Loss: 0.04298078328670734\n",
      "-----------EPOCH-----------    ----->  4185\n",
      "Train Loss: 0.04298035775907273\n",
      "-----------EPOCH-----------    ----->  4186\n",
      "Train Loss: 0.042979932969641504\n",
      "-----------EPOCH-----------    ----->  4187\n",
      "Train Loss: 0.04297950879287076\n",
      "-----------EPOCH-----------    ----->  4188\n",
      "Train Loss: 0.04297908495154068\n",
      "-----------EPOCH-----------    ----->  4189\n",
      "Train Loss: 0.04297866203820851\n",
      "-----------EPOCH-----------    ----->  4190\n",
      "Train Loss: 0.042978238421337786\n",
      "-----------EPOCH-----------    ----->  4191\n",
      "Train Loss: 0.04297781534795129\n",
      "-----------EPOCH-----------    ----->  4192\n",
      "Train Loss: 0.04297738893829835\n",
      "-----------EPOCH-----------    ----->  4193\n",
      "Train Loss: 0.042976963317438034\n",
      "-----------EPOCH-----------    ----->  4194\n",
      "Train Loss: 0.042976537104092286\n",
      "-----------EPOCH-----------    ----->  4195\n",
      "Train Loss: 0.042976111461144974\n",
      "-----------EPOCH-----------    ----->  4196\n",
      "Train Loss: 0.042975685086770195\n",
      "-----------EPOCH-----------    ----->  4197\n",
      "Train Loss: 0.042975259278225854\n",
      "-----------EPOCH-----------    ----->  4198\n",
      "Train Loss: 0.042974832566687084\n",
      "-----------EPOCH-----------    ----->  4199\n",
      "Train Loss: 0.042974405574364015\n",
      "-----------EPOCH-----------    ----->  4200\n",
      "Train Loss: 0.04297397841000373\n",
      "-----------EPOCH-----------    ----->  4201\n",
      "Train Loss: 0.042973551635554386\n",
      "-----------EPOCH-----------    ----->  4202\n",
      "Train Loss: 0.042973125062616316\n",
      "-----------EPOCH-----------    ----->  4203\n",
      "Train Loss: 0.042972698300524456\n",
      "-----------EPOCH-----------    ----->  4204\n",
      "Train Loss: 0.04297227200128096\n",
      "-----------EPOCH-----------    ----->  4205\n",
      "Train Loss: 0.04297184498301354\n",
      "-----------EPOCH-----------    ----->  4206\n",
      "Train Loss: 0.04297141898782254\n",
      "-----------EPOCH-----------    ----->  4207\n",
      "Train Loss: 0.04297099296541071\n",
      "-----------EPOCH-----------    ----->  4208\n",
      "Train Loss: 0.042970566972184675\n",
      "-----------EPOCH-----------    ----->  4209\n",
      "Train Loss: 0.04297014145639713\n",
      "-----------EPOCH-----------    ----->  4210\n",
      "Train Loss: 0.042969714890585896\n",
      "-----------EPOCH-----------    ----->  4211\n",
      "Train Loss: 0.04296928815397826\n",
      "-----------EPOCH-----------    ----->  4212\n",
      "Train Loss: 0.042968861406596386\n",
      "-----------EPOCH-----------    ----->  4213\n",
      "Train Loss: 0.042968435194859704\n",
      "-----------EPOCH-----------    ----->  4214\n",
      "Train Loss: 0.04296801114538455\n",
      "-----------EPOCH-----------    ----->  4215\n",
      "Train Loss: 0.04296758635867078\n",
      "-----------EPOCH-----------    ----->  4216\n",
      "Train Loss: 0.042967162482385204\n",
      "-----------EPOCH-----------    ----->  4217\n",
      "Train Loss: 0.0429667387189412\n",
      "-----------EPOCH-----------    ----->  4218\n",
      "Train Loss: 0.042966311526860604\n",
      "-----------EPOCH-----------    ----->  4219\n",
      "Train Loss: 0.04296588476275547\n",
      "-----------EPOCH-----------    ----->  4220\n",
      "Train Loss: 0.04296545821312339\n",
      "-----------EPOCH-----------    ----->  4221\n",
      "Train Loss: 0.04296503276230074\n",
      "-----------EPOCH-----------    ----->  4222\n",
      "Train Loss: 0.042964607988315334\n",
      "-----------EPOCH-----------    ----->  4223\n",
      "Train Loss: 0.042964183548225385\n",
      "-----------EPOCH-----------    ----->  4224\n",
      "Train Loss: 0.04296375954780792\n",
      "-----------EPOCH-----------    ----->  4225\n",
      "Train Loss: 0.042963335001371845\n",
      "-----------EPOCH-----------    ----->  4226\n",
      "Train Loss: 0.04296291095259098\n",
      "-----------EPOCH-----------    ----->  4227\n",
      "Train Loss: 0.04296248732848513\n",
      "-----------EPOCH-----------    ----->  4228\n",
      "Train Loss: 0.04296206367536743\n",
      "-----------EPOCH-----------    ----->  4229\n",
      "Train Loss: 0.04296164093415005\n",
      "-----------EPOCH-----------    ----->  4230\n",
      "Train Loss: 0.04296121766719642\n",
      "-----------EPOCH-----------    ----->  4231\n",
      "Train Loss: 0.04296079431905883\n",
      "-----------EPOCH-----------    ----->  4232\n",
      "Train Loss: 0.0429603710061601\n",
      "-----------EPOCH-----------    ----->  4233\n",
      "Train Loss: 0.04295994743365235\n",
      "-----------EPOCH-----------    ----->  4234\n",
      "Train Loss: 0.04295952430422073\n",
      "-----------EPOCH-----------    ----->  4235\n",
      "Train Loss: 0.042959100599639845\n",
      "-----------EPOCH-----------    ----->  4236\n",
      "Train Loss: 0.04295867802298634\n",
      "-----------EPOCH-----------    ----->  4237\n",
      "Train Loss: 0.04295825513482118\n",
      "-----------EPOCH-----------    ----->  4238\n",
      "Train Loss: 0.04295783293331415\n",
      "-----------EPOCH-----------    ----->  4239\n",
      "Train Loss: 0.042957410010589316\n",
      "-----------EPOCH-----------    ----->  4240\n",
      "Train Loss: 0.04295698710910855\n",
      "-----------EPOCH-----------    ----->  4241\n",
      "Train Loss: 0.04295656459732158\n",
      "-----------EPOCH-----------    ----->  4242\n",
      "Train Loss: 0.042956142103098484\n",
      "-----------EPOCH-----------    ----->  4243\n",
      "Train Loss: 0.04295572013986242\n",
      "-----------EPOCH-----------    ----->  4244\n",
      "Train Loss: 0.04295529823160893\n",
      "-----------EPOCH-----------    ----->  4245\n",
      "Train Loss: 0.04295487815468473\n",
      "-----------EPOCH-----------    ----->  4246\n",
      "Train Loss: 0.04295445843095011\n",
      "-----------EPOCH-----------    ----->  4247\n",
      "Train Loss: 0.042954039126587254\n",
      "-----------EPOCH-----------    ----->  4248\n",
      "Train Loss: 0.042953619224720054\n",
      "-----------EPOCH-----------    ----->  4249\n",
      "Train Loss: 0.042953200302438155\n",
      "-----------EPOCH-----------    ----->  4250\n",
      "Train Loss: 0.04295278134064443\n",
      "-----------EPOCH-----------    ----->  4251\n",
      "Train Loss: 0.04295236312927846\n",
      "-----------EPOCH-----------    ----->  4252\n",
      "Train Loss: 0.042951944339559324\n",
      "-----------EPOCH-----------    ----->  4253\n",
      "Train Loss: 0.04295152525564346\n",
      "-----------EPOCH-----------    ----->  4254\n",
      "Train Loss: 0.04295110527210421\n",
      "-----------EPOCH-----------    ----->  4255\n",
      "Train Loss: 0.04295068686981129\n",
      "-----------EPOCH-----------    ----->  4256\n",
      "Train Loss: 0.042950268475489176\n",
      "-----------EPOCH-----------    ----->  4257\n",
      "Train Loss: 0.04294985119721227\n",
      "-----------EPOCH-----------    ----->  4258\n",
      "Train Loss: 0.04294943302692596\n",
      "-----------EPOCH-----------    ----->  4259\n",
      "Train Loss: 0.04294901402630991\n",
      "-----------EPOCH-----------    ----->  4260\n",
      "Train Loss: 0.042948596078836346\n",
      "-----------EPOCH-----------    ----->  4261\n",
      "Train Loss: 0.04294817777537251\n",
      "-----------EPOCH-----------    ----->  4262\n",
      "Train Loss: 0.042947758946833\n",
      "-----------EPOCH-----------    ----->  4263\n",
      "Train Loss: 0.04294734043844766\n",
      "-----------EPOCH-----------    ----->  4264\n",
      "Train Loss: 0.0429469221948296\n",
      "-----------EPOCH-----------    ----->  4265\n",
      "Train Loss: 0.042946504045672296\n",
      "-----------EPOCH-----------    ----->  4266\n",
      "Train Loss: 0.04294608613518871\n",
      "-----------EPOCH-----------    ----->  4267\n",
      "Train Loss: 0.04294566870618105\n",
      "-----------EPOCH-----------    ----->  4268\n",
      "Train Loss: 0.042945251343861575\n",
      "-----------EPOCH-----------    ----->  4269\n",
      "Train Loss: 0.04294483474767477\n",
      "-----------EPOCH-----------    ----->  4270\n",
      "Train Loss: 0.04294441853126465\n",
      "-----------EPOCH-----------    ----->  4271\n",
      "Train Loss: 0.04294400256118874\n",
      "-----------EPOCH-----------    ----->  4272\n",
      "Train Loss: 0.042943587012218704\n",
      "-----------EPOCH-----------    ----->  4273\n",
      "Train Loss: 0.042943171971904365\n",
      "-----------EPOCH-----------    ----->  4274\n",
      "Train Loss: 0.04294275735742305\n",
      "-----------EPOCH-----------    ----->  4275\n",
      "Train Loss: 0.04294234275336003\n",
      "-----------EPOCH-----------    ----->  4276\n",
      "Train Loss: 0.04294192857231957\n",
      "-----------EPOCH-----------    ----->  4277\n",
      "Train Loss: 0.042941514687168274\n",
      "-----------EPOCH-----------    ----->  4278\n",
      "Train Loss: 0.04294109973500895\n",
      "-----------EPOCH-----------    ----->  4279\n",
      "Train Loss: 0.0429406849029866\n",
      "-----------EPOCH-----------    ----->  4280\n",
      "Train Loss: 0.04294026993922278\n",
      "-----------EPOCH-----------    ----->  4281\n",
      "Train Loss: 0.04293985481415033\n",
      "-----------EPOCH-----------    ----->  4282\n",
      "Train Loss: 0.042939440230522014\n",
      "-----------EPOCH-----------    ----->  4283\n",
      "Train Loss: 0.0429390262852748\n",
      "-----------EPOCH-----------    ----->  4284\n",
      "Train Loss: 0.04293861246076979\n",
      "-----------EPOCH-----------    ----->  4285\n",
      "Train Loss: 0.04293819910905219\n",
      "-----------EPOCH-----------    ----->  4286\n",
      "Train Loss: 0.0429377850366249\n",
      "-----------EPOCH-----------    ----->  4287\n",
      "Train Loss: 0.04293737049848958\n",
      "-----------EPOCH-----------    ----->  4288\n",
      "Train Loss: 0.04293695617366021\n",
      "-----------EPOCH-----------    ----->  4289\n",
      "Train Loss: 0.0429365416377809\n",
      "-----------EPOCH-----------    ----->  4290\n",
      "Train Loss: 0.042936127524109996\n",
      "-----------EPOCH-----------    ----->  4291\n",
      "Train Loss: 0.04293571410651599\n",
      "-----------EPOCH-----------    ----->  4292\n",
      "Train Loss: 0.04293530134706989\n",
      "-----------EPOCH-----------    ----->  4293\n",
      "Train Loss: 0.04293488878168921\n",
      "-----------EPOCH-----------    ----->  4294\n",
      "Train Loss: 0.042934476024060995\n",
      "-----------EPOCH-----------    ----->  4295\n",
      "Train Loss: 0.04293406341737009\n",
      "-----------EPOCH-----------    ----->  4296\n",
      "Train Loss: 0.042933650545245304\n",
      "-----------EPOCH-----------    ----->  4297\n",
      "Train Loss: 0.042933238317141104\n",
      "-----------EPOCH-----------    ----->  4298\n",
      "Train Loss: 0.042932826369361535\n",
      "-----------EPOCH-----------    ----->  4299\n",
      "Train Loss: 0.04293241362062395\n",
      "-----------EPOCH-----------    ----->  4300\n",
      "Train Loss: 0.04293200137973533\n",
      "-----------EPOCH-----------    ----->  4301\n",
      "Train Loss: 0.042931589452478686\n",
      "-----------EPOCH-----------    ----->  4302\n",
      "Train Loss: 0.04293117762212926\n",
      "-----------EPOCH-----------    ----->  4303\n",
      "Train Loss: 0.04293076614335223\n",
      "-----------EPOCH-----------    ----->  4304\n",
      "Train Loss: 0.042930354603725664\n",
      "-----------EPOCH-----------    ----->  4305\n",
      "Train Loss: 0.04292994256570314\n",
      "-----------EPOCH-----------    ----->  4306\n",
      "Train Loss: 0.04292953046743018\n",
      "-----------EPOCH-----------    ----->  4307\n",
      "Train Loss: 0.04292911890819272\n",
      "-----------EPOCH-----------    ----->  4308\n",
      "Train Loss: 0.0429287071225706\n",
      "-----------EPOCH-----------    ----->  4309\n",
      "Train Loss: 0.042928296002440795\n",
      "-----------EPOCH-----------    ----->  4310\n",
      "Train Loss: 0.042927885407808314\n",
      "-----------EPOCH-----------    ----->  4311\n",
      "Train Loss: 0.04292747524687707\n",
      "-----------EPOCH-----------    ----->  4312\n",
      "Train Loss: 0.042927066043597\n",
      "-----------EPOCH-----------    ----->  4313\n",
      "Train Loss: 0.04292665766838926\n",
      "-----------EPOCH-----------    ----->  4314\n",
      "Train Loss: 0.04292624986061718\n",
      "-----------EPOCH-----------    ----->  4315\n",
      "Train Loss: 0.04292584144058639\n",
      "-----------EPOCH-----------    ----->  4316\n",
      "Train Loss: 0.042925432940662735\n",
      "-----------EPOCH-----------    ----->  4317\n",
      "Train Loss: 0.042925024743779974\n",
      "-----------EPOCH-----------    ----->  4318\n",
      "Train Loss: 0.042924616288774996\n",
      "-----------EPOCH-----------    ----->  4319\n",
      "Train Loss: 0.04292420862165018\n",
      "-----------EPOCH-----------    ----->  4320\n",
      "Train Loss: 0.04292380075531\n",
      "-----------EPOCH-----------    ----->  4321\n",
      "Train Loss: 0.042923392686153444\n",
      "-----------EPOCH-----------    ----->  4322\n",
      "Train Loss: 0.04292298499280094\n",
      "-----------EPOCH-----------    ----->  4323\n",
      "Train Loss: 0.04292257841032676\n",
      "-----------EPOCH-----------    ----->  4324\n",
      "Train Loss: 0.04292217262699529\n",
      "-----------EPOCH-----------    ----->  4325\n",
      "Train Loss: 0.04292176649445648\n",
      "-----------EPOCH-----------    ----->  4326\n",
      "Train Loss: 0.042921359775174577\n",
      "-----------EPOCH-----------    ----->  4327\n",
      "Train Loss: 0.042920952318837094\n",
      "-----------EPOCH-----------    ----->  4328\n",
      "Train Loss: 0.04292054507841949\n",
      "-----------EPOCH-----------    ----->  4329\n",
      "Train Loss: 0.04292013818126812\n",
      "-----------EPOCH-----------    ----->  4330\n",
      "Train Loss: 0.042919732325559054\n",
      "-----------EPOCH-----------    ----->  4331\n",
      "Train Loss: 0.04291932618844975\n",
      "-----------EPOCH-----------    ----->  4332\n",
      "Train Loss: 0.04291892027209804\n",
      "-----------EPOCH-----------    ----->  4333\n",
      "Train Loss: 0.04291851449585319\n",
      "-----------EPOCH-----------    ----->  4334\n",
      "Train Loss: 0.042918107914241624\n",
      "-----------EPOCH-----------    ----->  4335\n",
      "Train Loss: 0.042917701600569624\n",
      "-----------EPOCH-----------    ----->  4336\n",
      "Train Loss: 0.042917295817202744\n",
      "-----------EPOCH-----------    ----->  4337\n",
      "Train Loss: 0.04291689022986714\n",
      "-----------EPOCH-----------    ----->  4338\n",
      "Train Loss: 0.042916485649713516\n",
      "-----------EPOCH-----------    ----->  4339\n",
      "Train Loss: 0.04291608225787997\n",
      "-----------EPOCH-----------    ----->  4340\n",
      "Train Loss: 0.042915678986280244\n",
      "-----------EPOCH-----------    ----->  4341\n",
      "Train Loss: 0.042915275896652415\n",
      "-----------EPOCH-----------    ----->  4342\n",
      "Train Loss: 0.04291487321515531\n",
      "-----------EPOCH-----------    ----->  4343\n",
      "Train Loss: 0.04291447032330363\n",
      "-----------EPOCH-----------    ----->  4344\n",
      "Train Loss: 0.04291406690343749\n",
      "-----------EPOCH-----------    ----->  4345\n",
      "Train Loss: 0.04291366367798161\n",
      "-----------EPOCH-----------    ----->  4346\n",
      "Train Loss: 0.04291326078171685\n",
      "-----------EPOCH-----------    ----->  4347\n",
      "Train Loss: 0.0429128580052703\n",
      "-----------EPOCH-----------    ----->  4348\n",
      "Train Loss: 0.04291245524106488\n",
      "-----------EPOCH-----------    ----->  4349\n",
      "Train Loss: 0.04291205212574157\n",
      "-----------EPOCH-----------    ----->  4350\n",
      "Train Loss: 0.04291164931285416\n",
      "-----------EPOCH-----------    ----->  4351\n",
      "Train Loss: 0.0429112468865804\n",
      "-----------EPOCH-----------    ----->  4352\n",
      "Train Loss: 0.04291084444430941\n",
      "-----------EPOCH-----------    ----->  4353\n",
      "Train Loss: 0.04291044204139959\n",
      "-----------EPOCH-----------    ----->  4354\n",
      "Train Loss: 0.042910039614268855\n",
      "-----------EPOCH-----------    ----->  4355\n",
      "Train Loss: 0.042909637258103143\n",
      "-----------EPOCH-----------    ----->  4356\n",
      "Train Loss: 0.04290923504271723\n",
      "-----------EPOCH-----------    ----->  4357\n",
      "Train Loss: 0.042908833195313044\n",
      "-----------EPOCH-----------    ----->  4358\n",
      "Train Loss: 0.04290843033316183\n",
      "-----------EPOCH-----------    ----->  4359\n",
      "Train Loss: 0.04290802835746207\n",
      "-----------EPOCH-----------    ----->  4360\n",
      "Train Loss: 0.04290762567217271\n",
      "-----------EPOCH-----------    ----->  4361\n",
      "Train Loss: 0.042907222863409464\n",
      "-----------EPOCH-----------    ----->  4362\n",
      "Train Loss: 0.042906819874099465\n",
      "-----------EPOCH-----------    ----->  4363\n",
      "Train Loss: 0.04290641710735796\n",
      "-----------EPOCH-----------    ----->  4364\n",
      "Train Loss: 0.04290601406520793\n",
      "-----------EPOCH-----------    ----->  4365\n",
      "Train Loss: 0.042905610804237486\n",
      "-----------EPOCH-----------    ----->  4366\n",
      "Train Loss: 0.04290520800912284\n",
      "-----------EPOCH-----------    ----->  4367\n",
      "Train Loss: 0.04290480546704552\n",
      "-----------EPOCH-----------    ----->  4368\n",
      "Train Loss: 0.04290440260588482\n",
      "-----------EPOCH-----------    ----->  4369\n",
      "Train Loss: 0.04290399985481252\n",
      "-----------EPOCH-----------    ----->  4370\n",
      "Train Loss: 0.042903596299046574\n",
      "-----------EPOCH-----------    ----->  4371\n",
      "Train Loss: 0.04290319350665301\n",
      "-----------EPOCH-----------    ----->  4372\n",
      "Train Loss: 0.04290279127488202\n",
      "-----------EPOCH-----------    ----->  4373\n",
      "Train Loss: 0.04290238883070718\n",
      "-----------EPOCH-----------    ----->  4374\n",
      "Train Loss: 0.042901986126530144\n",
      "-----------EPOCH-----------    ----->  4375\n",
      "Train Loss: 0.04290158332353304\n",
      "-----------EPOCH-----------    ----->  4376\n",
      "Train Loss: 0.04290118034015449\n",
      "-----------EPOCH-----------    ----->  4377\n",
      "Train Loss: 0.042900776688168905\n",
      "-----------EPOCH-----------    ----->  4378\n",
      "Train Loss: 0.042900372928268475\n",
      "-----------EPOCH-----------    ----->  4379\n",
      "Train Loss: 0.04289996947865961\n",
      "-----------EPOCH-----------    ----->  4380\n",
      "Train Loss: 0.04289956588352267\n",
      "-----------EPOCH-----------    ----->  4381\n",
      "Train Loss: 0.04289916103508871\n",
      "-----------EPOCH-----------    ----->  4382\n",
      "Train Loss: 0.04289875560963461\n",
      "-----------EPOCH-----------    ----->  4383\n",
      "Train Loss: 0.042898350178404154\n",
      "-----------EPOCH-----------    ----->  4384\n",
      "Train Loss: 0.04289794418803281\n",
      "-----------EPOCH-----------    ----->  4385\n",
      "Train Loss: 0.042897537958584024\n",
      "-----------EPOCH-----------    ----->  4386\n",
      "Train Loss: 0.042897131859468966\n",
      "-----------EPOCH-----------    ----->  4387\n",
      "Train Loss: 0.04289672581133774\n",
      "-----------EPOCH-----------    ----->  4388\n",
      "Train Loss: 0.042896319925034176\n",
      "-----------EPOCH-----------    ----->  4389\n",
      "Train Loss: 0.04289591465291216\n",
      "-----------EPOCH-----------    ----->  4390\n",
      "Train Loss: 0.04289550987494111\n",
      "-----------EPOCH-----------    ----->  4391\n",
      "Train Loss: 0.04289510627523777\n",
      "-----------EPOCH-----------    ----->  4392\n",
      "Train Loss: 0.04289470263640725\n",
      "-----------EPOCH-----------    ----->  4393\n",
      "Train Loss: 0.042894298674244255\n",
      "-----------EPOCH-----------    ----->  4394\n",
      "Train Loss: 0.04289389608659216\n",
      "-----------EPOCH-----------    ----->  4395\n",
      "Train Loss: 0.04289349393517288\n",
      "-----------EPOCH-----------    ----->  4396\n",
      "Train Loss: 0.04289309286410393\n",
      "-----------EPOCH-----------    ----->  4397\n",
      "Train Loss: 0.042892692425222693\n",
      "-----------EPOCH-----------    ----->  4398\n",
      "Train Loss: 0.04289229193178616\n",
      "-----------EPOCH-----------    ----->  4399\n",
      "Train Loss: 0.0428918915041286\n",
      "-----------EPOCH-----------    ----->  4400\n",
      "Train Loss: 0.04289149132013379\n",
      "-----------EPOCH-----------    ----->  4401\n",
      "Train Loss: 0.04289109136139407\n",
      "-----------EPOCH-----------    ----->  4402\n",
      "Train Loss: 0.04289069089758236\n",
      "-----------EPOCH-----------    ----->  4403\n",
      "Train Loss: 0.042890290170401024\n",
      "-----------EPOCH-----------    ----->  4404\n",
      "Train Loss: 0.042889889288896255\n",
      "-----------EPOCH-----------    ----->  4405\n",
      "Train Loss: 0.0428894888173769\n",
      "-----------EPOCH-----------    ----->  4406\n",
      "Train Loss: 0.04288908807940547\n",
      "-----------EPOCH-----------    ----->  4407\n",
      "Train Loss: 0.04288868709963548\n",
      "-----------EPOCH-----------    ----->  4408\n",
      "Train Loss: 0.042888286243877895\n",
      "-----------EPOCH-----------    ----->  4409\n",
      "Train Loss: 0.04288788399319278\n",
      "-----------EPOCH-----------    ----->  4410\n",
      "Train Loss: 0.042887482008341186\n",
      "-----------EPOCH-----------    ----->  4411\n",
      "Train Loss: 0.04288708048883315\n",
      "-----------EPOCH-----------    ----->  4412\n",
      "Train Loss: 0.042886679060570566\n",
      "-----------EPOCH-----------    ----->  4413\n",
      "Train Loss: 0.042886278000004795\n",
      "-----------EPOCH-----------    ----->  4414\n",
      "Train Loss: 0.042885877464929105\n",
      "-----------EPOCH-----------    ----->  4415\n",
      "Train Loss: 0.04288547736768116\n",
      "-----------EPOCH-----------    ----->  4416\n",
      "Train Loss: 0.042885077583542264\n",
      "-----------EPOCH-----------    ----->  4417\n",
      "Train Loss: 0.042884677924088226\n",
      "-----------EPOCH-----------    ----->  4418\n",
      "Train Loss: 0.042884278710349555\n",
      "-----------EPOCH-----------    ----->  4419\n",
      "Train Loss: 0.04288387935940669\n",
      "-----------EPOCH-----------    ----->  4420\n",
      "Train Loss: 0.04288347893085894\n",
      "-----------EPOCH-----------    ----->  4421\n",
      "Train Loss: 0.042883078797267375\n",
      "-----------EPOCH-----------    ----->  4422\n",
      "Train Loss: 0.04288267874963112\n",
      "-----------EPOCH-----------    ----->  4423\n",
      "Train Loss: 0.042882278661966984\n",
      "-----------EPOCH-----------    ----->  4424\n",
      "Train Loss: 0.04288187852053836\n",
      "-----------EPOCH-----------    ----->  4425\n",
      "Train Loss: 0.04288147892117119\n",
      "-----------EPOCH-----------    ----->  4426\n",
      "Train Loss: 0.04288107947411671\n",
      "-----------EPOCH-----------    ----->  4427\n",
      "Train Loss: 0.04288068033673229\n",
      "-----------EPOCH-----------    ----->  4428\n",
      "Train Loss: 0.04288028158667783\n",
      "-----------EPOCH-----------    ----->  4429\n",
      "Train Loss: 0.042879882400075536\n",
      "-----------EPOCH-----------    ----->  4430\n",
      "Train Loss: 0.04287948197038179\n",
      "-----------EPOCH-----------    ----->  4431\n",
      "Train Loss: 0.042879081269682574\n",
      "-----------EPOCH-----------    ----->  4432\n",
      "Train Loss: 0.04287868046779525\n",
      "-----------EPOCH-----------    ----->  4433\n",
      "Train Loss: 0.04287827985061129\n",
      "-----------EPOCH-----------    ----->  4434\n",
      "Train Loss: 0.042877879723924185\n",
      "-----------EPOCH-----------    ----->  4435\n",
      "Train Loss: 0.042877479831786205\n",
      "-----------EPOCH-----------    ----->  4436\n",
      "Train Loss: 0.042877079800102434\n",
      "-----------EPOCH-----------    ----->  4437\n",
      "Train Loss: 0.042876679829844264\n",
      "-----------EPOCH-----------    ----->  4438\n",
      "Train Loss: 0.04287628012244929\n",
      "-----------EPOCH-----------    ----->  4439\n",
      "Train Loss: 0.042875881226074344\n",
      "-----------EPOCH-----------    ----->  4440\n",
      "Train Loss: 0.04287548286787218\n",
      "-----------EPOCH-----------    ----->  4441\n",
      "Train Loss: 0.04287508498188134\n",
      "-----------EPOCH-----------    ----->  4442\n",
      "Train Loss: 0.04287468746768254\n",
      "-----------EPOCH-----------    ----->  4443\n",
      "Train Loss: 0.04287428993379911\n",
      "-----------EPOCH-----------    ----->  4444\n",
      "Train Loss: 0.04287389244196638\n",
      "-----------EPOCH-----------    ----->  4445\n",
      "Train Loss: 0.04287349510323021\n",
      "-----------EPOCH-----------    ----->  4446\n",
      "Train Loss: 0.042873097913813496\n",
      "-----------EPOCH-----------    ----->  4447\n",
      "Train Loss: 0.04287270139464397\n",
      "-----------EPOCH-----------    ----->  4448\n",
      "Train Loss: 0.042872305048391575\n",
      "-----------EPOCH-----------    ----->  4449\n",
      "Train Loss: 0.042871908488747924\n",
      "-----------EPOCH-----------    ----->  4450\n",
      "Train Loss: 0.04287151223707049\n",
      "-----------EPOCH-----------    ----->  4451\n",
      "Train Loss: 0.04287111544644119\n",
      "-----------EPOCH-----------    ----->  4452\n",
      "Train Loss: 0.04287071835639791\n",
      "-----------EPOCH-----------    ----->  4453\n",
      "Train Loss: 0.042870321042796165\n",
      "-----------EPOCH-----------    ----->  4454\n",
      "Train Loss: 0.04286992371678175\n",
      "-----------EPOCH-----------    ----->  4455\n",
      "Train Loss: 0.04286952668092938\n",
      "-----------EPOCH-----------    ----->  4456\n",
      "Train Loss: 0.04286913000493644\n",
      "-----------EPOCH-----------    ----->  4457\n",
      "Train Loss: 0.042868733812494314\n",
      "-----------EPOCH-----------    ----->  4458\n",
      "Train Loss: 0.04286833807045747\n",
      "-----------EPOCH-----------    ----->  4459\n",
      "Train Loss: 0.04286794277048052\n",
      "-----------EPOCH-----------    ----->  4460\n",
      "Train Loss: 0.042867547152872096\n",
      "-----------EPOCH-----------    ----->  4461\n",
      "Train Loss: 0.04286715133277616\n",
      "-----------EPOCH-----------    ----->  4462\n",
      "Train Loss: 0.042866755433242504\n",
      "-----------EPOCH-----------    ----->  4463\n",
      "Train Loss: 0.042866357405654656\n",
      "-----------EPOCH-----------    ----->  4464\n",
      "Train Loss: 0.042865959793377977\n",
      "-----------EPOCH-----------    ----->  4465\n",
      "Train Loss: 0.04286556221592518\n",
      "-----------EPOCH-----------    ----->  4466\n",
      "Train Loss: 0.042865164859879276\n",
      "-----------EPOCH-----------    ----->  4467\n",
      "Train Loss: 0.04286476785494196\n",
      "-----------EPOCH-----------    ----->  4468\n",
      "Train Loss: 0.042864370900432484\n",
      "-----------EPOCH-----------    ----->  4469\n",
      "Train Loss: 0.04286397419291541\n",
      "-----------EPOCH-----------    ----->  4470\n",
      "Train Loss: 0.042863577999863255\n",
      "-----------EPOCH-----------    ----->  4471\n",
      "Train Loss: 0.04286318201617191\n",
      "-----------EPOCH-----------    ----->  4472\n",
      "Train Loss: 0.04286278597645289\n",
      "-----------EPOCH-----------    ----->  4473\n",
      "Train Loss: 0.042862389723177796\n",
      "-----------EPOCH-----------    ----->  4474\n",
      "Train Loss: 0.04286199373205391\n",
      "-----------EPOCH-----------    ----->  4475\n",
      "Train Loss: 0.0428615980924848\n",
      "-----------EPOCH-----------    ----->  4476\n",
      "Train Loss: 0.04286120266855299\n",
      "-----------EPOCH-----------    ----->  4477\n",
      "Train Loss: 0.04286080793034225\n",
      "-----------EPOCH-----------    ----->  4478\n",
      "Train Loss: 0.042860413723716385\n",
      "-----------EPOCH-----------    ----->  4479\n",
      "Train Loss: 0.04286002016721993\n",
      "-----------EPOCH-----------    ----->  4480\n",
      "Train Loss: 0.04285962682780077\n",
      "-----------EPOCH-----------    ----->  4481\n",
      "Train Loss: 0.042859233912235596\n",
      "-----------EPOCH-----------    ----->  4482\n",
      "Train Loss: 0.042858841038185866\n",
      "-----------EPOCH-----------    ----->  4483\n",
      "Train Loss: 0.0428584482611271\n",
      "-----------EPOCH-----------    ----->  4484\n",
      "Train Loss: 0.04285805569678441\n",
      "-----------EPOCH-----------    ----->  4485\n",
      "Train Loss: 0.04285766408515145\n",
      "-----------EPOCH-----------    ----->  4486\n",
      "Train Loss: 0.04285727228835846\n",
      "-----------EPOCH-----------    ----->  4487\n",
      "Train Loss: 0.04285688069337872\n",
      "-----------EPOCH-----------    ----->  4488\n",
      "Train Loss: 0.042856489549660974\n",
      "-----------EPOCH-----------    ----->  4489\n",
      "Train Loss: 0.042856098798596656\n",
      "-----------EPOCH-----------    ----->  4490\n",
      "Train Loss: 0.04285570912610308\n",
      "-----------EPOCH-----------    ----->  4491\n",
      "Train Loss: 0.04285531957171296\n",
      "-----------EPOCH-----------    ----->  4492\n",
      "Train Loss: 0.04285493018639398\n",
      "-----------EPOCH-----------    ----->  4493\n",
      "Train Loss: 0.04285454050865156\n",
      "-----------EPOCH-----------    ----->  4494\n",
      "Train Loss: 0.04285415077679196\n",
      "-----------EPOCH-----------    ----->  4495\n",
      "Train Loss: 0.042853761305084205\n",
      "-----------EPOCH-----------    ----->  4496\n",
      "Train Loss: 0.042853371305925696\n",
      "-----------EPOCH-----------    ----->  4497\n",
      "Train Loss: 0.04285298186101281\n",
      "-----------EPOCH-----------    ----->  4498\n",
      "Train Loss: 0.04285259317220653\n",
      "-----------EPOCH-----------    ----->  4499\n",
      "Train Loss: 0.042852204307767434\n",
      "-----------EPOCH-----------    ----->  4500\n",
      "Train Loss: 0.04285181526468253\n",
      "-----------EPOCH-----------    ----->  4501\n",
      "Train Loss: 0.04285142553771057\n",
      "-----------EPOCH-----------    ----->  4502\n",
      "Train Loss: 0.04285103628859128\n",
      "-----------EPOCH-----------    ----->  4503\n",
      "Train Loss: 0.0428506471889182\n",
      "-----------EPOCH-----------    ----->  4504\n",
      "Train Loss: 0.042850258233330774\n",
      "-----------EPOCH-----------    ----->  4505\n",
      "Train Loss: 0.042849869392057496\n",
      "-----------EPOCH-----------    ----->  4506\n",
      "Train Loss: 0.04284948048804195\n",
      "-----------EPOCH-----------    ----->  4507\n",
      "Train Loss: 0.04284909214426352\n",
      "-----------EPOCH-----------    ----->  4508\n",
      "Train Loss: 0.04284870428667274\n",
      "-----------EPOCH-----------    ----->  4509\n",
      "Train Loss: 0.042848316472467896\n",
      "-----------EPOCH-----------    ----->  4510\n",
      "Train Loss: 0.042847928139824305\n",
      "-----------EPOCH-----------    ----->  4511\n",
      "Train Loss: 0.04284753910557885\n",
      "-----------EPOCH-----------    ----->  4512\n",
      "Train Loss: 0.04284715042687026\n",
      "-----------EPOCH-----------    ----->  4513\n",
      "Train Loss: 0.042846761947438736\n",
      "-----------EPOCH-----------    ----->  4514\n",
      "Train Loss: 0.042846373406873056\n",
      "-----------EPOCH-----------    ----->  4515\n",
      "Train Loss: 0.042845984672460924\n",
      "-----------EPOCH-----------    ----->  4516\n",
      "Train Loss: 0.04284559570866017\n",
      "-----------EPOCH-----------    ----->  4517\n",
      "Train Loss: 0.0428452059872699\n",
      "-----------EPOCH-----------    ----->  4518\n",
      "Train Loss: 0.042844816624679476\n",
      "-----------EPOCH-----------    ----->  4519\n",
      "Train Loss: 0.04284442739887143\n",
      "-----------EPOCH-----------    ----->  4520\n",
      "Train Loss: 0.042844037364628565\n",
      "-----------EPOCH-----------    ----->  4521\n",
      "Train Loss: 0.042843647841656396\n",
      "-----------EPOCH-----------    ----->  4522\n",
      "Train Loss: 0.042843258173278644\n",
      "-----------EPOCH-----------    ----->  4523\n",
      "Train Loss: 0.04284286884193513\n",
      "-----------EPOCH-----------    ----->  4524\n",
      "Train Loss: 0.042842480143727116\n",
      "-----------EPOCH-----------    ----->  4525\n",
      "Train Loss: 0.042842092176175746\n",
      "-----------EPOCH-----------    ----->  4526\n",
      "Train Loss: 0.04284170418667914\n",
      "-----------EPOCH-----------    ----->  4527\n",
      "Train Loss: 0.0428413155000992\n",
      "-----------EPOCH-----------    ----->  4528\n",
      "Train Loss: 0.04284092649606034\n",
      "-----------EPOCH-----------    ----->  4529\n",
      "Train Loss: 0.0428405378956275\n",
      "-----------EPOCH-----------    ----->  4530\n",
      "Train Loss: 0.04284014949478691\n",
      "-----------EPOCH-----------    ----->  4531\n",
      "Train Loss: 0.04283976128960596\n",
      "-----------EPOCH-----------    ----->  4532\n",
      "Train Loss: 0.04283937350525546\n",
      "-----------EPOCH-----------    ----->  4533\n",
      "Train Loss: 0.04283898581169653\n",
      "-----------EPOCH-----------    ----->  4534\n",
      "Train Loss: 0.042838598875916414\n",
      "-----------EPOCH-----------    ----->  4535\n",
      "Train Loss: 0.042838212441944995\n",
      "-----------EPOCH-----------    ----->  4536\n",
      "Train Loss: 0.04283782476945959\n",
      "-----------EPOCH-----------    ----->  4537\n",
      "Train Loss: 0.042837437474767655\n",
      "-----------EPOCH-----------    ----->  4538\n",
      "Train Loss: 0.04283705061972692\n",
      "-----------EPOCH-----------    ----->  4539\n",
      "Train Loss: 0.04283666401124471\n",
      "-----------EPOCH-----------    ----->  4540\n",
      "Train Loss: 0.04283627789920698\n",
      "-----------EPOCH-----------    ----->  4541\n",
      "Train Loss: 0.04283589309381555\n",
      "-----------EPOCH-----------    ----->  4542\n",
      "Train Loss: 0.04283550813306094\n",
      "-----------EPOCH-----------    ----->  4543\n",
      "Train Loss: 0.04283512333713657\n",
      "-----------EPOCH-----------    ----->  4544\n",
      "Train Loss: 0.042834738488161245\n",
      "-----------EPOCH-----------    ----->  4545\n",
      "Train Loss: 0.04283435373984664\n",
      "-----------EPOCH-----------    ----->  4546\n",
      "Train Loss: 0.04283396881757793\n",
      "-----------EPOCH-----------    ----->  4547\n",
      "Train Loss: 0.04283358444456942\n",
      "-----------EPOCH-----------    ----->  4548\n",
      "Train Loss: 0.04283319826070475\n",
      "-----------EPOCH-----------    ----->  4549\n",
      "Train Loss: 0.042832812579765615\n",
      "-----------EPOCH-----------    ----->  4550\n",
      "Train Loss: 0.04283242726260422\n",
      "-----------EPOCH-----------    ----->  4551\n",
      "Train Loss: 0.04283204224100183\n",
      "-----------EPOCH-----------    ----->  4552\n",
      "Train Loss: 0.042831657330631094\n",
      "-----------EPOCH-----------    ----->  4553\n",
      "Train Loss: 0.04283127292177229\n",
      "-----------EPOCH-----------    ----->  4554\n",
      "Train Loss: 0.04283088928166562\n",
      "-----------EPOCH-----------    ----->  4555\n",
      "Train Loss: 0.04283050553596578\n",
      "-----------EPOCH-----------    ----->  4556\n",
      "Train Loss: 0.04283012193778591\n",
      "-----------EPOCH-----------    ----->  4557\n",
      "Train Loss: 0.042829738577173024\n",
      "-----------EPOCH-----------    ----->  4558\n",
      "Train Loss: 0.04282935550887725\n",
      "-----------EPOCH-----------    ----->  4559\n",
      "Train Loss: 0.042828972939587415\n",
      "-----------EPOCH-----------    ----->  4560\n",
      "Train Loss: 0.04282859001653346\n",
      "-----------EPOCH-----------    ----->  4561\n",
      "Train Loss: 0.04282820685934457\n",
      "-----------EPOCH-----------    ----->  4562\n",
      "Train Loss: 0.042827823908413644\n",
      "-----------EPOCH-----------    ----->  4563\n",
      "Train Loss: 0.042827440942550636\n",
      "-----------EPOCH-----------    ----->  4564\n",
      "Train Loss: 0.04282705817303873\n",
      "-----------EPOCH-----------    ----->  4565\n",
      "Train Loss: 0.04282667538179057\n",
      "-----------EPOCH-----------    ----->  4566\n",
      "Train Loss: 0.042826292687085356\n",
      "-----------EPOCH-----------    ----->  4567\n",
      "Train Loss: 0.04282591024392709\n",
      "-----------EPOCH-----------    ----->  4568\n",
      "Train Loss: 0.042825528782925636\n",
      "-----------EPOCH-----------    ----->  4569\n",
      "Train Loss: 0.04282514706338569\n",
      "-----------EPOCH-----------    ----->  4570\n",
      "Train Loss: 0.042824765233345365\n",
      "-----------EPOCH-----------    ----->  4571\n",
      "Train Loss: 0.04282438366992888\n",
      "-----------EPOCH-----------    ----->  4572\n",
      "Train Loss: 0.04282400239018548\n",
      "-----------EPOCH-----------    ----->  4573\n",
      "Train Loss: 0.04282362157814272\n",
      "-----------EPOCH-----------    ----->  4574\n",
      "Train Loss: 0.04282324171293493\n",
      "-----------EPOCH-----------    ----->  4575\n",
      "Train Loss: 0.04282286173474438\n",
      "-----------EPOCH-----------    ----->  4576\n",
      "Train Loss: 0.04282248195650653\n",
      "-----------EPOCH-----------    ----->  4577\n",
      "Train Loss: 0.042822102425849246\n",
      "-----------EPOCH-----------    ----->  4578\n",
      "Train Loss: 0.04282172240426165\n",
      "-----------EPOCH-----------    ----->  4579\n",
      "Train Loss: 0.04282134284104079\n",
      "-----------EPOCH-----------    ----->  4580\n",
      "Train Loss: 0.04282096373661104\n",
      "-----------EPOCH-----------    ----->  4581\n",
      "Train Loss: 0.042820584253282355\n",
      "-----------EPOCH-----------    ----->  4582\n",
      "Train Loss: 0.04282020503279674\n",
      "-----------EPOCH-----------    ----->  4583\n",
      "Train Loss: 0.04281982605627189\n",
      "-----------EPOCH-----------    ----->  4584\n",
      "Train Loss: 0.04281944719675124\n",
      "-----------EPOCH-----------    ----->  4585\n",
      "Train Loss: 0.04281906835093537\n",
      "-----------EPOCH-----------    ----->  4586\n",
      "Train Loss: 0.042818689644391165\n",
      "-----------EPOCH-----------    ----->  4587\n",
      "Train Loss: 0.042818310816910114\n",
      "-----------EPOCH-----------    ----->  4588\n",
      "Train Loss: 0.042817930770735355\n",
      "-----------EPOCH-----------    ----->  4589\n",
      "Train Loss: 0.04281755130787291\n",
      "-----------EPOCH-----------    ----->  4590\n",
      "Train Loss: 0.04281717239158575\n",
      "-----------EPOCH-----------    ----->  4591\n",
      "Train Loss: 0.04281679268638595\n",
      "-----------EPOCH-----------    ----->  4592\n",
      "Train Loss: 0.042816413370441564\n",
      "-----------EPOCH-----------    ----->  4593\n",
      "Train Loss: 0.04281603450973319\n",
      "-----------EPOCH-----------    ----->  4594\n",
      "Train Loss: 0.04281565524144271\n",
      "-----------EPOCH-----------    ----->  4595\n",
      "Train Loss: 0.0428152765793451\n",
      "-----------EPOCH-----------    ----->  4596\n",
      "Train Loss: 0.04281489808454158\n",
      "-----------EPOCH-----------    ----->  4597\n",
      "Train Loss: 0.042814519033890386\n",
      "-----------EPOCH-----------    ----->  4598\n",
      "Train Loss: 0.042814139923625115\n",
      "-----------EPOCH-----------    ----->  4599\n",
      "Train Loss: 0.04281376150743412\n",
      "-----------EPOCH-----------    ----->  4600\n",
      "Train Loss: 0.04281338326087258\n",
      "-----------EPOCH-----------    ----->  4601\n",
      "Train Loss: 0.042813005637763704\n",
      "-----------EPOCH-----------    ----->  4602\n",
      "Train Loss: 0.042812628677709005\n",
      "-----------EPOCH-----------    ----->  4603\n",
      "Train Loss: 0.04281225193083293\n",
      "-----------EPOCH-----------    ----->  4604\n",
      "Train Loss: 0.0428118726442787\n",
      "-----------EPOCH-----------    ----->  4605\n",
      "Train Loss: 0.04281149340488443\n",
      "-----------EPOCH-----------    ----->  4606\n",
      "Train Loss: 0.04281111415491567\n",
      "-----------EPOCH-----------    ----->  4607\n",
      "Train Loss: 0.04281073590708138\n",
      "-----------EPOCH-----------    ----->  4608\n",
      "Train Loss: 0.04281035771816993\n",
      "-----------EPOCH-----------    ----->  4609\n",
      "Train Loss: 0.042809980164008776\n",
      "-----------EPOCH-----------    ----->  4610\n",
      "Train Loss: 0.042809603459161696\n",
      "-----------EPOCH-----------    ----->  4611\n",
      "Train Loss: 0.04280922664267533\n",
      "-----------EPOCH-----------    ----->  4612\n",
      "Train Loss: 0.042808850654221804\n",
      "-----------EPOCH-----------    ----->  4613\n",
      "Train Loss: 0.04280847479317246\n",
      "-----------EPOCH-----------    ----->  4614\n",
      "Train Loss: 0.0428080986531558\n",
      "-----------EPOCH-----------    ----->  4615\n",
      "Train Loss: 0.04280772293425663\n",
      "-----------EPOCH-----------    ----->  4616\n",
      "Train Loss: 0.042807347255139426\n",
      "-----------EPOCH-----------    ----->  4617\n",
      "Train Loss: 0.042806971711991534\n",
      "-----------EPOCH-----------    ----->  4618\n",
      "Train Loss: 0.04280659675902998\n",
      "-----------EPOCH-----------    ----->  4619\n",
      "Train Loss: 0.042806221950751754\n",
      "-----------EPOCH-----------    ----->  4620\n",
      "Train Loss: 0.042805846827970014\n",
      "-----------EPOCH-----------    ----->  4621\n",
      "Train Loss: 0.04280547200641344\n",
      "-----------EPOCH-----------    ----->  4622\n",
      "Train Loss: 0.04280509672254118\n",
      "-----------EPOCH-----------    ----->  4623\n",
      "Train Loss: 0.042804722077949844\n",
      "-----------EPOCH-----------    ----->  4624\n",
      "Train Loss: 0.04280434714355886\n",
      "-----------EPOCH-----------    ----->  4625\n",
      "Train Loss: 0.042803972647307016\n",
      "-----------EPOCH-----------    ----->  4626\n",
      "Train Loss: 0.04280359832900658\n",
      "-----------EPOCH-----------    ----->  4627\n",
      "Train Loss: 0.042803223837154764\n",
      "-----------EPOCH-----------    ----->  4628\n",
      "Train Loss: 0.04280285029549097\n",
      "-----------EPOCH-----------    ----->  4629\n",
      "Train Loss: 0.04280247703341591\n",
      "-----------EPOCH-----------    ----->  4630\n",
      "Train Loss: 0.04280210538965947\n",
      "-----------EPOCH-----------    ----->  4631\n",
      "Train Loss: 0.04280173323357984\n",
      "-----------EPOCH-----------    ----->  4632\n",
      "Train Loss: 0.042801361022100505\n",
      "-----------EPOCH-----------    ----->  4633\n",
      "Train Loss: 0.04280098936571658\n",
      "-----------EPOCH-----------    ----->  4634\n",
      "Train Loss: 0.04280061755360681\n",
      "-----------EPOCH-----------    ----->  4635\n",
      "Train Loss: 0.042800246323737925\n",
      "-----------EPOCH-----------    ----->  4636\n",
      "Train Loss: 0.042799874999460016\n",
      "-----------EPOCH-----------    ----->  4637\n",
      "Train Loss: 0.04279950407439629\n",
      "-----------EPOCH-----------    ----->  4638\n",
      "Train Loss: 0.04279913370479204\n",
      "-----------EPOCH-----------    ----->  4639\n",
      "Train Loss: 0.04279876278222649\n",
      "-----------EPOCH-----------    ----->  4640\n",
      "Train Loss: 0.04279839212991391\n",
      "-----------EPOCH-----------    ----->  4641\n",
      "Train Loss: 0.042798020936558163\n",
      "-----------EPOCH-----------    ----->  4642\n",
      "Train Loss: 0.04279764995905461\n",
      "-----------EPOCH-----------    ----->  4643\n",
      "Train Loss: 0.04279727849503599\n",
      "-----------EPOCH-----------    ----->  4644\n",
      "Train Loss: 0.042796906688936924\n",
      "-----------EPOCH-----------    ----->  4645\n",
      "Train Loss: 0.04279653556191463\n",
      "-----------EPOCH-----------    ----->  4646\n",
      "Train Loss: 0.04279616435712797\n",
      "-----------EPOCH-----------    ----->  4647\n",
      "Train Loss: 0.04279579382036429\n",
      "-----------EPOCH-----------    ----->  4648\n",
      "Train Loss: 0.042795422736674325\n",
      "-----------EPOCH-----------    ----->  4649\n",
      "Train Loss: 0.042795052486877434\n",
      "-----------EPOCH-----------    ----->  4650\n",
      "Train Loss: 0.04279468197548762\n",
      "-----------EPOCH-----------    ----->  4651\n",
      "Train Loss: 0.04279431211180551\n",
      "-----------EPOCH-----------    ----->  4652\n",
      "Train Loss: 0.04279394197051053\n",
      "-----------EPOCH-----------    ----->  4653\n",
      "Train Loss: 0.042793572355067366\n",
      "-----------EPOCH-----------    ----->  4654\n",
      "Train Loss: 0.04279320329322804\n",
      "-----------EPOCH-----------    ----->  4655\n",
      "Train Loss: 0.0427928340920109\n",
      "-----------EPOCH-----------    ----->  4656\n",
      "Train Loss: 0.042792465454820024\n",
      "-----------EPOCH-----------    ----->  4657\n",
      "Train Loss: 0.04279209641007754\n",
      "-----------EPOCH-----------    ----->  4658\n",
      "Train Loss: 0.042791728318644154\n",
      "-----------EPOCH-----------    ----->  4659\n",
      "Train Loss: 0.04279136030673108\n",
      "-----------EPOCH-----------    ----->  4660\n",
      "Train Loss: 0.042790993029548946\n",
      "-----------EPOCH-----------    ----->  4661\n",
      "Train Loss: 0.042790626233333705\n",
      "-----------EPOCH-----------    ----->  4662\n",
      "Train Loss: 0.04279026018113277\n",
      "-----------EPOCH-----------    ----->  4663\n",
      "Train Loss: 0.0427898939630002\n",
      "-----------EPOCH-----------    ----->  4664\n",
      "Train Loss: 0.04278952856478635\n",
      "-----------EPOCH-----------    ----->  4665\n",
      "Train Loss: 0.04278916377932824\n",
      "-----------EPOCH-----------    ----->  4666\n",
      "Train Loss: 0.04278879863317884\n",
      "-----------EPOCH-----------    ----->  4667\n",
      "Train Loss: 0.04278843407155949\n",
      "-----------EPOCH-----------    ----->  4668\n",
      "Train Loss: 0.042788070085005\n",
      "-----------EPOCH-----------    ----->  4669\n",
      "Train Loss: 0.0427877062834797\n",
      "-----------EPOCH-----------    ----->  4670\n",
      "Train Loss: 0.04278734262697222\n",
      "-----------EPOCH-----------    ----->  4671\n",
      "Train Loss: 0.04278697926518993\n",
      "-----------EPOCH-----------    ----->  4672\n",
      "Train Loss: 0.042786615129117654\n",
      "-----------EPOCH-----------    ----->  4673\n",
      "Train Loss: 0.042786251581904376\n",
      "-----------EPOCH-----------    ----->  4674\n",
      "Train Loss: 0.0427858878174182\n",
      "-----------EPOCH-----------    ----->  4675\n",
      "Train Loss: 0.04278552444729237\n",
      "-----------EPOCH-----------    ----->  4676\n",
      "Train Loss: 0.042785160885305006\n",
      "-----------EPOCH-----------    ----->  4677\n",
      "Train Loss: 0.042784797967222406\n",
      "-----------EPOCH-----------    ----->  4678\n",
      "Train Loss: 0.04278443523891954\n",
      "-----------EPOCH-----------    ----->  4679\n",
      "Train Loss: 0.04278407285378116\n",
      "-----------EPOCH-----------    ----->  4680\n",
      "Train Loss: 0.04278371070418086\n",
      "-----------EPOCH-----------    ----->  4681\n",
      "Train Loss: 0.0427833486940019\n",
      "-----------EPOCH-----------    ----->  4682\n",
      "Train Loss: 0.04278298741006491\n",
      "-----------EPOCH-----------    ----->  4683\n",
      "Train Loss: 0.04278262583468125\n",
      "-----------EPOCH-----------    ----->  4684\n",
      "Train Loss: 0.04278226506894574\n",
      "-----------EPOCH-----------    ----->  4685\n",
      "Train Loss: 0.04278190412961549\n",
      "-----------EPOCH-----------    ----->  4686\n",
      "Train Loss: 0.042781543559008185\n",
      "-----------EPOCH-----------    ----->  4687\n",
      "Train Loss: 0.04278118293863736\n",
      "-----------EPOCH-----------    ----->  4688\n",
      "Train Loss: 0.04278082249829051\n",
      "-----------EPOCH-----------    ----->  4689\n",
      "Train Loss: 0.04278046213627462\n",
      "-----------EPOCH-----------    ----->  4690\n",
      "Train Loss: 0.04278010230768209\n",
      "-----------EPOCH-----------    ----->  4691\n",
      "Train Loss: 0.04277974304459702\n",
      "-----------EPOCH-----------    ----->  4692\n",
      "Train Loss: 0.042779383292007506\n",
      "-----------EPOCH-----------    ----->  4693\n",
      "Train Loss: 0.04277902407341154\n",
      "-----------EPOCH-----------    ----->  4694\n",
      "Train Loss: 0.0427786650146423\n",
      "-----------EPOCH-----------    ----->  4695\n",
      "Train Loss: 0.042778306538974555\n",
      "-----------EPOCH-----------    ----->  4696\n",
      "Train Loss: 0.042777947848149145\n",
      "-----------EPOCH-----------    ----->  4697\n",
      "Train Loss: 0.042777590108059864\n",
      "-----------EPOCH-----------    ----->  4698\n",
      "Train Loss: 0.04277723183349833\n",
      "-----------EPOCH-----------    ----->  4699\n",
      "Train Loss: 0.042776873799893665\n",
      "-----------EPOCH-----------    ----->  4700\n",
      "Train Loss: 0.04277651507376134\n",
      "-----------EPOCH-----------    ----->  4701\n",
      "Train Loss: 0.04277615702726368\n",
      "-----------EPOCH-----------    ----->  4702\n",
      "Train Loss: 0.042775798888677\n",
      "-----------EPOCH-----------    ----->  4703\n",
      "Train Loss: 0.042775440883009525\n",
      "-----------EPOCH-----------    ----->  4704\n",
      "Train Loss: 0.04277508272137908\n",
      "-----------EPOCH-----------    ----->  4705\n",
      "Train Loss: 0.04277472468363619\n",
      "-----------EPOCH-----------    ----->  4706\n",
      "Train Loss: 0.04277436659903\n",
      "-----------EPOCH-----------    ----->  4707\n",
      "Train Loss: 0.042774008143033025\n",
      "-----------EPOCH-----------    ----->  4708\n",
      "Train Loss: 0.042773649396392825\n",
      "-----------EPOCH-----------    ----->  4709\n",
      "Train Loss: 0.042773290608249616\n",
      "-----------EPOCH-----------    ----->  4710\n",
      "Train Loss: 0.04277293255585888\n",
      "-----------EPOCH-----------    ----->  4711\n",
      "Train Loss: 0.042772574146159745\n",
      "-----------EPOCH-----------    ----->  4712\n",
      "Train Loss: 0.04277221598465997\n",
      "-----------EPOCH-----------    ----->  4713\n",
      "Train Loss: 0.04277185778410203\n",
      "-----------EPOCH-----------    ----->  4714\n",
      "Train Loss: 0.04277149980806436\n",
      "-----------EPOCH-----------    ----->  4715\n",
      "Train Loss: 0.04277114175229121\n",
      "-----------EPOCH-----------    ----->  4716\n",
      "Train Loss: 0.04277078311683578\n",
      "-----------EPOCH-----------    ----->  4717\n",
      "Train Loss: 0.04277042472393901\n",
      "-----------EPOCH-----------    ----->  4718\n",
      "Train Loss: 0.042770067099273334\n",
      "-----------EPOCH-----------    ----->  4719\n",
      "Train Loss: 0.04276970927484177\n",
      "-----------EPOCH-----------    ----->  4720\n",
      "Train Loss: 0.04276935233627178\n",
      "-----------EPOCH-----------    ----->  4721\n",
      "Train Loss: 0.042768995445502396\n",
      "-----------EPOCH-----------    ----->  4722\n",
      "Train Loss: 0.04276863912145142\n",
      "-----------EPOCH-----------    ----->  4723\n",
      "Train Loss: 0.04276828270603781\n",
      "-----------EPOCH-----------    ----->  4724\n",
      "Train Loss: 0.04276792752928013\n",
      "-----------EPOCH-----------    ----->  4725\n",
      "Train Loss: 0.042767572246196296\n",
      "-----------EPOCH-----------    ----->  4726\n",
      "Train Loss: 0.04276721767609595\n",
      "-----------EPOCH-----------    ----->  4727\n",
      "Train Loss: 0.04276686342742702\n",
      "-----------EPOCH-----------    ----->  4728\n",
      "Train Loss: 0.04276650931013538\n",
      "-----------EPOCH-----------    ----->  4729\n",
      "Train Loss: 0.04276615526005914\n",
      "-----------EPOCH-----------    ----->  4730\n",
      "Train Loss: 0.0427658018486677\n",
      "-----------EPOCH-----------    ----->  4731\n",
      "Train Loss: 0.04276544800193812\n",
      "-----------EPOCH-----------    ----->  4732\n",
      "Train Loss: 0.0427650944420443\n",
      "-----------EPOCH-----------    ----->  4733\n",
      "Train Loss: 0.04276474132050845\n",
      "-----------EPOCH-----------    ----->  4734\n",
      "Train Loss: 0.04276438822229237\n",
      "-----------EPOCH-----------    ----->  4735\n",
      "Train Loss: 0.042764035011698696\n",
      "-----------EPOCH-----------    ----->  4736\n",
      "Train Loss: 0.04276368265641526\n",
      "-----------EPOCH-----------    ----->  4737\n",
      "Train Loss: 0.042763330469551844\n",
      "-----------EPOCH-----------    ----->  4738\n",
      "Train Loss: 0.042762978090062485\n",
      "-----------EPOCH-----------    ----->  4739\n",
      "Train Loss: 0.04276262533099454\n",
      "-----------EPOCH-----------    ----->  4740\n",
      "Train Loss: 0.04276227263012044\n",
      "-----------EPOCH-----------    ----->  4741\n",
      "Train Loss: 0.042761920134105964\n",
      "-----------EPOCH-----------    ----->  4742\n",
      "Train Loss: 0.04276156738457471\n",
      "-----------EPOCH-----------    ----->  4743\n",
      "Train Loss: 0.04276121514888747\n",
      "-----------EPOCH-----------    ----->  4744\n",
      "Train Loss: 0.04276086282120993\n",
      "-----------EPOCH-----------    ----->  4745\n",
      "Train Loss: 0.04276051048581133\n",
      "-----------EPOCH-----------    ----->  4746\n",
      "Train Loss: 0.04276015725089624\n",
      "-----------EPOCH-----------    ----->  4747\n",
      "Train Loss: 0.04275980457677999\n",
      "-----------EPOCH-----------    ----->  4748\n",
      "Train Loss: 0.042759452447163025\n",
      "-----------EPOCH-----------    ----->  4749\n",
      "Train Loss: 0.04275910035930797\n",
      "-----------EPOCH-----------    ----->  4750\n",
      "Train Loss: 0.04275874829828248\n",
      "-----------EPOCH-----------    ----->  4751\n",
      "Train Loss: 0.042758395920504615\n",
      "-----------EPOCH-----------    ----->  4752\n",
      "Train Loss: 0.04275804427821048\n",
      "-----------EPOCH-----------    ----->  4753\n",
      "Train Loss: 0.04275769226209471\n",
      "-----------EPOCH-----------    ----->  4754\n",
      "Train Loss: 0.04275734080424302\n",
      "-----------EPOCH-----------    ----->  4755\n",
      "Train Loss: 0.04275698919258765\n",
      "-----------EPOCH-----------    ----->  4756\n",
      "Train Loss: 0.04275663780588683\n",
      "-----------EPOCH-----------    ----->  4757\n",
      "Train Loss: 0.042756286778615364\n",
      "-----------EPOCH-----------    ----->  4758\n",
      "Train Loss: 0.04275593497603482\n",
      "-----------EPOCH-----------    ----->  4759\n",
      "Train Loss: 0.042755583372867355\n",
      "-----------EPOCH-----------    ----->  4760\n",
      "Train Loss: 0.042755231248115755\n",
      "-----------EPOCH-----------    ----->  4761\n",
      "Train Loss: 0.042754879030957545\n",
      "-----------EPOCH-----------    ----->  4762\n",
      "Train Loss: 0.04275452756393529\n",
      "-----------EPOCH-----------    ----->  4763\n",
      "Train Loss: 0.042754175597230666\n",
      "-----------EPOCH-----------    ----->  4764\n",
      "Train Loss: 0.04275382415183023\n",
      "-----------EPOCH-----------    ----->  4765\n",
      "Train Loss: 0.04275347283664529\n",
      "-----------EPOCH-----------    ----->  4766\n",
      "Train Loss: 0.04275312137206774\n",
      "-----------EPOCH-----------    ----->  4767\n",
      "Train Loss: 0.0427527702599012\n",
      "-----------EPOCH-----------    ----->  4768\n",
      "Train Loss: 0.04275241907035744\n",
      "-----------EPOCH-----------    ----->  4769\n",
      "Train Loss: 0.04275206830106177\n",
      "-----------EPOCH-----------    ----->  4770\n",
      "Train Loss: 0.04275171790703981\n",
      "-----------EPOCH-----------    ----->  4771\n",
      "Train Loss: 0.04275136743697997\n",
      "-----------EPOCH-----------    ----->  4772\n",
      "Train Loss: 0.04275101714317977\n",
      "-----------EPOCH-----------    ----->  4773\n",
      "Train Loss: 0.04275066649775\n",
      "-----------EPOCH-----------    ----->  4774\n",
      "Train Loss: 0.04275031585891839\n",
      "-----------EPOCH-----------    ----->  4775\n",
      "Train Loss: 0.04274996528370366\n",
      "-----------EPOCH-----------    ----->  4776\n",
      "Train Loss: 0.04274961379270031\n",
      "-----------EPOCH-----------    ----->  4777\n",
      "Train Loss: 0.04274926241570901\n",
      "-----------EPOCH-----------    ----->  4778\n",
      "Train Loss: 0.04274891070758472\n",
      "-----------EPOCH-----------    ----->  4779\n",
      "Train Loss: 0.042748559518393216\n",
      "-----------EPOCH-----------    ----->  4780\n",
      "Train Loss: 0.042748207983864736\n",
      "-----------EPOCH-----------    ----->  4781\n",
      "Train Loss: 0.04274785646003575\n",
      "-----------EPOCH-----------    ----->  4782\n",
      "Train Loss: 0.04274750481557224\n",
      "-----------EPOCH-----------    ----->  4783\n",
      "Train Loss: 0.04274715289619405\n",
      "-----------EPOCH-----------    ----->  4784\n",
      "Train Loss: 0.0427468011354513\n",
      "-----------EPOCH-----------    ----->  4785\n",
      "Train Loss: 0.04274644887347323\n",
      "-----------EPOCH-----------    ----->  4786\n",
      "Train Loss: 0.04274609654119733\n",
      "-----------EPOCH-----------    ----->  4787\n",
      "Train Loss: 0.04274574493733351\n",
      "-----------EPOCH-----------    ----->  4788\n",
      "Train Loss: 0.042745393279715015\n",
      "-----------EPOCH-----------    ----->  4789\n",
      "Train Loss: 0.04274504099306269\n",
      "-----------EPOCH-----------    ----->  4790\n",
      "Train Loss: 0.04274468885929462\n",
      "-----------EPOCH-----------    ----->  4791\n",
      "Train Loss: 0.04274433648805541\n",
      "-----------EPOCH-----------    ----->  4792\n",
      "Train Loss: 0.042743985021140206\n",
      "-----------EPOCH-----------    ----->  4793\n",
      "Train Loss: 0.04274363330217644\n",
      "-----------EPOCH-----------    ----->  4794\n",
      "Train Loss: 0.04274328227188636\n",
      "-----------EPOCH-----------    ----->  4795\n",
      "Train Loss: 0.04274293165526406\n",
      "-----------EPOCH-----------    ----->  4796\n",
      "Train Loss: 0.04274258130646594\n",
      "-----------EPOCH-----------    ----->  4797\n",
      "Train Loss: 0.04274223054182919\n",
      "-----------EPOCH-----------    ----->  4798\n",
      "Train Loss: 0.04274187996514032\n",
      "-----------EPOCH-----------    ----->  4799\n",
      "Train Loss: 0.04274152913409414\n",
      "-----------EPOCH-----------    ----->  4800\n",
      "Train Loss: 0.04274117800180996\n",
      "-----------EPOCH-----------    ----->  4801\n",
      "Train Loss: 0.042740827066205925\n",
      "-----------EPOCH-----------    ----->  4802\n",
      "Train Loss: 0.042740475657115\n",
      "-----------EPOCH-----------    ----->  4803\n",
      "Train Loss: 0.042740124056919494\n",
      "-----------EPOCH-----------    ----->  4804\n",
      "Train Loss: 0.04273977273735237\n",
      "-----------EPOCH-----------    ----->  4805\n",
      "Train Loss: 0.0427394216173877\n",
      "-----------EPOCH-----------    ----->  4806\n",
      "Train Loss: 0.042739070475991084\n",
      "-----------EPOCH-----------    ----->  4807\n",
      "Train Loss: 0.04273872001919867\n",
      "-----------EPOCH-----------    ----->  4808\n",
      "Train Loss: 0.04273837008645296\n",
      "-----------EPOCH-----------    ----->  4809\n",
      "Train Loss: 0.042738019523808436\n",
      "-----------EPOCH-----------    ----->  4810\n",
      "Train Loss: 0.04273766964962842\n",
      "-----------EPOCH-----------    ----->  4811\n",
      "Train Loss: 0.042737319843377114\n",
      "-----------EPOCH-----------    ----->  4812\n",
      "Train Loss: 0.04273697015453236\n",
      "-----------EPOCH-----------    ----->  4813\n",
      "Train Loss: 0.042736619617293886\n",
      "-----------EPOCH-----------    ----->  4814\n",
      "Train Loss: 0.0427362694843857\n",
      "-----------EPOCH-----------    ----->  4815\n",
      "Train Loss: 0.04273592000097352\n",
      "-----------EPOCH-----------    ----->  4816\n",
      "Train Loss: 0.042735569900515614\n",
      "-----------EPOCH-----------    ----->  4817\n",
      "Train Loss: 0.042735220309785764\n",
      "-----------EPOCH-----------    ----->  4818\n",
      "Train Loss: 0.04273487121498676\n",
      "-----------EPOCH-----------    ----->  4819\n",
      "Train Loss: 0.04273452107556879\n",
      "-----------EPOCH-----------    ----->  4820\n",
      "Train Loss: 0.04273417115219192\n",
      "-----------EPOCH-----------    ----->  4821\n",
      "Train Loss: 0.042733821434458516\n",
      "-----------EPOCH-----------    ----->  4822\n",
      "Train Loss: 0.042733471685171304\n",
      "-----------EPOCH-----------    ----->  4823\n",
      "Train Loss: 0.04273312228414451\n",
      "-----------EPOCH-----------    ----->  4824\n",
      "Train Loss: 0.04273277360321351\n",
      "-----------EPOCH-----------    ----->  4825\n",
      "Train Loss: 0.042732424919199645\n",
      "-----------EPOCH-----------    ----->  4826\n",
      "Train Loss: 0.042732076971158425\n",
      "-----------EPOCH-----------    ----->  4827\n",
      "Train Loss: 0.04273172896180658\n",
      "-----------EPOCH-----------    ----->  4828\n",
      "Train Loss: 0.04273138079040002\n",
      "-----------EPOCH-----------    ----->  4829\n",
      "Train Loss: 0.042731032995040975\n",
      "-----------EPOCH-----------    ----->  4830\n",
      "Train Loss: 0.04273068521513747\n",
      "-----------EPOCH-----------    ----->  4831\n",
      "Train Loss: 0.04273033680892567\n",
      "-----------EPOCH-----------    ----->  4832\n",
      "Train Loss: 0.042729989018587086\n",
      "-----------EPOCH-----------    ----->  4833\n",
      "Train Loss: 0.04272964155095024\n",
      "-----------EPOCH-----------    ----->  4834\n",
      "Train Loss: 0.042729293794578425\n",
      "-----------EPOCH-----------    ----->  4835\n",
      "Train Loss: 0.042728945788069427\n",
      "-----------EPOCH-----------    ----->  4836\n",
      "Train Loss: 0.042728598048995536\n",
      "-----------EPOCH-----------    ----->  4837\n",
      "Train Loss: 0.042728250077078006\n",
      "-----------EPOCH-----------    ----->  4838\n",
      "Train Loss: 0.042727902205332534\n",
      "-----------EPOCH-----------    ----->  4839\n",
      "Train Loss: 0.042727554592399124\n",
      "-----------EPOCH-----------    ----->  4840\n",
      "Train Loss: 0.042727206904110165\n",
      "-----------EPOCH-----------    ----->  4841\n",
      "Train Loss: 0.04272685895851158\n",
      "-----------EPOCH-----------    ----->  4842\n",
      "Train Loss: 0.04272651140984592\n",
      "-----------EPOCH-----------    ----->  4843\n",
      "Train Loss: 0.042726163041347166\n",
      "-----------EPOCH-----------    ----->  4844\n",
      "Train Loss: 0.04272581480831928\n",
      "-----------EPOCH-----------    ----->  4845\n",
      "Train Loss: 0.042725467106595354\n",
      "-----------EPOCH-----------    ----->  4846\n",
      "Train Loss: 0.04272511960308212\n",
      "-----------EPOCH-----------    ----->  4847\n",
      "Train Loss: 0.04272477203698379\n",
      "-----------EPOCH-----------    ----->  4848\n",
      "Train Loss: 0.04272442475066337\n",
      "-----------EPOCH-----------    ----->  4849\n",
      "Train Loss: 0.042724078115990716\n",
      "-----------EPOCH-----------    ----->  4850\n",
      "Train Loss: 0.04272373233980063\n",
      "-----------EPOCH-----------    ----->  4851\n",
      "Train Loss: 0.042723387328332335\n",
      "-----------EPOCH-----------    ----->  4852\n",
      "Train Loss: 0.04272304323211731\n",
      "-----------EPOCH-----------    ----->  4853\n",
      "Train Loss: 0.0427226998724862\n",
      "-----------EPOCH-----------    ----->  4854\n",
      "Train Loss: 0.04272235678692344\n",
      "-----------EPOCH-----------    ----->  4855\n",
      "Train Loss: 0.042722013641653234\n",
      "-----------EPOCH-----------    ----->  4856\n",
      "Train Loss: 0.042721670667066565\n",
      "-----------EPOCH-----------    ----->  4857\n",
      "Train Loss: 0.04272132878883852\n",
      "-----------EPOCH-----------    ----->  4858\n",
      "Train Loss: 0.04272098757396297\n",
      "-----------EPOCH-----------    ----->  4859\n",
      "Train Loss: 0.042720645641224964\n",
      "-----------EPOCH-----------    ----->  4860\n",
      "Train Loss: 0.042720304322610925\n",
      "-----------EPOCH-----------    ----->  4861\n",
      "Train Loss: 0.04271996362132202\n",
      "-----------EPOCH-----------    ----->  4862\n",
      "Train Loss: 0.042719623567518614\n",
      "-----------EPOCH-----------    ----->  4863\n",
      "Train Loss: 0.042719283356126486\n",
      "-----------EPOCH-----------    ----->  4864\n",
      "Train Loss: 0.042718943804669715\n",
      "-----------EPOCH-----------    ----->  4865\n",
      "Train Loss: 0.042718604487358994\n",
      "-----------EPOCH-----------    ----->  4866\n",
      "Train Loss: 0.042718265753234466\n",
      "-----------EPOCH-----------    ----->  4867\n",
      "Train Loss: 0.04271792725153868\n",
      "-----------EPOCH-----------    ----->  4868\n",
      "Train Loss: 0.04271758876793386\n",
      "-----------EPOCH-----------    ----->  4869\n",
      "Train Loss: 0.042717250583422274\n",
      "-----------EPOCH-----------    ----->  4870\n",
      "Train Loss: 0.04271691283778497\n",
      "-----------EPOCH-----------    ----->  4871\n",
      "Train Loss: 0.0427165747334896\n",
      "-----------EPOCH-----------    ----->  4872\n",
      "Train Loss: 0.04271623675592766\n",
      "-----------EPOCH-----------    ----->  4873\n",
      "Train Loss: 0.042715899128783826\n",
      "-----------EPOCH-----------    ----->  4874\n",
      "Train Loss: 0.042715561521339124\n",
      "-----------EPOCH-----------    ----->  4875\n",
      "Train Loss: 0.04271522399323462\n",
      "-----------EPOCH-----------    ----->  4876\n",
      "Train Loss: 0.04271488659283782\n",
      "-----------EPOCH-----------    ----->  4877\n",
      "Train Loss: 0.04271454923108229\n",
      "-----------EPOCH-----------    ----->  4878\n",
      "Train Loss: 0.04271421175710819\n",
      "-----------EPOCH-----------    ----->  4879\n",
      "Train Loss: 0.04271387406711868\n",
      "-----------EPOCH-----------    ----->  4880\n",
      "Train Loss: 0.0427135365315568\n",
      "-----------EPOCH-----------    ----->  4881\n",
      "Train Loss: 0.04271319939196931\n",
      "-----------EPOCH-----------    ----->  4882\n",
      "Train Loss: 0.042712862247739986\n",
      "-----------EPOCH-----------    ----->  4883\n",
      "Train Loss: 0.042712524991832944\n",
      "-----------EPOCH-----------    ----->  4884\n",
      "Train Loss: 0.04271218826719237\n",
      "-----------EPOCH-----------    ----->  4885\n",
      "Train Loss: 0.04271185243253233\n",
      "-----------EPOCH-----------    ----->  4886\n",
      "Train Loss: 0.042711517431745546\n",
      "-----------EPOCH-----------    ----->  4887\n",
      "Train Loss: 0.042711181983498464\n",
      "-----------EPOCH-----------    ----->  4888\n",
      "Train Loss: 0.04271084640081646\n",
      "-----------EPOCH-----------    ----->  4889\n",
      "Train Loss: 0.042710510588117194\n",
      "-----------EPOCH-----------    ----->  4890\n",
      "Train Loss: 0.04271017489877273\n",
      "-----------EPOCH-----------    ----->  4891\n",
      "Train Loss: 0.04270983898922946\n",
      "-----------EPOCH-----------    ----->  4892\n",
      "Train Loss: 0.04270950326596297\n",
      "-----------EPOCH-----------    ----->  4893\n",
      "Train Loss: 0.04270916739893076\n",
      "-----------EPOCH-----------    ----->  4894\n",
      "Train Loss: 0.04270883150064659\n",
      "-----------EPOCH-----------    ----->  4895\n",
      "Train Loss: 0.04270849520692344\n",
      "-----------EPOCH-----------    ----->  4896\n",
      "Train Loss: 0.042708158614364646\n",
      "-----------EPOCH-----------    ----->  4897\n",
      "Train Loss: 0.04270782269307359\n",
      "-----------EPOCH-----------    ----->  4898\n",
      "Train Loss: 0.042707487020355955\n",
      "-----------EPOCH-----------    ----->  4899\n",
      "Train Loss: 0.04270715114218805\n",
      "-----------EPOCH-----------    ----->  4900\n",
      "Train Loss: 0.04270681540195813\n",
      "-----------EPOCH-----------    ----->  4901\n",
      "Train Loss: 0.04270648008671277\n",
      "-----------EPOCH-----------    ----->  4902\n",
      "Train Loss: 0.04270614451640344\n",
      "-----------EPOCH-----------    ----->  4903\n",
      "Train Loss: 0.042705808757779004\n",
      "-----------EPOCH-----------    ----->  4904\n",
      "Train Loss: 0.04270547311351931\n",
      "-----------EPOCH-----------    ----->  4905\n",
      "Train Loss: 0.04270513738793116\n",
      "-----------EPOCH-----------    ----->  4906\n",
      "Train Loss: 0.04270480127174964\n",
      "-----------EPOCH-----------    ----->  4907\n",
      "Train Loss: 0.042704465025747256\n",
      "-----------EPOCH-----------    ----->  4908\n",
      "Train Loss: 0.042704128102141914\n",
      "-----------EPOCH-----------    ----->  4909\n",
      "Train Loss: 0.04270379140842903\n",
      "-----------EPOCH-----------    ----->  4910\n",
      "Train Loss: 0.04270345493784462\n",
      "-----------EPOCH-----------    ----->  4911\n",
      "Train Loss: 0.04270311889760182\n",
      "-----------EPOCH-----------    ----->  4912\n",
      "Train Loss: 0.04270278306674558\n",
      "-----------EPOCH-----------    ----->  4913\n",
      "Train Loss: 0.04270244477863584\n",
      "-----------EPOCH-----------    ----->  4914\n",
      "Train Loss: 0.04270210636227143\n",
      "-----------EPOCH-----------    ----->  4915\n",
      "Train Loss: 0.04270176794094607\n",
      "-----------EPOCH-----------    ----->  4916\n",
      "Train Loss: 0.04270142950210483\n",
      "-----------EPOCH-----------    ----->  4917\n",
      "Train Loss: 0.042701091201630056\n",
      "-----------EPOCH-----------    ----->  4918\n",
      "Train Loss: 0.04270075236049934\n",
      "-----------EPOCH-----------    ----->  4919\n",
      "Train Loss: 0.04270041369781009\n",
      "-----------EPOCH-----------    ----->  4920\n",
      "Train Loss: 0.04270007511136057\n",
      "-----------EPOCH-----------    ----->  4921\n",
      "Train Loss: 0.042699735773680726\n",
      "-----------EPOCH-----------    ----->  4922\n",
      "Train Loss: 0.042699396485975726\n",
      "-----------EPOCH-----------    ----->  4923\n",
      "Train Loss: 0.042699057598299006\n",
      "-----------EPOCH-----------    ----->  4924\n",
      "Train Loss: 0.042698718671932034\n",
      "-----------EPOCH-----------    ----->  4925\n",
      "Train Loss: 0.042698379362545655\n",
      "-----------EPOCH-----------    ----->  4926\n",
      "Train Loss: 0.042698040199451254\n",
      "-----------EPOCH-----------    ----->  4927\n",
      "Train Loss: 0.04269770080935776\n",
      "-----------EPOCH-----------    ----->  4928\n",
      "Train Loss: 0.042697362010270516\n",
      "-----------EPOCH-----------    ----->  4929\n",
      "Train Loss: 0.042697023154307734\n",
      "-----------EPOCH-----------    ----->  4930\n",
      "Train Loss: 0.04269668395805038\n",
      "-----------EPOCH-----------    ----->  4931\n",
      "Train Loss: 0.04269634501807019\n",
      "-----------EPOCH-----------    ----->  4932\n",
      "Train Loss: 0.04269600652009023\n",
      "-----------EPOCH-----------    ----->  4933\n",
      "Train Loss: 0.04269566836736244\n",
      "-----------EPOCH-----------    ----->  4934\n",
      "Train Loss: 0.042695329788093615\n",
      "-----------EPOCH-----------    ----->  4935\n",
      "Train Loss: 0.042694991582282384\n",
      "-----------EPOCH-----------    ----->  4936\n",
      "Train Loss: 0.04269465356125594\n",
      "-----------EPOCH-----------    ----->  4937\n",
      "Train Loss: 0.042694315448837845\n",
      "-----------EPOCH-----------    ----->  4938\n",
      "Train Loss: 0.042693977608252213\n",
      "-----------EPOCH-----------    ----->  4939\n",
      "Train Loss: 0.042693640011617816\n",
      "-----------EPOCH-----------    ----->  4940\n",
      "Train Loss: 0.042693302755274797\n",
      "-----------EPOCH-----------    ----->  4941\n",
      "Train Loss: 0.04269296550704967\n",
      "-----------EPOCH-----------    ----->  4942\n",
      "Train Loss: 0.04269262866207227\n",
      "-----------EPOCH-----------    ----->  4943\n",
      "Train Loss: 0.04269229273974558\n",
      "-----------EPOCH-----------    ----->  4944\n",
      "Train Loss: 0.04269195650587752\n",
      "-----------EPOCH-----------    ----->  4945\n",
      "Train Loss: 0.042691620450342936\n",
      "-----------EPOCH-----------    ----->  4946\n",
      "Train Loss: 0.042691284812391234\n",
      "-----------EPOCH-----------    ----->  4947\n",
      "Train Loss: 0.04269094921906448\n",
      "-----------EPOCH-----------    ----->  4948\n",
      "Train Loss: 0.04269061371907559\n",
      "-----------EPOCH-----------    ----->  4949\n",
      "Train Loss: 0.0426902784066835\n",
      "-----------EPOCH-----------    ----->  4950\n",
      "Train Loss: 0.042689943416617575\n",
      "-----------EPOCH-----------    ----->  4951\n",
      "Train Loss: 0.04268960775651037\n",
      "-----------EPOCH-----------    ----->  4952\n",
      "Train Loss: 0.04268927231748064\n",
      "-----------EPOCH-----------    ----->  4953\n",
      "Train Loss: 0.042688938006156155\n",
      "-----------EPOCH-----------    ----->  4954\n",
      "Train Loss: 0.04268860363136537\n",
      "-----------EPOCH-----------    ----->  4955\n",
      "Train Loss: 0.04268826942465941\n",
      "-----------EPOCH-----------    ----->  4956\n",
      "Train Loss: 0.04268793543086035\n",
      "-----------EPOCH-----------    ----->  4957\n",
      "Train Loss: 0.04268760179469729\n",
      "-----------EPOCH-----------    ----->  4958\n",
      "Train Loss: 0.04268726810588423\n",
      "-----------EPOCH-----------    ----->  4959\n",
      "Train Loss: 0.04268693461402308\n",
      "-----------EPOCH-----------    ----->  4960\n",
      "Train Loss: 0.04268660060216996\n",
      "-----------EPOCH-----------    ----->  4961\n",
      "Train Loss: 0.04268626681989841\n",
      "-----------EPOCH-----------    ----->  4962\n",
      "Train Loss: 0.042685933375678276\n",
      "-----------EPOCH-----------    ----->  4963\n",
      "Train Loss: 0.04268560036303683\n",
      "-----------EPOCH-----------    ----->  4964\n",
      "Train Loss: 0.042685267922343506\n",
      "-----------EPOCH-----------    ----->  4965\n",
      "Train Loss: 0.04268493564121657\n",
      "-----------EPOCH-----------    ----->  4966\n",
      "Train Loss: 0.04268460353530365\n",
      "-----------EPOCH-----------    ----->  4967\n",
      "Train Loss: 0.0426842718390625\n",
      "-----------EPOCH-----------    ----->  4968\n",
      "Train Loss: 0.04268394024959523\n",
      "-----------EPOCH-----------    ----->  4969\n",
      "Train Loss: 0.042683608540184256\n",
      "-----------EPOCH-----------    ----->  4970\n",
      "Train Loss: 0.04268327711534876\n",
      "-----------EPOCH-----------    ----->  4971\n",
      "Train Loss: 0.04268294650781043\n",
      "-----------EPOCH-----------    ----->  4972\n",
      "Train Loss: 0.04268261560806052\n",
      "-----------EPOCH-----------    ----->  4973\n",
      "Train Loss: 0.04268228452608758\n",
      "-----------EPOCH-----------    ----->  4974\n",
      "Train Loss: 0.04268195345999649\n",
      "-----------EPOCH-----------    ----->  4975\n",
      "Train Loss: 0.04268162208740046\n",
      "-----------EPOCH-----------    ----->  4976\n",
      "Train Loss: 0.04268129139659342\n",
      "-----------EPOCH-----------    ----->  4977\n",
      "Train Loss: 0.04268096081985336\n",
      "-----------EPOCH-----------    ----->  4978\n",
      "Train Loss: 0.04268063019111995\n",
      "-----------EPOCH-----------    ----->  4979\n",
      "Train Loss: 0.0426802999363042\n",
      "-----------EPOCH-----------    ----->  4980\n",
      "Train Loss: 0.04267996995290923\n",
      "-----------EPOCH-----------    ----->  4981\n",
      "Train Loss: 0.04267964002180023\n",
      "-----------EPOCH-----------    ----->  4982\n",
      "Train Loss: 0.04267930969791491\n",
      "-----------EPOCH-----------    ----->  4983\n",
      "Train Loss: 0.042678979563516434\n",
      "-----------EPOCH-----------    ----->  4984\n",
      "Train Loss: 0.042678649275952926\n",
      "-----------EPOCH-----------    ----->  4985\n",
      "Train Loss: 0.04267831853035876\n",
      "-----------EPOCH-----------    ----->  4986\n",
      "Train Loss: 0.04267798754707603\n",
      "-----------EPOCH-----------    ----->  4987\n",
      "Train Loss: 0.04267765064498054\n",
      "-----------EPOCH-----------    ----->  4988\n",
      "Train Loss: 0.042677313259407906\n",
      "-----------EPOCH-----------    ----->  4989\n",
      "Train Loss: 0.042676976551456136\n",
      "-----------EPOCH-----------    ----->  4990\n",
      "Train Loss: 0.042676640268538686\n",
      "-----------EPOCH-----------    ----->  4991\n",
      "Train Loss: 0.04267630394113863\n",
      "-----------EPOCH-----------    ----->  4992\n",
      "Train Loss: 0.04267596538459038\n",
      "-----------EPOCH-----------    ----->  4993\n",
      "Train Loss: 0.04267562709984677\n",
      "-----------EPOCH-----------    ----->  4994\n",
      "Train Loss: 0.04267528893724476\n",
      "-----------EPOCH-----------    ----->  4995\n",
      "Train Loss: 0.042674950621184815\n",
      "-----------EPOCH-----------    ----->  4996\n",
      "Train Loss: 0.04267461255106123\n",
      "-----------EPOCH-----------    ----->  4997\n",
      "Train Loss: 0.04267427481476857\n",
      "-----------EPOCH-----------    ----->  4998\n",
      "Train Loss: 0.04267393743740551\n",
      "-----------EPOCH-----------    ----->  4999\n",
      "Train Loss: 0.04267359989319874\n",
      "-----------EPOCH-----------    ----->  5000\n",
      "Train Loss: 0.04267326280422079\n",
      "Final Train Loss: 0.04267326280422079\n",
      "Time elapsed: 360.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize NeuralNetwork\n",
    "nn = NeuralNetwork()\n",
    "nn.addLayer(Layer(mini_batches_X[0].shape[0], 30, 'relu', batchSize))\n",
    "nn.addLayer(Layer(30, 10, 'relu', batchSize))\n",
    "nn.addLayer(Layer(10, 1, 'linear', batchSize))\n",
    "\n",
    "start = time.time()\n",
    "# nn.fit(mini_batches_X, mini_batches_Y, miniValX, miniValY, lr=1e4, epochAmount=5000)\n",
    "\n",
    "# Load weights\n",
    "nn.load_weights('nn_weights_PCA.npz')\n",
    "end = time.time()\n",
    "\n",
    "# nn.save_weights('nn_weights_PCA.npz')\n",
    "\n",
    "print(f'Time elapsed: {end - start:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_history_custom():\n",
    "    iterations, losses = zip(*nn.loss_history)\n",
    "    _, testLosses = zip(*nn.test_loss_history)\n",
    "    plt.plot(iterations, losses)\n",
    "    plt.plot(iterations, testLosses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Performance of NN (PCA) (lr = {1e-2}, epoch = {5000})')\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    plt.show()\n",
    "\n",
    "# plot_loss_history_custom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance (MSE): 0.04228316001584025\n",
      "Validation Performance (R2): 0.36550708802156806\n"
     ]
    }
   ],
   "source": [
    "MSE = np.squeeze(nn.testLoss(miniValX.T, miniValY))\n",
    "R2 = np.squeeze(nn.testLossR2(miniValX.T, miniValY))\n",
    "print(f'Validation Performance (MSE): {MSE}')\n",
    "print(f'Validation Performance (R2): {R2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance (MSE): 0.04335744872904736\n",
      "Test Performance (R2): 0.35549879072651325\n"
     ]
    }
   ],
   "source": [
    "MSE = np.squeeze(nn.testLoss(miniTestX.T, miniTestY))\n",
    "R2 = np.squeeze(nn.testLossR2(miniTestX.T, miniTestY))\n",
    "print(f'Test Performance (MSE): {MSE}')\n",
    "print(f'Test Performance (R2): {R2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.2403753013201012 Response: 0.143\n"
     ]
    }
   ],
   "source": [
    "demoInstanceLoc = 3\n",
    "demoPredictor = predictorData[demoInstanceLoc]\n",
    "demoResponse = responseData[demoInstanceLoc]\n",
    "demoPredictor = np.expand_dims(demoPredictor, axis=0)\n",
    "demoPrediction = np.squeeze(nn.predict(demoPredictor.T))\n",
    "print('Prediction:', demoPrediction, 'Response:', demoResponse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
