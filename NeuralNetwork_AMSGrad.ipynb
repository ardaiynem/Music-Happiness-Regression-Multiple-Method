{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"./data/dataset.csv\"\n",
    "df = pd.read_csv(dataPath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['popularity',\n",
       " 'duration_ms',\n",
       " 'explicit',\n",
       " 'danceability',\n",
       " 'energy',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'acousticness',\n",
       " 'instrumentalness',\n",
       " 'liveness',\n",
       " 'valence',\n",
       " 'tempo',\n",
       " 'time_signature']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(df.columns)\n",
    "columnsToKeep = columns[4: -1]\n",
    "columnsToKeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>21</td>\n",
       "      <td>384999</td>\n",
       "      <td>False</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>5</td>\n",
       "      <td>-16.393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>125.995</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113996</th>\n",
       "      <td>22</td>\n",
       "      <td>385000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>85.239</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113997</th>\n",
       "      <td>22</td>\n",
       "      <td>271466</td>\n",
       "      <td>False</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>132.378</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113998</th>\n",
       "      <td>41</td>\n",
       "      <td>283893</td>\n",
       "      <td>False</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>135.960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113999</th>\n",
       "      <td>22</td>\n",
       "      <td>241826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>79.198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  duration_ms  explicit  danceability  energy  key  \\\n",
       "0               73       230666     False         0.676  0.4610    1   \n",
       "1               55       149610     False         0.420  0.1660    1   \n",
       "2               57       210826     False         0.438  0.3590    0   \n",
       "3               71       201933     False         0.266  0.0596    0   \n",
       "4               82       198853     False         0.618  0.4430    2   \n",
       "...            ...          ...       ...           ...     ...  ...   \n",
       "113995          21       384999     False         0.172  0.2350    5   \n",
       "113996          22       385000     False         0.174  0.1170    0   \n",
       "113997          22       271466     False         0.629  0.3290    0   \n",
       "113998          41       283893     False         0.587  0.5060    7   \n",
       "113999          22       241826     False         0.526  0.4870    1   \n",
       "\n",
       "        loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0         -6.746     0       0.1430        0.0322          0.000001    0.3580   \n",
       "1        -17.235     1       0.0763        0.9240          0.000006    0.1010   \n",
       "2         -9.734     1       0.0557        0.2100          0.000000    0.1170   \n",
       "3        -18.515     1       0.0363        0.9050          0.000071    0.1320   \n",
       "4         -9.681     1       0.0526        0.4690          0.000000    0.0829   \n",
       "...          ...   ...          ...           ...               ...       ...   \n",
       "113995   -16.393     1       0.0422        0.6400          0.928000    0.0863   \n",
       "113996   -18.318     0       0.0401        0.9940          0.976000    0.1050   \n",
       "113997   -10.895     0       0.0420        0.8670          0.000000    0.0839   \n",
       "113998   -10.889     1       0.0297        0.3810          0.000000    0.2700   \n",
       "113999   -10.204     0       0.0725        0.6810          0.000000    0.0893   \n",
       "\n",
       "        valence    tempo  time_signature  \n",
       "0        0.7150   87.917               4  \n",
       "1        0.2670   77.489               4  \n",
       "2        0.1200   76.332               4  \n",
       "3        0.1430  181.740               3  \n",
       "4        0.1670  119.949               4  \n",
       "...         ...      ...             ...  \n",
       "113995   0.0339  125.995               5  \n",
       "113996   0.0350   85.239               4  \n",
       "113997   0.7430  132.378               4  \n",
       "113998   0.4130  135.960               4  \n",
       "113999   0.7080   79.198               4  \n",
       "\n",
       "[114000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[columnsToKeep]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62762/2517655219.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 0 0 ... 0 0 0]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'explicit'] = df['explicit'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Bool to numerical data for explicit row\n",
    "df.loc[:, 'explicit'] = df['explicit'].astype(int)\n",
    "\n",
    "# One hot encoding for nominal categroies\n",
    "df = pd.get_dummies(df, columns=['key', 'time_signature'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "      <th>time_signature_0</th>\n",
       "      <th>time_signature_1</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>21</td>\n",
       "      <td>384999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-16.393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113996</th>\n",
       "      <td>22</td>\n",
       "      <td>385000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-18.318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113997</th>\n",
       "      <td>22</td>\n",
       "      <td>271466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>-10.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113998</th>\n",
       "      <td>41</td>\n",
       "      <td>283893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>-10.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113999</th>\n",
       "      <td>22</td>\n",
       "      <td>241826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>-10.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  duration_ms  explicit  danceability  energy  loudness  \\\n",
       "0               73       230666         0         0.676  0.4610    -6.746   \n",
       "1               55       149610         0         0.420  0.1660   -17.235   \n",
       "2               57       210826         0         0.438  0.3590    -9.734   \n",
       "3               71       201933         0         0.266  0.0596   -18.515   \n",
       "4               82       198853         0         0.618  0.4430    -9.681   \n",
       "...            ...          ...       ...           ...     ...       ...   \n",
       "113995          21       384999         0         0.172  0.2350   -16.393   \n",
       "113996          22       385000         0         0.174  0.1170   -18.318   \n",
       "113997          22       271466         0         0.629  0.3290   -10.895   \n",
       "113998          41       283893         0         0.587  0.5060   -10.889   \n",
       "113999          22       241826         0         0.526  0.4870   -10.204   \n",
       "\n",
       "        mode  speechiness  acousticness  instrumentalness  ...  key_7  key_8  \\\n",
       "0          0       0.1430        0.0322          0.000001  ...      0      0   \n",
       "1          1       0.0763        0.9240          0.000006  ...      0      0   \n",
       "2          1       0.0557        0.2100          0.000000  ...      0      0   \n",
       "3          1       0.0363        0.9050          0.000071  ...      0      0   \n",
       "4          1       0.0526        0.4690          0.000000  ...      0      0   \n",
       "...      ...          ...           ...               ...  ...    ...    ...   \n",
       "113995     1       0.0422        0.6400          0.928000  ...      0      0   \n",
       "113996     0       0.0401        0.9940          0.976000  ...      0      0   \n",
       "113997     0       0.0420        0.8670          0.000000  ...      0      0   \n",
       "113998     1       0.0297        0.3810          0.000000  ...      1      0   \n",
       "113999     0       0.0725        0.6810          0.000000  ...      0      0   \n",
       "\n",
       "        key_9  key_10  key_11  time_signature_0  time_signature_1  \\\n",
       "0           0       0       0                 0                 0   \n",
       "1           0       0       0                 0                 0   \n",
       "2           0       0       0                 0                 0   \n",
       "3           0       0       0                 0                 0   \n",
       "4           0       0       0                 0                 0   \n",
       "...       ...     ...     ...               ...               ...   \n",
       "113995      0       0       0                 0                 0   \n",
       "113996      0       0       0                 0                 0   \n",
       "113997      0       0       0                 0                 0   \n",
       "113998      0       0       0                 0                 0   \n",
       "113999      0       0       0                 0                 0   \n",
       "\n",
       "        time_signature_3  time_signature_4  time_signature_5  \n",
       "0                      0                 1                 0  \n",
       "1                      0                 1                 0  \n",
       "2                      0                 1                 0  \n",
       "3                      1                 0                 0  \n",
       "4                      0                 1                 0  \n",
       "...                  ...               ...               ...  \n",
       "113995                 0                 0                 1  \n",
       "113996                 0                 1                 0  \n",
       "113997                 0                 1                 0  \n",
       "113998                 0                 1                 0  \n",
       "113999                 0                 1                 0  \n",
       "\n",
       "[114000 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(df):\n",
    "    min_vals = df.min()\n",
    "    max_vals = df.max()\n",
    "\n",
    "    feature_range = max_vals - min_vals\n",
    "\n",
    "    # Check if any feature has zero range\n",
    "    zero_range_features = feature_range[feature_range == 0].index\n",
    "\n",
    "    # Remove features with zero range from normalization\n",
    "    valid_features = feature_range[feature_range != 0].index\n",
    "    df_normalized = (df[valid_features] - min_vals[valid_features]) / feature_range[valid_features]\n",
    "\n",
    "    # Concatenate back the zero range features\n",
    "    if not zero_range_features.empty:\n",
    "        df_normalized = pd.concat([df_normalized, df[zero_range_features]], axis=1)\n",
    "\n",
    "    return df_normalized\n",
    "\n",
    "def standard_scaling(df):\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    return (df - mean) / std\n",
    "\n",
    "responseFrame = df.pop('valence')\n",
    "predictorFrame = df\n",
    "\n",
    "# Min-Max scaling for predictor variables\n",
    "df_normalized = min_max_scaling(predictorFrame)\n",
    "\n",
    "# Standard scaling for predictor variables\n",
    "df_standardized = standard_scaling(predictorFrame)\n",
    "\n",
    "predictorFrame_scaled = df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "def reluDer(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "def tanhDer(z):\n",
    "    return 1 - z**2\n",
    "\n",
    "def linearDer(z):\n",
    "    return 1\n",
    "\n",
    "activationDict = {'relu': relu, 'tanh': tanh, 'linear': linear}\n",
    "activationDerivativeDict = {'relu': reluDer, 'tanh': tanhDer, 'linear': linearDer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, inputNumNeuron, numNeurons, activationName, batchSize, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.batchSize = batchSize\n",
    "        self.inputNumNeuron = inputNumNeuron\n",
    "        self.numNeurons = numNeurons\n",
    "        self.activationName = activationName\n",
    "        self.activation = activationDict[self.activationName]\n",
    "        self.activationDerivative = activationDerivativeDict[self.activationName]\n",
    "        self.dZ_state = np.empty((numNeurons, batchSize))\n",
    "        self.Z_state = np.empty((numNeurons, batchSize))\n",
    "        self.A_state = np.empty((numNeurons, batchSize))\n",
    "        self.dW_state = np.zeros((self.numNeurons, self.inputNumNeuron))\n",
    "        self.db_state = np.zeros((self.numNeurons, 1))\n",
    "        self.initWeights()\n",
    "        # AMSGrad variables\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.moment_W = np.zeros((self.numNeurons, self.inputNumNeuron))\n",
    "        self.moment_b = np.zeros((self.numNeurons, 1))\n",
    "        self.velocity_W = np.zeros((self.numNeurons, self.inputNumNeuron))\n",
    "        self.velocity_b = np.zeros((self.numNeurons, 1))\n",
    "        self.velocity_W_max = np.zeros((self.numNeurons, self.inputNumNeuron))\n",
    "        self.velocity_b_max = np.zeros((self.numNeurons, 1))\n",
    "        self.iteration = 0\n",
    "\n",
    "    def initWeights(self):\n",
    "        # Random initialization unfortunately failed.\n",
    "        # self.W = np.random.randn(self.numNeurons, self.inputNumNeuron)\n",
    "        # self.b = np.random.randn(self.numNeurons, 1)\n",
    "\n",
    "        # Xavier initialization for weights\n",
    "        self.W = np.random.randn(self.numNeurons, self.inputNumNeuron) * np.sqrt(1 / self.inputNumNeuron)\n",
    "        # Initializing biases with zeros\n",
    "        self.b = np.zeros((self.numNeurons, 1))\n",
    "        \n",
    "    def updateForwardState(self, inputToLayer):\n",
    "        # print('\\nupdateForwardState():\\n', 'inputToLayer:', inputToLayer.shape, 'self.W', self.W.shape, 'self.b', self.b.shape)\n",
    "        inducedLocal = np.matmul(self.W, inputToLayer) + self.b\n",
    "        output = self.activation(inducedLocal)\n",
    "        self.Z_state = inducedLocal\n",
    "        self.A_state = output\n",
    "        return output\n",
    "    \n",
    "    def predict(self, inputToLayer, printVals=False):\n",
    "        inducedLocal = np.matmul(self.W, inputToLayer) + self.b\n",
    "        output = self.activation(inducedLocal)\n",
    "        if printVals:\n",
    "            print('inp:', self.b, self.W, 'out:', output)\n",
    "        return output\n",
    "\n",
    "    def updateDeltaState(self, dA):\n",
    "        # Derivative of loss over the weihts of this layer\n",
    "        # print('\\nupdateDeltaState():\\n', 'dA:', dA.shape, 'self.Z_state', self.Z_state.shape)\n",
    "        derActivation = self.activationDerivative(self.Z_state)\n",
    "        dZ = np.multiply(dA, derActivation)\n",
    "        self.dZ_state = dZ\n",
    "\n",
    "    def calculateChange(self, A_input):\n",
    "        self.dW_state = (1 / self.batchSize) * np.dot(self.dZ_state, A_input.T)\n",
    "        self.db_state = (1 / self.batchSize) * np.sum(self.dZ_state, axis=1, keepdims=True)\n",
    "        # print('\\ncalculateChange():\\n', 'self.dW_state:', self.dW_state, 'self.db_state', self.db_state, 'A_input:', A_input.T, 'self.Z_state', self.Z_state)\n",
    "        # print('\\ncalculateChange():\\n', 'A_input:', A_input.T.shape, 'self.Z_state', self.Z_state.shape, 'self.dW_state', self.dW_state.shape, 'self.db_state', self.db_state.shape)\n",
    "\n",
    "    def updateWeightsAndBias(self, lr):\n",
    "        # self.W = self.W - lr * self.dW_state\n",
    "        # self.b = self.b - lr * self.db_state\n",
    "        \n",
    "        # Update weights and biases with AMSGrad\n",
    "        self.iteration += 1\n",
    "        self.moment_W = self.beta1 * self.moment_W + (1 - self.beta1) * self.dW_state\n",
    "        self.moment_b = self.beta1 * self.moment_b + (1 - self.beta1) * self.db_state\n",
    "        self.velocity_W = self.beta2 * self.velocity_W + (1 - self.beta2) * np.square(self.dW_state)\n",
    "        self.velocity_b = self.beta2 * self.velocity_b + (1 - self.beta2) * np.square(self.db_state)\n",
    "\n",
    "        self.velocity_W_max = np.maximum(self.velocity_W_max, self.velocity_W)\n",
    "        self.velocity_b_max = np.maximum(self.velocity_b_max, self.velocity_b)\n",
    "\n",
    "        moment_W_hat = self.moment_W / (1 - self.beta1 ** self.iteration)\n",
    "        moment_b_hat = self.moment_b / (1 - self.beta1 ** self.iteration)\n",
    "\n",
    "        self.W -= lr * moment_W_hat / (np.sqrt(self.velocity_W_max) + self.epsilon)\n",
    "        self.b -= lr * moment_b_hat / (np.sqrt(self.velocity_b_max) + self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss_history = []\n",
    "        self.test_loss_history = []\n",
    "\n",
    "    def addLayer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def loss(self, predictions, y):\n",
    "        # MSE\n",
    "        batchSize = y.size\n",
    "        error = y - predictions\n",
    "        squaredError = np.dot(error.T, error)\n",
    "        mse = (1 / batchSize) * squaredError\n",
    "        return mse\n",
    "    \n",
    "    def lossDer(self, predictions, y):\n",
    "        # MSE Derivative\n",
    "        batchSize = y.size\n",
    "        error = y - predictions\n",
    "        mseDer = (-2 / batchSize) * np.sum(error, axis=0, keepdims=True)\n",
    "        return mseDer\n",
    "    \n",
    "    def predict(self, testPredictor):\n",
    "        output = testPredictor\n",
    "        for layer in self.layers:\n",
    "            printVals = True if False else False\n",
    "            output = layer.predict(output, printVals)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, trainPredictor):\n",
    "        output = trainPredictor\n",
    "        for layer in self.layers:\n",
    "            output = layer.updateForwardState(output)\n",
    "        return output\n",
    "    \n",
    "    def backprop(self, predictions, y, x, lr):\n",
    "        # Update Delta State\n",
    "        for layerNumber in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[layerNumber]\n",
    "            inputToLayer = self.layers[layerNumber - 1].A_state if layerNumber > 0 else x\n",
    "            \n",
    "            # Output Layer\n",
    "            if(layer == self.layers[-1]):\n",
    "                y_reshaped = np.reshape(y, (1, y.size))\n",
    "                lossDerivative = self.lossDer(predictions, y_reshaped)\n",
    "                # print('\\nbackpropFirst():\\n', 'predictions:', predictions.shape, 'y_reshaped:', y_reshaped.shape, 'lossDerivative:', lossDerivative.shape, 'inputToLayer', inputToLayer.shape)\n",
    "                layer.updateDeltaState(lossDerivative)\n",
    "                layer.calculateChange(inputToLayer)\n",
    "            # Hidden Layers\n",
    "            else:\n",
    "                dZ_next = nextLayer.dZ_state\n",
    "                W_next = nextLayer.W\n",
    "                dA = np.dot(W_next.T, dZ_next)\n",
    "                # print('\\nbackpropAlt():\\n', 'dZ_next:', dZ_next.shape, 'W_next', W_next.shape, 'dA:', dA.shape)\n",
    "                layer.updateDeltaState(dA)\n",
    "                layer.calculateChange(inputToLayer)\n",
    "\n",
    "            nextLayer = layer\n",
    "\n",
    "        # Update Weights and Bias\n",
    "        for layerNumber in range(len(self.layers)):\n",
    "            layer = self.layers[layerNumber]\n",
    "            layer.updateWeightsAndBias(lr)\n",
    "\n",
    "    def fit(self, mini_batches_x, mini_batches_y, mini_test_x, mini_test_y, lr=1e-2, epochAmount=10):\n",
    "        for epoch in range(epochAmount):\n",
    "            print('-----------EPOCH-----------    -----> ', epoch + 1)\n",
    "            # Train using mini-batches\n",
    "            for mini_batch_X, mini_batch_Y in zip(mini_batches_x, mini_batches_y):\n",
    "                predictions = self.forward(mini_batch_X)\n",
    "                self.backprop(predictions, mini_batch_Y, mini_batch_X, lr)\n",
    "\n",
    "            predictions = self.predict(mini_batch_X)\n",
    "            trainLoss = np.squeeze(self.loss(predictions.T, mini_batch_Y.T))\n",
    "            print(f'Train Loss:', trainLoss)\n",
    "            self.loss_history.append((epoch, trainLoss))\n",
    "\n",
    "            testError = np.squeeze(self.testLoss(mini_test_x.T, mini_test_y))\n",
    "            self.test_loss_history.append((epoch, testError))\n",
    "\n",
    "        print('Final Train Loss:', trainLoss)\n",
    "\n",
    "    def testLoss(self, test_x, test_y):\n",
    "        predictions = np.squeeze(self.predict(test_x))\n",
    "        lossMSE = self.loss(predictions, test_y)\n",
    "        return lossMSE\n",
    "    \n",
    "    def testLossR2(self, test_x, test_y):\n",
    "        predictions = np.squeeze(self.predict(test_x))\n",
    "        mean_observed = np.mean(test_y)\n",
    "        total_sum_squares = np.sum((test_y - mean_observed) ** 2)\n",
    "        residual_sum_squares = np.sum((test_y - predictions) ** 2)\n",
    "        r2 = 1 - (residual_sum_squares / total_sum_squares)\n",
    "        return r2\n",
    "\n",
    "    def plot_loss_history(self):\n",
    "        iterations, losses = zip(*self.loss_history)\n",
    "        _, testLosses = zip(*self.test_loss_history)\n",
    "        plt.plot(iterations, losses)\n",
    "        plt.plot(iterations, testLosses)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Training Loss')\n",
    "        plt.title(f'Training Loss over Epochs NN (lr = {1e4}, epoch = {5000})')\n",
    "        plt.legend(['Train', 'Test'])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def save_weights(self, filename):\n",
    "        # Create a dictionary to hold weights and biases of all layers\n",
    "        weights_dict = {}\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            weights_dict[f\"Layer_{i}_W\"] = layer.W\n",
    "            weights_dict[f\"Layer_{i}_b\"] = layer.b\n",
    "\n",
    "        # Save the weights dictionary to a file\n",
    "        np.savez(filename, **weights_dict)\n",
    "\n",
    "    def load_weights(self, filename):\n",
    "        # Load the weights dictionary from the file\n",
    "        data = np.load(filename)\n",
    "\n",
    "        # Iterate through layers and load weights and biases\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer.W = data[f\"Layer_{i}_W\"]\n",
    "            layer.b = data[f\"Layer_{i}_b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseData = responseFrame.to_numpy()\n",
    "predictorData = predictorFrame_scaled.to_numpy()\n",
    "\n",
    "# Full batch gradient descent\n",
    "batchSize = predictorData.shape[0]\n",
    "trainSplit = 0.8\n",
    "valSplit = 0.1\n",
    "testSplit = 0.1\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(predictorData))\n",
    "np.random.shuffle(indices)\n",
    "trainIndices = indices[:int(trainSplit * len(indices))]\n",
    "valIndices = indices[int(trainSplit* len(indices)):int((trainSplit + valSplit) * len(indices))]\n",
    "testIndices = indices[int((trainSplit + valSplit) * len(indices)):]\n",
    "\n",
    "trainPredictor, testPredictor, valPredictor = predictorData[trainIndices], predictorData[testIndices], predictorData[valIndices]\n",
    "trainResponse, testResponse, valResponse = responseData[trainIndices], responseData[testIndices], responseData[valIndices]\n",
    "\n",
    "trainResponse = np.expand_dims(trainResponse, axis=1)\n",
    "\n",
    "# Function to create mini-batches\n",
    "def create_mini_batches(data, batch_size):\n",
    "    mini_batches = []\n",
    "    data_size = len(data)\n",
    "    num_batches = data_size // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        mini_batch = data[start_idx:end_idx]\n",
    "        mini_batches.append(mini_batch.T)\n",
    "    \n",
    "    if data_size % batch_size != 0:\n",
    "        mini_batch = data[num_batches * batch_size:]\n",
    "        mini_batches.append(mini_batch.T)\n",
    "    \n",
    "    return np.array(mini_batches)\n",
    "\n",
    "# Create mini-batches\n",
    "mini_batches_X = create_mini_batches(trainPredictor, batch_size= batchSize)\n",
    "mini_batches_Y = create_mini_batches(trainResponse, batch_size= batchSize)\n",
    "miniTestX = testPredictor\n",
    "miniTestY = testResponse\n",
    "miniValX = valPredictor\n",
    "miniValY = valResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.002177\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize NeuralNetwork\n",
    "nn = NeuralNetwork()\n",
    "nn.addLayer(Layer(mini_batches_X[0].shape[0], 30, 'relu', batchSize))\n",
    "nn.addLayer(Layer(30, 10, 'relu', batchSize))\n",
    "nn.addLayer(Layer(10, 1, 'linear', batchSize))\n",
    "\n",
    "start = time.time()\n",
    "# nn.fit(mini_batches_X, mini_batches_Y, miniValX, miniValY, lr=1e-2, epochAmount=5000)\n",
    "\n",
    "# Load weights\n",
    "nn.load_weights('nn_weights_amsgrad.npz')\n",
    "end = time.time()\n",
    "\n",
    "# nn.save_weights('nn_weights_amsgrad.npz')\n",
    "\n",
    "print(f'Time elapsed: {end - start:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history_custom():\n",
    "    iterations, losses = zip(*nn.loss_history)\n",
    "    _, testLosses = zip(*nn.test_loss_history)\n",
    "    plt.plot(iterations, losses)\n",
    "    plt.plot(iterations, testLosses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Performance of NN (AMSGrad) (lr = {1e-2}, epoch = {5000})')\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    plt.show()\n",
    "\n",
    "# plot_loss_history_custom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance (MSE): 0.03691432270468161\n",
      "Validation Performance (R2): 0.4460708211536082\n"
     ]
    }
   ],
   "source": [
    "MSE = np.squeeze(nn.testLoss(miniValX.T, miniValY))\n",
    "R2 = np.squeeze(nn.testLossR2(miniValX.T, miniValY))\n",
    "print(f'Validation Performance (MSE): {MSE}')\n",
    "print(f'Validation Performance (R2): {R2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance (MSE): 0.037638558640706546\n",
      "Test Performance (R2): 0.44050913348610665\n"
     ]
    }
   ],
   "source": [
    "MSE = np.squeeze(nn.testLoss(miniTestX.T, miniTestY))\n",
    "R2 = np.squeeze(nn.testLossR2(miniTestX.T, miniTestY))\n",
    "print(f'Test Performance (MSE): {MSE}')\n",
    "print(f'Test Performance (R2): {R2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.24784339941495898 Response: 0.143\n"
     ]
    }
   ],
   "source": [
    "demoInstanceLoc = 3\n",
    "demoPredictor = predictorData[demoInstanceLoc]\n",
    "demoResponse = responseData[demoInstanceLoc]\n",
    "demoPredictor = np.expand_dims(demoPredictor, axis=0)\n",
    "demoPrediction = np.squeeze(nn.predict(demoPredictor.T))\n",
    "print('Prediction:', demoPrediction, 'Response:', demoResponse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
