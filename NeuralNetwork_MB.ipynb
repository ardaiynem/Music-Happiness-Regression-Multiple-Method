{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"./data/dataset.csv\"\n",
    "df = pd.read_csv(dataPath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['popularity',\n",
       " 'duration_ms',\n",
       " 'explicit',\n",
       " 'danceability',\n",
       " 'energy',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'acousticness',\n",
       " 'instrumentalness',\n",
       " 'liveness',\n",
       " 'valence',\n",
       " 'tempo',\n",
       " 'time_signature']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(df.columns)\n",
    "columnsToKeep = columns[4: -1]\n",
    "columnsToKeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>21</td>\n",
       "      <td>384999</td>\n",
       "      <td>False</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>5</td>\n",
       "      <td>-16.393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>125.995</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113996</th>\n",
       "      <td>22</td>\n",
       "      <td>385000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>85.239</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113997</th>\n",
       "      <td>22</td>\n",
       "      <td>271466</td>\n",
       "      <td>False</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>132.378</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113998</th>\n",
       "      <td>41</td>\n",
       "      <td>283893</td>\n",
       "      <td>False</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>135.960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113999</th>\n",
       "      <td>22</td>\n",
       "      <td>241826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>79.198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  duration_ms  explicit  danceability  energy  key  \\\n",
       "0               73       230666     False         0.676  0.4610    1   \n",
       "1               55       149610     False         0.420  0.1660    1   \n",
       "2               57       210826     False         0.438  0.3590    0   \n",
       "3               71       201933     False         0.266  0.0596    0   \n",
       "4               82       198853     False         0.618  0.4430    2   \n",
       "...            ...          ...       ...           ...     ...  ...   \n",
       "113995          21       384999     False         0.172  0.2350    5   \n",
       "113996          22       385000     False         0.174  0.1170    0   \n",
       "113997          22       271466     False         0.629  0.3290    0   \n",
       "113998          41       283893     False         0.587  0.5060    7   \n",
       "113999          22       241826     False         0.526  0.4870    1   \n",
       "\n",
       "        loudness  mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
       "0         -6.746     0       0.1430        0.0322          0.000001    0.3580   \n",
       "1        -17.235     1       0.0763        0.9240          0.000006    0.1010   \n",
       "2         -9.734     1       0.0557        0.2100          0.000000    0.1170   \n",
       "3        -18.515     1       0.0363        0.9050          0.000071    0.1320   \n",
       "4         -9.681     1       0.0526        0.4690          0.000000    0.0829   \n",
       "...          ...   ...          ...           ...               ...       ...   \n",
       "113995   -16.393     1       0.0422        0.6400          0.928000    0.0863   \n",
       "113996   -18.318     0       0.0401        0.9940          0.976000    0.1050   \n",
       "113997   -10.895     0       0.0420        0.8670          0.000000    0.0839   \n",
       "113998   -10.889     1       0.0297        0.3810          0.000000    0.2700   \n",
       "113999   -10.204     0       0.0725        0.6810          0.000000    0.0893   \n",
       "\n",
       "        valence    tempo  time_signature  \n",
       "0        0.7150   87.917               4  \n",
       "1        0.2670   77.489               4  \n",
       "2        0.1200   76.332               4  \n",
       "3        0.1430  181.740               3  \n",
       "4        0.1670  119.949               4  \n",
       "...         ...      ...             ...  \n",
       "113995   0.0339  125.995               5  \n",
       "113996   0.0350   85.239               4  \n",
       "113997   0.7430  132.378               4  \n",
       "113998   0.4130  135.960               4  \n",
       "113999   0.7080   79.198               4  \n",
       "\n",
       "[114000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[columnsToKeep]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9267/2517655219.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0 0 0 ... 0 0 0]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'explicit'] = df['explicit'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Bool to numerical data for explicit row\n",
    "df.loc[:, 'explicit'] = df['explicit'].astype(int)\n",
    "\n",
    "# One hot encoding for nominal categroies\n",
    "df = pd.get_dummies(df, columns=['key', 'time_signature'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "      <th>time_signature_0</th>\n",
       "      <th>time_signature_1</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>21</td>\n",
       "      <td>384999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>-16.393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113996</th>\n",
       "      <td>22</td>\n",
       "      <td>385000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>-18.318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113997</th>\n",
       "      <td>22</td>\n",
       "      <td>271466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>-10.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113998</th>\n",
       "      <td>41</td>\n",
       "      <td>283893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>-10.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113999</th>\n",
       "      <td>22</td>\n",
       "      <td>241826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>-10.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114000 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  duration_ms  explicit  danceability  energy  loudness  \\\n",
       "0               73       230666         0         0.676  0.4610    -6.746   \n",
       "1               55       149610         0         0.420  0.1660   -17.235   \n",
       "2               57       210826         0         0.438  0.3590    -9.734   \n",
       "3               71       201933         0         0.266  0.0596   -18.515   \n",
       "4               82       198853         0         0.618  0.4430    -9.681   \n",
       "...            ...          ...       ...           ...     ...       ...   \n",
       "113995          21       384999         0         0.172  0.2350   -16.393   \n",
       "113996          22       385000         0         0.174  0.1170   -18.318   \n",
       "113997          22       271466         0         0.629  0.3290   -10.895   \n",
       "113998          41       283893         0         0.587  0.5060   -10.889   \n",
       "113999          22       241826         0         0.526  0.4870   -10.204   \n",
       "\n",
       "        mode  speechiness  acousticness  instrumentalness  ...  key_7  key_8  \\\n",
       "0          0       0.1430        0.0322          0.000001  ...      0      0   \n",
       "1          1       0.0763        0.9240          0.000006  ...      0      0   \n",
       "2          1       0.0557        0.2100          0.000000  ...      0      0   \n",
       "3          1       0.0363        0.9050          0.000071  ...      0      0   \n",
       "4          1       0.0526        0.4690          0.000000  ...      0      0   \n",
       "...      ...          ...           ...               ...  ...    ...    ...   \n",
       "113995     1       0.0422        0.6400          0.928000  ...      0      0   \n",
       "113996     0       0.0401        0.9940          0.976000  ...      0      0   \n",
       "113997     0       0.0420        0.8670          0.000000  ...      0      0   \n",
       "113998     1       0.0297        0.3810          0.000000  ...      1      0   \n",
       "113999     0       0.0725        0.6810          0.000000  ...      0      0   \n",
       "\n",
       "        key_9  key_10  key_11  time_signature_0  time_signature_1  \\\n",
       "0           0       0       0                 0                 0   \n",
       "1           0       0       0                 0                 0   \n",
       "2           0       0       0                 0                 0   \n",
       "3           0       0       0                 0                 0   \n",
       "4           0       0       0                 0                 0   \n",
       "...       ...     ...     ...               ...               ...   \n",
       "113995      0       0       0                 0                 0   \n",
       "113996      0       0       0                 0                 0   \n",
       "113997      0       0       0                 0                 0   \n",
       "113998      0       0       0                 0                 0   \n",
       "113999      0       0       0                 0                 0   \n",
       "\n",
       "        time_signature_3  time_signature_4  time_signature_5  \n",
       "0                      0                 1                 0  \n",
       "1                      0                 1                 0  \n",
       "2                      0                 1                 0  \n",
       "3                      1                 0                 0  \n",
       "4                      0                 1                 0  \n",
       "...                  ...               ...               ...  \n",
       "113995                 0                 0                 1  \n",
       "113996                 0                 1                 0  \n",
       "113997                 0                 1                 0  \n",
       "113998                 0                 1                 0  \n",
       "113999                 0                 1                 0  \n",
       "\n",
       "[114000 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(df):\n",
    "    min_vals = df.min()\n",
    "    max_vals = df.max()\n",
    "\n",
    "    feature_range = max_vals - min_vals\n",
    "\n",
    "    # Check if any feature has zero range\n",
    "    zero_range_features = feature_range[feature_range == 0].index\n",
    "\n",
    "    # Remove features with zero range from normalization\n",
    "    valid_features = feature_range[feature_range != 0].index\n",
    "    df_normalized = (df[valid_features] - min_vals[valid_features]) / feature_range[valid_features]\n",
    "\n",
    "    # Concatenate back the zero range features\n",
    "    if not zero_range_features.empty:\n",
    "        df_normalized = pd.concat([df_normalized, df[zero_range_features]], axis=1)\n",
    "\n",
    "    return df_normalized\n",
    "\n",
    "def standard_scaling(df):\n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    return (df - mean) / std\n",
    "\n",
    "responseFrame = df.pop('valence')\n",
    "predictorFrame = df\n",
    "\n",
    "# Min-Max scaling for predictor variables\n",
    "df_normalized = min_max_scaling(predictorFrame)\n",
    "\n",
    "# Standard scaling for predictor variables\n",
    "df_standardized = standard_scaling(predictorFrame)\n",
    "\n",
    "predictorFrame_scaled = df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "def reluDer(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "def tanhDer(z):\n",
    "    return 1 - z**2\n",
    "\n",
    "def linearDer(z):\n",
    "    return 1\n",
    "\n",
    "activationDict = {'relu': relu, 'tanh': tanh, 'linear': linear}\n",
    "activationDerivativeDict = {'relu': reluDer, 'tanh': tanhDer, 'linear': linearDer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, inputNumNeuron, numNeurons, activationName, batchSize):\n",
    "        self.batchSize = batchSize\n",
    "        self.inputNumNeuron = inputNumNeuron\n",
    "        self.numNeurons = numNeurons\n",
    "        self.activationName = activationName\n",
    "        self.activation = activationDict[self.activationName]\n",
    "        self.activationDerivative = activationDerivativeDict[self.activationName]\n",
    "        self.dZ_state = np.empty((numNeurons, batchSize))\n",
    "        self.Z_state = np.empty((numNeurons, batchSize))\n",
    "        self.A_state = np.empty((numNeurons, batchSize))\n",
    "        self.dW_state = np.zeros((self.numNeurons, self.inputNumNeuron))\n",
    "        self.db_state = np.zeros((self.numNeurons, 1))\n",
    "        self.initWeights()\n",
    "\n",
    "    def initWeights(self):\n",
    "        # Random initialization unfortunately failed.\n",
    "        # self.W = np.random.randn(self.numNeurons, self.inputNumNeuron)\n",
    "        # self.b = np.random.randn(self.numNeurons, 1)\n",
    "\n",
    "        # Xavier initialization for weights\n",
    "        self.W = np.random.randn(self.numNeurons, self.inputNumNeuron) * np.sqrt(1 / self.inputNumNeuron)\n",
    "        # Initializing biases with zeros\n",
    "        self.b = np.zeros((self.numNeurons, 1))\n",
    "        \n",
    "    def updateForwardState(self, inputToLayer):\n",
    "        # print('\\nupdateForwardState():\\n', 'inputToLayer:', inputToLayer.shape, 'self.W', self.W.shape, 'self.b', self.b.shape)\n",
    "        inducedLocal = np.matmul(self.W, inputToLayer) + self.b\n",
    "        output = self.activation(inducedLocal)\n",
    "        self.Z_state = inducedLocal\n",
    "        self.A_state = output\n",
    "        return output\n",
    "    \n",
    "    def predict(self, inputToLayer, printVals=False):\n",
    "        inducedLocal = np.matmul(self.W, inputToLayer) + self.b\n",
    "        output = self.activation(inducedLocal)\n",
    "        if printVals:\n",
    "            print('inp:', self.b, self.W, 'out:', output)\n",
    "        return output\n",
    "\n",
    "    def updateDeltaState(self, dA):\n",
    "        # Derivative of loss over the weihts of this layer\n",
    "        # print('\\nupdateDeltaState():\\n', 'dA:', dA.shape, 'self.Z_state', self.Z_state.shape)\n",
    "        derActivation = self.activationDerivative(self.Z_state)\n",
    "        dZ = np.multiply(dA, derActivation)\n",
    "        self.dZ_state = dZ\n",
    "\n",
    "    def calculateChange(self, A_input):\n",
    "        self.dW_state = (1 / self.batchSize) * np.dot(self.dZ_state, A_input.T)\n",
    "        self.db_state = (1 / self.batchSize) * np.sum(self.dZ_state, axis=1, keepdims=True)\n",
    "        # print('\\ncalculateChange():\\n', 'self.dW_state:', self.dW_state, 'self.db_state', self.db_state, 'A_input:', A_input.T, 'self.Z_state', self.Z_state)\n",
    "        # print('\\ncalculateChange():\\n', 'A_input:', A_input.T.shape, 'self.Z_state', self.Z_state.shape, 'self.dW_state', self.dW_state.shape, 'self.db_state', self.db_state.shape)\n",
    "\n",
    "    def updateWeightsAndBias(self, lr):\n",
    "        self.W = self.W - lr * self.dW_state\n",
    "        self.b = self.b - lr * self.db_state\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"Input Dim: \" + str(self.inputNumNeuron) + \", Number of Neurons: \" + str(self.numNeurons) + \"\\n Activation: \" + self.activationName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss_history = []\n",
    "        self.test_loss_history = []\n",
    "\n",
    "    def addLayer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def loss(self, predictions, y):\n",
    "        # MSE\n",
    "        batchSize = y.size\n",
    "        error = y - predictions\n",
    "        squaredError = np.dot(error.T, error)\n",
    "        mse = (1 / batchSize) * squaredError\n",
    "        return mse\n",
    "    \n",
    "    def lossDer(self, predictions, y):\n",
    "        # MSE Derivative\n",
    "        batchSize = y.size\n",
    "        error = y - predictions\n",
    "        mseDer = (-2 / batchSize) * np.sum(error, axis=0, keepdims=True)\n",
    "        return mseDer\n",
    "    \n",
    "    def predict(self, testPredictor):\n",
    "        output = testPredictor\n",
    "        for layer in self.layers:\n",
    "            printVals = True if False else False\n",
    "            output = layer.predict(output, printVals)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, trainPredictor):\n",
    "        output = trainPredictor\n",
    "        for layer in self.layers:\n",
    "            output = layer.updateForwardState(output)\n",
    "        return output\n",
    "    \n",
    "    def backprop(self, predictions, y, x, lr):\n",
    "        # Update Delta State\n",
    "        for layerNumber in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[layerNumber]\n",
    "            inputToLayer = self.layers[layerNumber - 1].A_state if layerNumber > 0 else x\n",
    "            \n",
    "            # Output Layer\n",
    "            if(layer == self.layers[-1]):\n",
    "                y_reshaped = np.reshape(y, (1, y.size))\n",
    "                lossDerivative = self.lossDer(predictions, y_reshaped)\n",
    "                # print('\\nbackpropFirst():\\n', 'predictions:', predictions.shape, 'y_reshaped:', y_reshaped.shape, 'lossDerivative:', lossDerivative.shape, 'inputToLayer', inputToLayer.shape)\n",
    "                layer.updateDeltaState(lossDerivative)\n",
    "                layer.calculateChange(inputToLayer)\n",
    "            # Hidden Layers\n",
    "            else:\n",
    "                dZ_next = nextLayer.dZ_state\n",
    "                W_next = nextLayer.W\n",
    "                dA = np.dot(W_next.T, dZ_next)\n",
    "                # print('\\nbackpropAlt():\\n', 'dZ_next:', dZ_next.shape, 'W_next', W_next.shape, 'dA:', dA.shape)\n",
    "                layer.updateDeltaState(dA)\n",
    "                layer.calculateChange(inputToLayer)\n",
    "\n",
    "            nextLayer = layer\n",
    "\n",
    "        # Update Weights and Bias\n",
    "        for layerNumber in range(len(self.layers)):\n",
    "            layer = self.layers[layerNumber]\n",
    "            layer.updateWeightsAndBias(lr)\n",
    "\n",
    "    def fit(self, mini_batches_x, mini_batches_y, mini_test_x, mini_test_y, lr=1e-2, epochAmount=10):\n",
    "        for epoch in range(epochAmount):\n",
    "            total_loss = 0\n",
    "            num_batches = len(mini_batches_x)\n",
    "            print('-----------EPOCH-----------    -----> ', epoch + 1)\n",
    "            # Train using mini-batches\n",
    "            for mini_batch_X, mini_batch_Y in zip(mini_batches_x, mini_batches_y):\n",
    "                predictions = self.forward(mini_batch_X)\n",
    "                self.backprop(predictions, mini_batch_Y, mini_batch_X, lr)\n",
    "\n",
    "                # Compute loss for this mini-batch and accumulate\n",
    "                loss = np.squeeze(self.loss(predictions.T, mini_batch_Y.T))\n",
    "                total_loss += loss\n",
    "\n",
    "            # Average loss over all mini-batches\n",
    "            average_loss = total_loss / num_batches\n",
    "            print(f'Train Loss: {average_loss}')\n",
    "            self.loss_history.append((epoch, average_loss))\n",
    "\n",
    "            testError = np.squeeze(self.testLoss(mini_test_x.T, mini_test_y))\n",
    "            self.test_loss_history.append((epoch, testError))\n",
    "        \n",
    "        print('Final Train Loss:', average_loss)\n",
    "\n",
    "    def testLoss(self, test_x, test_y):\n",
    "        predictions = np.squeeze(self.predict(test_x))\n",
    "        lossMSE = self.loss(predictions, test_y)\n",
    "        return lossMSE\n",
    "    \n",
    "    def testLossR2(self, test_x, test_y):\n",
    "        predictions = np.squeeze(self.predict(test_x))\n",
    "        mean_observed = np.mean(test_y)\n",
    "        total_sum_squares = np.sum((test_y - mean_observed) ** 2)\n",
    "        residual_sum_squares = np.sum((test_y - predictions) ** 2)\n",
    "        r2 = 1 - (residual_sum_squares / total_sum_squares)\n",
    "        return r2\n",
    "    \n",
    "    def plot_loss_history(self):\n",
    "        iterations, losses = zip(*self.loss_history)\n",
    "        _, testLosses = zip(*self.test_loss_history)\n",
    "        plt.plot(iterations, losses)\n",
    "        plt.plot(iterations, testLosses)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Training Loss')\n",
    "        plt.title(f'Training Loss over Epochs NN (lr = {1e4}, epoch = {5000})')\n",
    "        plt.legend(['Train', 'Test'])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def save_weights(self, filename):\n",
    "        # Create a dictionary to hold weights and biases of all layers\n",
    "        weights_dict = {}\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            weights_dict[f\"Layer_{i}_W\"] = layer.W\n",
    "            weights_dict[f\"Layer_{i}_b\"] = layer.b\n",
    "\n",
    "        # Save the weights dictionary to a file\n",
    "        np.savez(filename, **weights_dict)\n",
    "\n",
    "    def load_weights(self, filename):\n",
    "        # Load the weights dictionary from the file\n",
    "        data = np.load(filename)\n",
    "\n",
    "        # Iterate through layers and load weights and biases\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer.W = data[f\"Layer_{i}_W\"]\n",
    "            layer.b = data[f\"Layer_{i}_b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseData = responseFrame.to_numpy()\n",
    "predictorData = predictorFrame_scaled.to_numpy()\n",
    "\n",
    "# Full batch gradient descent\n",
    "# batchSize = predictorData.shape[0] // 6000\n",
    "batchSize = 1\n",
    "trainSplit = 0.8\n",
    "valSplit = 0.1\n",
    "testSplit = 0.1\n",
    "\n",
    "# np.random.seed(42)\n",
    "indices = np.arange(len(predictorData))\n",
    "np.random.shuffle(indices)\n",
    "trainIndices = indices[:int(trainSplit * len(indices))]\n",
    "valIndices = indices[int(trainSplit* len(indices)):int((trainSplit + valSplit) * len(indices))]\n",
    "testIndices = indices[int((trainSplit + valSplit) * len(indices)):]\n",
    "\n",
    "trainPredictor, testPredictor, valPredictor = predictorData[trainIndices], predictorData[testIndices], predictorData[valIndices]\n",
    "trainResponse, testResponse, valResponse = responseData[trainIndices], responseData[testIndices], responseData[valIndices]\n",
    "\n",
    "trainResponse = np.expand_dims(trainResponse, axis=1)\n",
    "\n",
    "# Function to create mini-batches\n",
    "def create_mini_batches(data, batch_size):\n",
    "    mini_batches = []\n",
    "    data_size = len(data)\n",
    "    num_batches = data_size // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        mini_batch = data[start_idx:end_idx]\n",
    "        mini_batches.append(mini_batch.T)\n",
    "    \n",
    "    if data_size % batch_size != 0:\n",
    "        mini_batch = data[num_batches * batch_size:]\n",
    "        mini_batches.append(mini_batch.T)\n",
    "    \n",
    "    return np.array(mini_batches)\n",
    "\n",
    "# Create mini-batches\n",
    "mini_batches_X = create_mini_batches(trainPredictor, batch_size= batchSize)\n",
    "mini_batches_Y = create_mini_batches(trainResponse, batch_size= batchSize)\n",
    "miniTestX = testPredictor\n",
    "miniTestY = testResponse\n",
    "miniValX = valPredictor\n",
    "miniValY = valResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------EPOCH-----------    ----->  1\n",
      "Train Loss: 0.061709019757454034\n",
      "-----------EPOCH-----------    ----->  2\n",
      "Train Loss: 0.052240122523013924\n",
      "-----------EPOCH-----------    ----->  3\n",
      "Train Loss: 0.04943246750523644\n",
      "-----------EPOCH-----------    ----->  4\n",
      "Train Loss: 0.04765597168997376\n",
      "-----------EPOCH-----------    ----->  5\n",
      "Train Loss: 0.0463919938995002\n",
      "-----------EPOCH-----------    ----->  6\n",
      "Train Loss: 0.0454558375371336\n",
      "-----------EPOCH-----------    ----->  7\n",
      "Train Loss: 0.04475828861605634\n",
      "-----------EPOCH-----------    ----->  8\n",
      "Train Loss: 0.04423357162503508\n",
      "-----------EPOCH-----------    ----->  9\n",
      "Train Loss: 0.04383348289530651\n",
      "-----------EPOCH-----------    ----->  10\n",
      "Train Loss: 0.04352082131434157\n",
      "-----------EPOCH-----------    ----->  11\n",
      "Train Loss: 0.04326674903648083\n",
      "-----------EPOCH-----------    ----->  12\n",
      "Train Loss: 0.04305660402367534\n",
      "-----------EPOCH-----------    ----->  13\n",
      "Train Loss: 0.04287733100834618\n",
      "-----------EPOCH-----------    ----->  14\n",
      "Train Loss: 0.04272095870355568\n",
      "-----------EPOCH-----------    ----->  15\n",
      "Train Loss: 0.04258360617590314\n",
      "-----------EPOCH-----------    ----->  16\n",
      "Train Loss: 0.042461237240719\n",
      "-----------EPOCH-----------    ----->  17\n",
      "Train Loss: 0.042351391033173556\n",
      "-----------EPOCH-----------    ----->  18\n",
      "Train Loss: 0.04225157733269234\n",
      "-----------EPOCH-----------    ----->  19\n",
      "Train Loss: 0.0421602975949316\n",
      "-----------EPOCH-----------    ----->  20\n",
      "Train Loss: 0.04207705086598092\n",
      "-----------EPOCH-----------    ----->  21\n",
      "Train Loss: 0.04200071200959543\n",
      "-----------EPOCH-----------    ----->  22\n",
      "Train Loss: 0.04192951280288221\n",
      "-----------EPOCH-----------    ----->  23\n",
      "Train Loss: 0.04186267564299\n",
      "-----------EPOCH-----------    ----->  24\n",
      "Train Loss: 0.04179883298675254\n",
      "-----------EPOCH-----------    ----->  25\n",
      "Train Loss: 0.041738036346341\n",
      "-----------EPOCH-----------    ----->  26\n",
      "Train Loss: 0.04167981141479499\n",
      "-----------EPOCH-----------    ----->  27\n",
      "Train Loss: 0.04162476091532566\n",
      "-----------EPOCH-----------    ----->  28\n",
      "Train Loss: 0.04157137054426959\n",
      "-----------EPOCH-----------    ----->  29\n",
      "Train Loss: 0.041519988696829845\n",
      "-----------EPOCH-----------    ----->  30\n",
      "Train Loss: 0.04146968782377037\n",
      "-----------EPOCH-----------    ----->  31\n",
      "Train Loss: 0.041420468399824314\n",
      "-----------EPOCH-----------    ----->  32\n",
      "Train Loss: 0.04137188144014199\n",
      "-----------EPOCH-----------    ----->  33\n",
      "Train Loss: 0.04132522877675404\n",
      "-----------EPOCH-----------    ----->  34\n",
      "Train Loss: 0.041280454614076256\n",
      "-----------EPOCH-----------    ----->  35\n",
      "Train Loss: 0.041236740010554336\n",
      "-----------EPOCH-----------    ----->  36\n",
      "Train Loss: 0.04119410223640095\n",
      "-----------EPOCH-----------    ----->  37\n",
      "Train Loss: 0.041153042575610095\n",
      "-----------EPOCH-----------    ----->  38\n",
      "Train Loss: 0.04111331873453747\n",
      "-----------EPOCH-----------    ----->  39\n",
      "Train Loss: 0.041074820779398384\n",
      "-----------EPOCH-----------    ----->  40\n",
      "Train Loss: 0.041037317636775796\n",
      "-----------EPOCH-----------    ----->  41\n",
      "Train Loss: 0.041000667751235016\n",
      "-----------EPOCH-----------    ----->  42\n",
      "Train Loss: 0.040964976522357914\n",
      "-----------EPOCH-----------    ----->  43\n",
      "Train Loss: 0.04092985730837986\n",
      "-----------EPOCH-----------    ----->  44\n",
      "Train Loss: 0.04089621790865638\n",
      "-----------EPOCH-----------    ----->  45\n",
      "Train Loss: 0.040863726038496084\n",
      "-----------EPOCH-----------    ----->  46\n",
      "Train Loss: 0.0408315637574075\n",
      "-----------EPOCH-----------    ----->  47\n",
      "Train Loss: 0.040799711571103583\n",
      "-----------EPOCH-----------    ----->  48\n",
      "Train Loss: 0.040769082125516866\n",
      "-----------EPOCH-----------    ----->  49\n",
      "Train Loss: 0.04073934866393096\n",
      "-----------EPOCH-----------    ----->  50\n",
      "Train Loss: 0.04071083020505644\n",
      "Final Train Loss: 0.04071083020505644\n",
      "Time elapsed: 324.6\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize NeuralNetwork\n",
    "nn = NeuralNetwork()\n",
    "nn.addLayer(Layer(mini_batches_X[0].shape[0], 30, 'relu', batchSize))\n",
    "nn.addLayer(Layer(30, 10, 'relu', batchSize))\n",
    "nn.addLayer(Layer(10, 1, 'linear', batchSize))\n",
    "\n",
    "start = time.time()\n",
    "nn.fit(mini_batches_X, mini_batches_Y, miniValX, miniValY, lr=1e-4, epochAmount=50)\n",
    "\n",
    "# Load weights\n",
    "# nn.load_weights('nn_weights_MB.npz')\n",
    "end = time.time()\n",
    "\n",
    "nn.save_weights('nn_weights_SGD.npz')\n",
    "\n",
    "print(f'Time elapsed: {end - start:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_history_custom():\n",
    "    iterations, losses = zip(*nn.loss_history)\n",
    "    _, testLosses = zip(*nn.test_loss_history)\n",
    "    plt.plot(iterations, losses)\n",
    "    plt.plot(iterations, testLosses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Performance of SGD (lr = {1e-4}, epoch = {50})')\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_history_custom()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance (MSE): 0.04088682371799708\n",
      "Validation Performance (R2): 0.3843356753882413\n"
     ]
    }
   ],
   "source": [
    "MSE = np.squeeze(nn.testLoss(miniValX.T, miniValY))\n",
    "R2 = np.squeeze(nn.testLossR2(miniValX.T, miniValY))\n",
    "print(f'Validation Performance (MSE): {MSE}')\n",
    "print(f'Validation Performance (R2): {R2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance (MSE): 0.040115269121971456\n",
      "Test Performance (R2): 0.3879069700505764\n"
     ]
    }
   ],
   "source": [
    "MSE = np.squeeze(nn.testLoss(miniTestX.T, miniTestY))\n",
    "R2 = np.squeeze(nn.testLossR2(miniTestX.T, miniTestY))\n",
    "print(f'Test Performance (MSE): {MSE}')\n",
    "print(f'Test Performance (R2): {R2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0.5653393987854322 Response: 0.648\n"
     ]
    }
   ],
   "source": [
    "demoInstanceLoc = 140\n",
    "demoPredictor = predictorData[demoInstanceLoc]\n",
    "demoResponse = responseData[demoInstanceLoc]\n",
    "demoPredictor = np.expand_dims(demoPredictor, axis=0)\n",
    "demoPrediction = np.squeeze(nn.predict(demoPredictor.T))\n",
    "print('Prediction:', demoPrediction, 'Response:', demoResponse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
